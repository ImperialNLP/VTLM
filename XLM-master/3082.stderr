/var/spool/slurm/d/job03082/slurm_script: line 15: {workdir}/3082.stdout: No such file or directory
/var/spool/slurm/d/job03082/slurm_script: line 16: {workdir}/3082.stdout: No such file or directory
/var/spool/slurm/d/job03082/slurm_script: line 17: {workdir}/3082.stdout: No such file or directory
/var/spool/slurm/d/job03082/slurm_script: line 18: {workdir}/3082.stdout: No such file or directory
/var/spool/slurm/d/job03082/slurm_script: line 19: {workdir}/3082.stdout: No such file or directory
/var/spool/slurm/d/job03082/slurm_script: line 20: {workdir}/3082.stdout: No such file or directory
3: FAISS library was not found.
3: FAISS not available. Switching to standard nearest neighbors search implementation.
2: FAISS library was not found.
2: FAISS not available. Switching to standard nearest neighbors search implementation.
0: FAISS library was not found.
0: FAISS not available. Switching to standard nearest neighbors search implementation.
1: FAISS library was not found.
1: FAISS not available. Switching to standard nearest neighbors search implementation.
2: FAISS library was not found.
2: FAISS not available. Switching to standard nearest neighbors search implementation.
0: FAISS library was not found.
0: FAISS not available. Switching to standard nearest neighbors search implementation.
2: FAISS library was not found.
2: FAISS not available. Switching to standard nearest neighbors search implementation.
3: FAISS library was not found.
3: FAISS not available. Switching to standard nearest neighbors search implementation.
1: FAISS library was not found.
1: FAISS not available. Switching to standard nearest neighbors search implementation.
0: FAISS library was not found.
0: FAISS not available. Switching to standard nearest neighbors search implementation.
3: FAISS library was not found.
3: FAISS not available. Switching to standard nearest neighbors search implementation.
1: FAISS library was not found.
1: FAISS not available. Switching to standard nearest neighbors search implementation.
3: INFO - 04/18/20 13:31:24 - 0:00:00 - ============ Initialized logger ============
3: INFO - 04/18/20 13:31:24 - 0:00:00 - accumulate_gradients: 1
3:                                      ae_steps: []
3:                                      amp: -1
3:                                      asm: False
3:                                      attention_dropout: 0.1
3:                                      batch_size: 64
3:                                      beam_size: 1
3:                                      bptt: 256
3:                                      bt_src_langs: []
3:                                      bt_steps: []
3:                                      clip_grad_norm: 5
3:                                      clm_steps: []
3:                                      command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3082"
3:                                      context_size: 0
3:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      debug: False
3:                                      debug_slurm: False
3:                                      debug_train: False
3:                                      dropout: 0.1
3:                                      dump_path: ./dumped/xlm_en_de_tlm/3082
3:                                      early_stopping: False
3:                                      emb_dim: 512
3:                                      encoder_only: True
3:                                      epoch_size: 300000
3:                                      eval_bleu: False
3:                                      eval_only: False
3:                                      exp_id: 3082
3:                                      exp_name: xlm_en_de_tlm
3:                                      fp16: False
3:                                      gelu_activation: True
3:                                      global_rank: 1
3:                                      group_by_size: True
3:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
3:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      is_master: False
3:                                      is_slurm_job: False
3:                                      lambda_ae: 1
3:                                      lambda_bt: 1
3:                                      lambda_clm: 1
3:                                      lambda_mlm: 1
3:                                      lambda_mt: 1
3:                                      lambda_pc: 1
3:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
3:                                      langs: ['en', 'de', 'img']
3:                                      length_penalty: 1
3:                                      lg_sampling_factor: -1
3:                                      lgs: en-de
3:                                      local_rank: 1
3:                                      master_port: -1
3:                                      max_batch_size: 0
3:                                      max_epoch: 100000
3:                                      max_len: 100
3:                                      max_vocab: -1
3:                                      min_count: 0
3:                                      mlm_steps: [('en', 'de')]
3:                                      mono_dataset: {}
3:                                      mt_steps: []
3:                                      multi_gpu: True
3:                                      multi_node: False
3:                                      n_gpu_per_node: 3
3:                                      n_heads: 8
3:                                      n_langs: 3
3:                                      n_layers: 6
3:                                      n_nodes: 1
3:                                      node_id: 0
3:                                      only_vlm: False
3:                                      optimizer: adam,lr=0.0001
3:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      pc_steps: []
3:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
3:                                      reload_checkpoint: 
3:                                      reload_emb: 
3:                                      reload_model: 
3:                                      sample_alpha: 0
3:                                      save_periodic: 0
3:                                      share_inout_emb: True
3:                                      sinusoidal_embeddings: False
3:                                      split_data: False
3:                                      stopping_criterion: _valid_mlm_ppl,25
3:                                      tokens_per_batch: -1
3:                                      use_lang_emb: True
3:                                      use_memory: False
3:                                      validation_metrics: valid_en_de_mlm_ppl
3:                                      vlm_steps: [('en', 'de')]
3:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      word_blank: 0
3:                                      word_dropout: 0
3:                                      word_keep: 0.1
3:                                      word_mask: 0.8
3:                                      word_mask_keep_rand: 0.8,0.1,0.1
3:                                      word_pred: 0.15
3:                                      word_rand: 0.1
3:                                      word_shuffle: 0
3:                                      world_size: 3
3: INFO - 04/18/20 13:31:24 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3082
3:                                      
3: INFO - 04/18/20 13:31:24 - 0:00:00 - Running command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
3: 
3: WARNING - 04/18/20 13:31:24 - 0:00:00 - Signal handler installed.
3: 
3: INFO - 04/18/20 13:31:24 - 0:00:00 - ============ Parallel data (de-en)
3: INFO - 04/18/20 13:31:24 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
1: INFO - 04/18/20 13:31:24 - 0:00:00 - ============ Initialized logger ============
1: INFO - 04/18/20 13:31:24 - 0:00:00 - accumulate_gradients: 1
1:                                      ae_steps: []
1:                                      amp: -1
1:                                      asm: False
1:                                      attention_dropout: 0.1
1:                                      batch_size: 64
1:                                      beam_size: 1
1:                                      bptt: 256
1:                                      bt_src_langs: []
1:                                      bt_steps: []
1:                                      clip_grad_norm: 5
1:                                      clm_steps: []
1:                                      command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3082"
1:                                      context_size: 0
1:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
1:                                      debug: False
1:                                      debug_slurm: False
1:                                      debug_train: False
1:                                      dropout: 0.1
1:                                      dump_path: ./dumped/xlm_en_de_tlm/3082
1:                                      early_stopping: False
1:                                      emb_dim: 512
1:                                      encoder_only: True
1:                                      epoch_size: 300000
1:                                      eval_bleu: False
1:                                      eval_only: False
1:                                      exp_id: 3082
1:                                      exp_name: xlm_en_de_tlm
1:                                      fp16: False
1:                                      gelu_activation: True
1:                                      global_rank: 2
1:                                      group_by_size: True
1:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
1:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
1:                                      is_master: False
1:                                      is_slurm_job: False
1:                                      lambda_ae: 1
1:                                      lambda_bt: 1
1:                                      lambda_clm: 1
1:                                      lambda_mlm: 1
1:                                      lambda_mt: 1
1:                                      lambda_pc: 1
1:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
1:                                      langs: ['en', 'de', 'img']
1:                                      length_penalty: 1
1:                                      lg_sampling_factor: -1
1:                                      lgs: en-de
1:                                      local_rank: 2
1:                                      master_port: -1
1:                                      max_batch_size: 0
1:                                      max_epoch: 100000
1:                                      max_len: 100
1:                                      max_vocab: -1
1:                                      min_count: 0
1:                                      mlm_steps: [('en', 'de')]
1:                                      mono_dataset: {}
1:                                      mt_steps: []
1:                                      multi_gpu: True
1:                                      multi_node: False
1:                                      n_gpu_per_node: 3
1:                                      n_heads: 8
1:                                      n_langs: 3
1:                                      n_layers: 6
1:                                      n_nodes: 1
1:                                      node_id: 0
1:                                      only_vlm: False
1:                                      optimizer: adam,lr=0.0001
1:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
1:                                      pc_steps: []
1:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
1:                                      reload_checkpoint: 
1:                                      reload_emb: 
1:                                      reload_model: 
1:                                      sample_alpha: 0
1:                                      save_periodic: 0
1:                                      share_inout_emb: True
1:                                      sinusoidal_embeddings: False
1:                                      split_data: False
1:                                      stopping_criterion: _valid_mlm_ppl,25
1:                                      tokens_per_batch: -1
1:                                      use_lang_emb: True
1:                                      use_memory: False
1:                                      validation_metrics: valid_en_de_mlm_ppl
1:                                      vlm_steps: [('en', 'de')]
1:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
1:                                      word_blank: 0
1:                                      word_dropout: 0
1:                                      word_keep: 0.1
1:                                      word_mask: 0.8
1:                                      word_mask_keep_rand: 0.8,0.1,0.1
1:                                      word_pred: 0.15
1:                                      word_rand: 0.1
1:                                      word_shuffle: 0
1:                                      world_size: 3
1: INFO - 04/18/20 13:31:24 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3082
1:                                      
1: INFO - 04/18/20 13:31:24 - 0:00:00 - Running command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
3: INFO - 04/18/20 13:31:24 - 0:00:00 - ============ Initialized logger ============
1: 
1: WARNING - 04/18/20 13:31:24 - 0:00:00 - Signal handler installed.
1: 
1: INFO - 04/18/20 13:31:24 - 0:00:00 - ============ Parallel data (de-en)
3: INFO - 04/18/20 13:31:24 - 0:00:00 - accumulate_gradients: 1
3:                                      ae_steps: []
3:                                      amp: -1
3:                                      asm: False
3:                                      attention_dropout: 0.1
3:                                      batch_size: 64
3:                                      beam_size: 1
3:                                      bptt: 256
3:                                      bt_src_langs: []
3:                                      bt_steps: []
3:                                      clip_grad_norm: 5
3:                                      clm_steps: []
3:                                      command: python train.py --local_rank=0 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3082"
3:                                      context_size: 0
3:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      debug: False
3:                                      debug_slurm: False
3:                                      debug_train: False
3:                                      dropout: 0.1
3:                                      dump_path: ./dumped/xlm_en_de_tlm/3082
3:                                      early_stopping: False
3:                                      emb_dim: 512
3:                                      encoder_only: True
3:                                      epoch_size: 300000
3:                                      eval_bleu: False
3:                                      eval_only: False
3:                                      exp_id: 3082
3:                                      exp_name: xlm_en_de_tlm
3:                                      fp16: False
3:                                      gelu_activation: True
3:                                      global_rank: 0
3:                                      group_by_size: True
3:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
3:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      is_master: True
3:                                      is_slurm_job: False
3:                                      lambda_ae: 1
3:                                      lambda_bt: 1
3:                                      lambda_clm: 1
3:                                      lambda_mlm: 1
3:                                      lambda_mt: 1
3:                                      lambda_pc: 1
3:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
3:                                      langs: ['en', 'de', 'img']
3:                                      length_penalty: 1
3:                                      lg_sampling_factor: -1
3:                                      lgs: en-de
3:                                      local_rank: 0
3:                                      master_port: -1
3:                                      max_batch_size: 0
3:                                      max_epoch: 100000
3:                                      max_len: 100
3:                                      max_vocab: -1
3:                                      min_count: 0
3:                                      mlm_steps: [('en', 'de')]
3:                                      mono_dataset: {}
3:                                      mt_steps: []
3:                                      multi_gpu: True
3:                                      multi_node: False
3:                                      n_gpu_per_node: 3
3:                                      n_heads: 8
3:                                      n_langs: 3
3:                                      n_layers: 6
3:                                      n_nodes: 1
1: INFO - 04/18/20 13:31:24 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3:                                      node_id: 0
3:                                      only_vlm: False
3:                                      optimizer: adam,lr=0.0001
3:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      pc_steps: []
3:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
3:                                      reload_checkpoint: 
3:                                      reload_emb: 
3:                                      reload_model: 
3:                                      sample_alpha: 0
3:                                      save_periodic: 0
3:                                      share_inout_emb: True
3:                                      sinusoidal_embeddings: False
3:                                      split_data: False
3:                                      stopping_criterion: _valid_mlm_ppl,25
3:                                      tokens_per_batch: -1
3:                                      use_lang_emb: True
3:                                      use_memory: False
3:                                      validation_metrics: valid_en_de_mlm_ppl
3:                                      vlm_steps: [('en', 'de')]
3:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      word_blank: 0
3:                                      word_dropout: 0
3:                                      word_keep: 0.1
3:                                      word_mask: 0.8
3:                                      word_mask_keep_rand: 0.8,0.1,0.1
3:                                      word_pred: 0.15
3:                                      word_rand: 0.1
3:                                      word_shuffle: 0
3:                                      world_size: 3
3: INFO - 04/18/20 13:31:24 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3082
3:                                      
3: INFO - 04/18/20 13:31:24 - 0:00:00 - Running command: python train.py --local_rank=0 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
3: 
3: WARNING - 04/18/20 13:31:24 - 0:00:00 - Signal handler installed.
3: 
3: INFO - 04/18/20 13:31:24 - 0:00:00 - ============ Parallel data (de-en)
3: INFO - 04/18/20 13:31:24 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
0: INFO - 04/18/20 13:31:24 - 0:00:00 - ============ Initialized logger ============
0: INFO - 04/18/20 13:31:24 - 0:00:00 - accumulate_gradients: 1
0:                                      ae_steps: []
0:                                      amp: -1
0:                                      asm: False
0:                                      attention_dropout: 0.1
0:                                      batch_size: 64
0:                                      beam_size: 1
0:                                      bptt: 256
0:                                      bt_src_langs: []
0:                                      bt_steps: []
0:                                      clip_grad_norm: 5
0:                                      clm_steps: []
0:                                      command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3082"
0:                                      context_size: 0
0:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
0:                                      debug: False
0:                                      debug_slurm: False
0:                                      debug_train: False
0:                                      dropout: 0.1
0:                                      dump_path: ./dumped/xlm_en_de_tlm/3082
0:                                      early_stopping: False
0:                                      emb_dim: 512
0:                                      encoder_only: True
0:                                      epoch_size: 300000
0:                                      eval_bleu: False
0:                                      eval_only: False
0:                                      exp_id: 3082
0:                                      exp_name: xlm_en_de_tlm
0:                                      fp16: False
0:                                      gelu_activation: True
0:                                      global_rank: 2
0:                                      group_by_size: True
0:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
0:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
0:                                      is_master: False
0:                                      is_slurm_job: False
0:                                      lambda_ae: 1
0:                                      lambda_bt: 1
0:                                      lambda_clm: 1
0:                                      lambda_mlm: 1
0:                                      lambda_mt: 1
0:                                      lambda_pc: 1
0:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
0:                                      langs: ['en', 'de', 'img']
0:                                      length_penalty: 1
0:                                      lg_sampling_factor: -1
0:                                      lgs: en-de
0:                                      local_rank: 2
0:                                      master_port: -1
0:                                      max_batch_size: 0
0:                                      max_epoch: 100000
0:                                      max_len: 100
0:                                      max_vocab: -1
0:                                      min_count: 0
0:                                      mlm_steps: [('en', 'de')]
0:                                      mono_dataset: {}
0:                                      mt_steps: []
0:                                      multi_gpu: True
0:                                      multi_node: False
0:                                      n_gpu_per_node: 3
0:                                      n_heads: 8
0:                                      n_langs: 3
0:                                      n_layers: 6
0:                                      n_nodes: 1
0:                                      node_id: 0
0:                                      only_vlm: False
0:                                      optimizer: adam,lr=0.0001
0:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
0:                                      pc_steps: []
0:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
0:                                      reload_checkpoint: 
0:                                      reload_emb: 
0:                                      reload_model: 
0:                                      sample_alpha: 0
0:                                      save_periodic: 0
0:                                      share_inout_emb: True
0:                                      sinusoidal_embeddings: False
0:                                      split_data: False
0:                                      stopping_criterion: _valid_mlm_ppl,25
0:                                      tokens_per_batch: -1
0:                                      use_lang_emb: True
0:                                      use_memory: False
0:                                      validation_metrics: valid_en_de_mlm_ppl
0:                                      vlm_steps: [('en', 'de')]
0:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
0:                                      word_blank: 0
0:                                      word_dropout: 0
0:                                      word_keep: 0.1
0:                                      word_mask: 0.8
0:                                      word_mask_keep_rand: 0.8,0.1,0.1
0:                                      word_pred: 0.15
0:                                      word_rand: 0.1
0:                                      word_shuffle: 0
0:                                      world_size: 3
0: INFO - 04/18/20 13:31:24 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3082
0:                                      
0: INFO - 04/18/20 13:31:24 - 0:00:00 - Running command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
0: 
0: WARNING - 04/18/20 13:31:24 - 0:00:00 - Signal handler installed.
0: 
0: INFO - 04/18/20 13:31:24 - 0:00:00 - ============ Parallel data (de-en)
0: INFO - 04/18/20 13:31:24 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
1: INFO - 04/18/20 13:31:24 - 0:00:00 - ============ Initialized logger ============
3: INFO - 04/18/20 13:31:24 - 0:00:00 - ============ Initialized logger ============
1: INFO - 04/18/20 13:31:24 - 0:00:00 - accumulate_gradients: 1
1:                                      ae_steps: []
1:                                      amp: -1
1:                                      asm: False
1:                                      attention_dropout: 0.1
1:                                      batch_size: 64
1:                                      beam_size: 1
1:                                      bptt: 256
1:                                      bt_src_langs: []
1:                                      bt_steps: []
1:                                      clip_grad_norm: 5
1:                                      clm_steps: []
1:                                      command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3082"
1:                                      context_size: 0
1:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
1:                                      debug: False
1:                                      debug_slurm: False
1:                                      debug_train: False
1:                                      dropout: 0.1
1:                                      dump_path: ./dumped/xlm_en_de_tlm/3082
1:                                      early_stopping: False
1:                                      emb_dim: 512
1:                                      encoder_only: True
1:                                      epoch_size: 300000
1:                                      eval_bleu: False
1:                                      eval_only: False
1:                                      exp_id: 3082
1:                                      exp_name: xlm_en_de_tlm
1:                                      fp16: False
1:                                      gelu_activation: True
1:                                      global_rank: 1
1:                                      group_by_size: True
1:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
1:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
1:                                      is_master: False
1:                                      is_slurm_job: False
1:                                      lambda_ae: 1
1:                                      lambda_bt: 1
1:                                      lambda_clm: 1
1:                                      lambda_mlm: 1
1:                                      lambda_mt: 1
1:                                      lambda_pc: 1
1:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
1:                                      langs: ['en', 'de', 'img']
1:                                      length_penalty: 1
1:                                      lg_sampling_factor: -1
1:                                      lgs: en-de
1:                                      local_rank: 1
1:                                      master_port: -1
1:                                      max_batch_size: 0
1:                                      max_epoch: 100000
1:                                      max_len: 100
1:                                      max_vocab: -1
1:                                      min_count: 0
1:                                      mlm_steps: [('en', 'de')]
1:                                      mono_dataset: {}
1:                                      mt_steps: []
1:                                      multi_gpu: True
1:                                      multi_node: False
1:                                      n_gpu_per_node: 3
1:                                      n_heads: 8
1:                                      n_langs: 3
1:                                      n_layers: 6
1:                                      n_nodes: 1
1:                                      node_id: 0
1:                                      only_vlm: False
1:                                      optimizer: adam,lr=0.0001
1:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
1:                                      pc_steps: []
1:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
1:                                      reload_checkpoint: 
1:                                      reload_emb: 
1:                                      reload_model: 
1:                                      sample_alpha: 0
1:                                      save_periodic: 0
1:                                      share_inout_emb: True
1:                                      sinusoidal_embeddings: False
1:                                      split_data: False
1:                                      stopping_criterion: _valid_mlm_ppl,25
1:                                      tokens_per_batch: -1
1:                                      use_lang_emb: True
1:                                      use_memory: False
1:                                      validation_metrics: valid_en_de_mlm_ppl
1:                                      vlm_steps: [('en', 'de')]
1:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
1:                                      word_blank: 0
1:                                      word_dropout: 0
1:                                      word_keep: 0.1
1:                                      word_mask: 0.8
1:                                      word_mask_keep_rand: 0.8,0.1,0.1
1:                                      word_pred: 0.15
1:                                      word_rand: 0.1
1:                                      word_shuffle: 0
1:                                      world_size: 3
1: INFO - 04/18/20 13:31:24 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3082
1:                                      
1: INFO - 04/18/20 13:31:24 - 0:00:00 - Running command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
3: INFO - 04/18/20 13:31:24 - 0:00:00 - accumulate_gradients: 1
3:                                      ae_steps: []
3:                                      amp: -1
3:                                      asm: False
3:                                      attention_dropout: 0.1
3:                                      batch_size: 64
3:                                      beam_size: 1
3:                                      bptt: 256
3:                                      bt_src_langs: []
3:                                      bt_steps: []
3:                                      clip_grad_norm: 5
3:                                      clm_steps: []
3:                                      command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3082"
3:                                      context_size: 0
3:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      debug: False
3:                                      debug_slurm: False
3:                                      debug_train: False
3:                                      dropout: 0.1
3:                                      dump_path: ./dumped/xlm_en_de_tlm/3082
3:                                      early_stopping: False
3:                                      emb_dim: 512
3:                                      encoder_only: True
3:                                      epoch_size: 300000
3:                                      eval_bleu: False
3:                                      eval_only: False
3:                                      exp_id: 3082
3:                                      exp_name: xlm_en_de_tlm
3:                                      fp16: False
3:                                      gelu_activation: True
3:                                      global_rank: 2
3:                                      group_by_size: True
3:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
3:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      is_master: False
3:                                      is_slurm_job: False
3:                                      lambda_ae: 1
3:                                      lambda_bt: 1
3:                                      lambda_clm: 1
3:                                      lambda_mlm: 1
3:                                      lambda_mt: 1
3:                                      lambda_pc: 1
3:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
3:                                      langs: ['en', 'de', 'img']
3:                                      length_penalty: 1
3:                                      lg_sampling_factor: -1
3:                                      lgs: en-de
3:                                      local_rank: 2
3:                                      master_port: -1
3:                                      max_batch_size: 0
3:                                      max_epoch: 100000
3:                                      max_len: 100
3:                                      max_vocab: -1
3:                                      min_count: 0
3:                                      mlm_steps: [('en', 'de')]
3:                                      mono_dataset: {}
3:                                      mt_steps: []
3:                                      multi_gpu: True
3:                                      multi_node: False
3:                                      n_gpu_per_node: 3
3:                                      n_heads: 8
3:                                      n_langs: 3
3:                                      n_layers: 6
3:                                      n_nodes: 1
1: 
1: WARNING - 04/18/20 13:31:24 - 0:00:00 - Signal handler installed.
3:                                      node_id: 0
3:                                      only_vlm: False
3:                                      optimizer: adam,lr=0.0001
3:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      pc_steps: []
3:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
3:                                      reload_checkpoint: 
3:                                      reload_emb: 
3:                                      reload_model: 
3:                                      sample_alpha: 0
3:                                      save_periodic: 0
3:                                      share_inout_emb: True
3:                                      sinusoidal_embeddings: False
3:                                      split_data: False
3:                                      stopping_criterion: _valid_mlm_ppl,25
3:                                      tokens_per_batch: -1
3:                                      use_lang_emb: True
3:                                      use_memory: False
3:                                      validation_metrics: valid_en_de_mlm_ppl
3:                                      vlm_steps: [('en', 'de')]
3:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      word_blank: 0
3:                                      word_dropout: 0
3:                                      word_keep: 0.1
3:                                      word_mask: 0.8
3:                                      word_mask_keep_rand: 0.8,0.1,0.1
3:                                      word_pred: 0.15
3:                                      word_rand: 0.1
3:                                      word_shuffle: 0
3:                                      world_size: 3
3: INFO - 04/18/20 13:31:24 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3082
3:                                      
1: 
3: INFO - 04/18/20 13:31:24 - 0:00:00 - Running command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
3: 
1: INFO - 04/18/20 13:31:24 - 0:00:00 - ============ Parallel data (de-en)
3: WARNING - 04/18/20 13:31:24 - 0:00:00 - Signal handler installed.
1: INFO - 04/18/20 13:31:24 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: 
3: INFO - 04/18/20 13:31:24 - 0:00:00 - ============ Parallel data (de-en)
3: INFO - 04/18/20 13:31:24 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
0: Traceback (most recent call last):
0:   File "train.py", line 348, in <module>
0:     main(params)
0:   File "train.py", line 230, in main
0:     init_distributed_mode(params)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/slurm.py", line 171, in init_distributed_mode
0:     backend='nccl',
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py", line 397, in init_process_group
0:     store, rank, world_size = next(rendezvous_iterator)
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/rendezvous.py", line 168, in _env_rendezvous_handler
2: INFO - 04/18/20 13:31:24 - 0:00:00 - ============ Initialized logger ============
0:     store = TCPStore(master_addr, master_port, world_size, start_daemon)
0: RuntimeError: Address already in use
1: Traceback (most recent call last):
1:   File "train.py", line 348, in <module>
2: INFO - 04/18/20 13:31:24 - 0:00:00 - accumulate_gradients: 1
2:                                      ae_steps: []
2:                                      amp: -1
2:                                      asm: False
2:                                      attention_dropout: 0.1
2:                                      batch_size: 64
2:                                      beam_size: 1
2:                                      bptt: 256
2:                                      bt_src_langs: []
2:                                      bt_steps: []
2:                                      clip_grad_norm: 5
2:                                      clm_steps: []
2:                                      command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3082"
2:                                      context_size: 0
2:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
2:                                      debug: False
2:                                      debug_slurm: False
2:                                      debug_train: False
2:                                      dropout: 0.1
2:                                      dump_path: ./dumped/xlm_en_de_tlm/3082
2:                                      early_stopping: False
2:                                      emb_dim: 512
2:                                      encoder_only: True
2:                                      epoch_size: 300000
2:                                      eval_bleu: False
2:                                      eval_only: False
2:                                      exp_id: 3082
2:                                      exp_name: xlm_en_de_tlm
2:                                      fp16: False
2:                                      gelu_activation: True
2:                                      global_rank: 1
2:                                      group_by_size: True
2:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
2:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
2:                                      is_master: False
2:                                      is_slurm_job: False
2:                                      lambda_ae: 1
2:                                      lambda_bt: 1
2:                                      lambda_clm: 1
2:                                      lambda_mlm: 1
2:                                      lambda_mt: 1
2:                                      lambda_pc: 1
2:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
2:                                      langs: ['en', 'de', 'img']
2:                                      length_penalty: 1
2:                                      lg_sampling_factor: -1
2:                                      lgs: en-de
2:                                      local_rank: 1
2:                                      master_port: -1
2:                                      max_batch_size: 0
2:                                      max_epoch: 100000
2:                                      max_len: 100
2:                                      max_vocab: -1
2:                                      min_count: 0
2:                                      mlm_steps: [('en', 'de')]
2:                                      mono_dataset: {}
2:                                      mt_steps: []
2:                                      multi_gpu: True
2:                                      multi_node: False
2:                                      n_gpu_per_node: 3
2:                                      n_heads: 8
2:                                      n_langs: 3
2:                                      n_layers: 6
2:                                      n_nodes: 1
2:                                      node_id: 0
2:                                      only_vlm: False
2:                                      optimizer: adam,lr=0.0001
2:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
2:                                      pc_steps: []
2:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
2:                                      reload_checkpoint: 
2:                                      reload_emb: 
2:                                      reload_model: 
2:                                      sample_alpha: 0
2:                                      save_periodic: 0
2:                                      share_inout_emb: True
2:                                      sinusoidal_embeddings: False
2:                                      split_data: False
2:                                      stopping_criterion: _valid_mlm_ppl,25
2:                                      tokens_per_batch: -1
2:                                      use_lang_emb: True
2:                                      use_memory: False
2:                                      validation_metrics: valid_en_de_mlm_ppl
2:                                      vlm_steps: [('en', 'de')]
2:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
2:                                      word_blank: 0
2:                                      word_dropout: 0
2:                                      word_keep: 0.1
2:                                      word_mask: 0.8
2:                                      word_mask_keep_rand: 0.8,0.1,0.1
2:                                      word_pred: 0.15
2:                                      word_rand: 0.1
2:                                      word_shuffle: 0
2:                                      world_size: 3
2: INFO - 04/18/20 13:31:24 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3082
2:                                      
2: INFO - 04/18/20 13:31:24 - 0:00:00 - Running command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
2: 
2: WARNING - 04/18/20 13:31:24 - 0:00:00 - Signal handler installed.
2: 
2: INFO - 04/18/20 13:31:24 - 0:00:00 - ============ Parallel data (de-en)
1:     main(params)
1:   File "train.py", line 230, in main
2: INFO - 04/18/20 13:31:24 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
1:     init_distributed_mode(params)
1:   File "/home/menekse/xlm/Animal/XLM-master/src/slurm.py", line 171, in init_distributed_mode
1:     backend='nccl',
1:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py", line 397, in init_process_group
1:     store, rank, world_size = next(rendezvous_iterator)
1:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/rendezvous.py", line 168, in _env_rendezvous_handler
1:     store = TCPStore(master_addr, master_port, world_size, start_daemon)
1: RuntimeError: Address already in use
2: Traceback (most recent call last):
2:   File "train.py", line 348, in <module>
0: INFO - 04/18/20 13:31:24 - 0:00:00 - ============ Initialized logger ============
2: INFO - 04/18/20 13:31:24 - 0:00:00 - ============ Initialized logger ============
2: INFO - 04/18/20 13:31:24 - 0:00:00 - accumulate_gradients: 1
2:                                      ae_steps: []
2:                                      amp: -1
2:                                      asm: False
2:                                      attention_dropout: 0.1
2:                                      batch_size: 64
2:                                      beam_size: 1
2:                                      bptt: 256
2:                                      bt_src_langs: []
2:                                      bt_steps: []
2:                                      clip_grad_norm: 5
2:                                      clm_steps: []
2:                                      command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3082"
2:                                      context_size: 0
2:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
2:                                      debug: False
2:                                      debug_slurm: False
2:                                      debug_train: False
2:                                      dropout: 0.1
2:                                      dump_path: ./dumped/xlm_en_de_tlm/3082
2:                                      early_stopping: False
2:                                      emb_dim: 512
2:                                      encoder_only: True
2:                                      epoch_size: 300000
2:                                      eval_bleu: False
2:                                      eval_only: False
2:                                      exp_id: 3082
2:                                      exp_name: xlm_en_de_tlm
2:                                      fp16: False
2:                                      gelu_activation: True
2:                                      global_rank: 2
2:                                      group_by_size: True
2:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
2:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
2:                                      is_master: False
2:                                      is_slurm_job: False
2:                                      lambda_ae: 1
2:                                      lambda_bt: 1
2:                                      lambda_clm: 1
2:                                      lambda_mlm: 1
2:                                      lambda_mt: 1
2:                                      lambda_pc: 1
2:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
2:                                      langs: ['en', 'de', 'img']
2:                                      length_penalty: 1
2:                                      lg_sampling_factor: -1
2:                                      lgs: en-de
2:                                      local_rank: 2
2:                                      master_port: -1
2:                                      max_batch_size: 0
2:                                      max_epoch: 100000
2:                                      max_len: 100
2:                                      max_vocab: -1
2:                                      min_count: 0
2:                                      mlm_steps: [('en', 'de')]
2:                                      mono_dataset: {}
2:                                      mt_steps: []
2:                                      multi_gpu: True
2:                                      multi_node: False
2:                                      n_gpu_per_node: 3
2:                                      n_heads: 8
2:                                      n_langs: 3
2:                                      n_layers: 6
2:                                      n_nodes: 1
0: INFO - 04/18/20 13:31:24 - 0:00:00 - accumulate_gradients: 1
0:                                      ae_steps: []
0:                                      amp: -1
0:                                      asm: False
0:                                      attention_dropout: 0.1
0:                                      batch_size: 64
0:                                      beam_size: 1
0:                                      bptt: 256
0:                                      bt_src_langs: []
0:                                      bt_steps: []
0:                                      clip_grad_norm: 5
0:                                      clm_steps: []
0:                                      command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3082"
0:                                      context_size: 0
0:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
0:                                      debug: False
0:                                      debug_slurm: False
0:                                      debug_train: False
0:                                      dropout: 0.1
0:                                      dump_path: ./dumped/xlm_en_de_tlm/3082
0:                                      early_stopping: False
0:                                      emb_dim: 512
0:                                      encoder_only: True
0:                                      epoch_size: 300000
0:                                      eval_bleu: False
0:                                      eval_only: False
0:                                      exp_id: 3082
0:                                      exp_name: xlm_en_de_tlm
0:                                      fp16: False
0:                                      gelu_activation: True
0:                                      global_rank: 1
0:                                      group_by_size: True
0:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
0:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
0:                                      is_master: False
0:                                      is_slurm_job: False
0:                                      lambda_ae: 1
0:                                      lambda_bt: 1
0:                                      lambda_clm: 1
0:                                      lambda_mlm: 1
0:                                      lambda_mt: 1
0:                                      lambda_pc: 1
0:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
0:                                      langs: ['en', 'de', 'img']
0:                                      length_penalty: 1
0:                                      lg_sampling_factor: -1
0:                                      lgs: en-de
0:                                      local_rank: 1
0:                                      master_port: -1
0:                                      max_batch_size: 0
0:                                      max_epoch: 100000
0:                                      max_len: 100
0:                                      max_vocab: -1
0:                                      min_count: 0
0:                                      mlm_steps: [('en', 'de')]
0:                                      mono_dataset: {}
0:                                      mt_steps: []
0:                                      multi_gpu: True
0:                                      multi_node: False
0:                                      n_gpu_per_node: 3
0:                                      n_heads: 8
0:                                      n_langs: 3
0:                                      n_layers: 6
0:                                      n_nodes: 1
2:                                      node_id: 0
2:                                      only_vlm: False
2:                                      optimizer: adam,lr=0.0001
2:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
2:                                      pc_steps: []
2:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
2:                                      reload_checkpoint: 
2:                                      reload_emb: 
2:                                      reload_model: 
2:                                      sample_alpha: 0
2:                                      save_periodic: 0
2:                                      share_inout_emb: True
2:                                      sinusoidal_embeddings: False
2:                                      split_data: False
2:                                      stopping_criterion: _valid_mlm_ppl,25
2:                                      tokens_per_batch: -1
2:                                      use_lang_emb: True
2:                                      use_memory: False
2:                                      validation_metrics: valid_en_de_mlm_ppl
2:                                      vlm_steps: [('en', 'de')]
2:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
2:                                      word_blank: 0
2:                                      word_dropout: 0
2:                                      word_keep: 0.1
2:                                      word_mask: 0.8
2:                                      word_mask_keep_rand: 0.8,0.1,0.1
2:                                      word_pred: 0.15
2:                                      word_rand: 0.1
2:                                      word_shuffle: 0
2:                                      world_size: 3
2: INFO - 04/18/20 13:31:24 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3082
2:                                      
2: INFO - 04/18/20 13:31:24 - 0:00:00 - Running command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
0:                                      node_id: 0
0:                                      only_vlm: False
0:                                      optimizer: adam,lr=0.0001
0:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
0:                                      pc_steps: []
0:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
0:                                      reload_checkpoint: 
0:                                      reload_emb: 
0:                                      reload_model: 
0:                                      sample_alpha: 0
0:                                      save_periodic: 0
0:                                      share_inout_emb: True
0:                                      sinusoidal_embeddings: False
0:                                      split_data: False
0:                                      stopping_criterion: _valid_mlm_ppl,25
0:                                      tokens_per_batch: -1
0:                                      use_lang_emb: True
0:                                      use_memory: False
0:                                      validation_metrics: valid_en_de_mlm_ppl
0:                                      vlm_steps: [('en', 'de')]
0:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
0:                                      word_blank: 0
0:                                      word_dropout: 0
0:                                      word_keep: 0.1
0:                                      word_mask: 0.8
0:                                      word_mask_keep_rand: 0.8,0.1,0.1
0:                                      word_pred: 0.15
0:                                      word_rand: 0.1
0:                                      word_shuffle: 0
0:                                      world_size: 3
0: INFO - 04/18/20 13:31:24 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3082
0:                                      
0: INFO - 04/18/20 13:31:24 - 0:00:00 - Running command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
0: 
2: 
2:     main(params)
2:   File "train.py", line 230, in main
2: WARNING - 04/18/20 13:31:24 - 0:00:00 - Signal handler installed.
0: WARNING - 04/18/20 13:31:24 - 0:00:00 - Signal handler installed.
2: 
0: 
2: INFO - 04/18/20 13:31:24 - 0:00:00 - ============ Parallel data (de-en)
0: INFO - 04/18/20 13:31:24 - 0:00:00 - ============ Parallel data (de-en)
2: INFO - 04/18/20 13:31:24 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
0: INFO - 04/18/20 13:31:24 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
2:     init_distributed_mode(params)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/slurm.py", line 171, in init_distributed_mode
2:     backend='nccl',
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py", line 397, in init_process_group
2:     store, rank, world_size = next(rendezvous_iterator)
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/rendezvous.py", line 168, in _env_rendezvous_handler
2:     store = TCPStore(master_addr, master_port, world_size, start_daemon)
2: RuntimeError: Address already in use
1: INFO - 04/18/20 13:31:29 - 0:00:05 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:31:29 - 0:00:05 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
3: INFO - 04/18/20 13:31:29 - 0:00:05 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:31:29 - 0:00:05 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
3: INFO - 04/18/20 13:31:29 - 0:00:05 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:31:29 - 0:00:05 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
0: INFO - 04/18/20 13:31:31 - 0:00:07 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:31:31 - 0:00:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
2: INFO - 04/18/20 13:31:31 - 0:00:07 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:31:31 - 0:00:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
1: INFO - 04/18/20 13:31:31 - 0:00:07 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:31:31 - 0:00:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
0: INFO - 04/18/20 13:31:31 - 0:00:07 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:31:31 - 0:00:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
3: INFO - 04/18/20 13:31:31 - 0:00:07 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:31:31 - 0:00:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
2: INFO - 04/18/20 13:31:32 - 0:00:08 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:31:32 - 0:00:08 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
1: Traceback (most recent call last):
1:   File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
1:     "__main__", mod_spec)
1:   File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
1:     exec(code, run_globals)
1:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 263, in <module>
1:     main()
1:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 259, in main
1:     cmd=cmd)
1: subprocess.CalledProcessError: Command '['/home/menekse/virtualenvs/torch_env/bin/python', '-u', 'train.py', '--local_rank=2', '--exp_name', 'xlm_en_de_tlm', '--dump_path', './dumped', '--data_path', '/data/shared/ConceptualCaptions/XLM_data/50k', '--lgs', 'en-de', '--clm_steps', '', '--mlm_steps', 'en-de', '--emb_dim', '512', '--n_layers', '6', '--n_heads', '8', '--dropout', '0.1', '--attention_dropout', '0.1', '--gelu_activation', 'true', '--batch_size', '64', '--bptt', '256', '--optimizer', 'adam,lr=0.0001', '--epoch_size', '300000', '--max_epoch', '100000', '--validation_metrics', 'valid_en_de_mlm_ppl', '--stopping_criterion', '_valid_mlm_ppl,25', '--fp16', 'false', '--image_names', '/data/shared/ConceptualCaptions/XLM_data/50k']' returned non-zero exit status 1.
0: Traceback (most recent call last):
0:   File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
0:     "__main__", mod_spec)
0:   File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
0:     exec(code, run_globals)
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 263, in <module>
0:     main()
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 259, in main
0:     cmd=cmd)
0: subprocess.CalledProcessError: Command '['/home/menekse/virtualenvs/torch_env/bin/python', '-u', 'train.py', '--local_rank=2', '--exp_name', 'xlm_en_de_tlm', '--dump_path', './dumped', '--data_path', '/data/shared/ConceptualCaptions/XLM_data/50k', '--lgs', 'en-de', '--clm_steps', '', '--mlm_steps', 'en-de', '--emb_dim', '512', '--n_layers', '6', '--n_heads', '8', '--dropout', '0.1', '--attention_dropout', '0.1', '--gelu_activation', 'true', '--batch_size', '64', '--bptt', '256', '--optimizer', 'adam,lr=0.0001', '--epoch_size', '300000', '--max_epoch', '100000', '--validation_metrics', 'valid_en_de_mlm_ppl', '--stopping_criterion', '_valid_mlm_ppl,25', '--fp16', 'false', '--image_names', '/data/shared/ConceptualCaptions/XLM_data/50k']' returned non-zero exit status 1.
2: Traceback (most recent call last):
2:   File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
2:     "__main__", mod_spec)
2:   File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
2:     exec(code, run_globals)
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 263, in <module>
2:     main()
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 259, in main
2:     cmd=cmd)
2: subprocess.CalledProcessError: Command '['/home/menekse/virtualenvs/torch_env/bin/python', '-u', 'train.py', '--local_rank=2', '--exp_name', 'xlm_en_de_tlm', '--dump_path', './dumped', '--data_path', '/data/shared/ConceptualCaptions/XLM_data/50k', '--lgs', 'en-de', '--clm_steps', '', '--mlm_steps', 'en-de', '--emb_dim', '512', '--n_layers', '6', '--n_heads', '8', '--dropout', '0.1', '--attention_dropout', '0.1', '--gelu_activation', 'true', '--batch_size', '64', '--bptt', '256', '--optimizer', 'adam,lr=0.0001', '--epoch_size', '300000', '--max_epoch', '100000', '--validation_metrics', 'valid_en_de_mlm_ppl', '--stopping_criterion', '_valid_mlm_ppl,25', '--fp16', 'false', '--image_names', '/data/shared/ConceptualCaptions/XLM_data/50k']' returned non-zero exit status 1.
1: INFO - 04/18/20 13:31:34 - 0:00:11 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:31:34 - 0:00:11 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:31:35 - 0:00:11 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:31:37 - 0:00:13 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:31:37 - 0:00:13 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
0: INFO - 04/18/20 13:31:37 - 0:00:13 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
2: INFO - 04/18/20 13:31:38 - 0:00:14 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
2: INFO - 04/18/20 13:31:38 - 0:00:14 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
srun: error: hanabi: task 0: Exited with exit code 1
0: INFO - 04/18/20 13:31:39 - 0:00:15 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
srun: error: hanabi: task 1: Exited with exit code 1
srun: error: hanabi: task 2: Exited with exit code 1
3: INFO - 04/18/20 13:31:46 - 0:00:22 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:31:46 - 0:00:22 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:31:46 - 0:00:22 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:31:47 - 0:00:23 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:31:47 - 0:00:23 - Removed 0 empty sentences.
2: INFO - 04/18/20 13:31:48 - 0:00:24 - Removed 0 empty sentences.
2: INFO - 04/18/20 13:31:48 - 0:00:24 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:31:52 - 0:00:28 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:31:53 - 0:00:29 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:32:03 - 0:00:39 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:32:04 - 0:00:40 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:32:05 - 0:00:41 - Removed 0 empty sentences.
2: INFO - 04/18/20 13:32:05 - 0:00:41 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:32:05 - 0:00:42 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:32:05 - 0:00:42 - Removed 0 empty sentences.
2: INFO - 04/18/20 13:32:06 - 0:00:42 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:32:13 - 0:00:49 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:32:14 - 0:00:51 - Removed 2 too long sentences.
3: INFO - 04/18/20 13:32:16 - 0:00:52 - Removed 2 too long sentences.
0: INFO - 04/18/20 13:32:16 - 0:00:53 - Removed 0 empty sentences.
2: INFO - 04/18/20 13:32:17 - 0:00:53 - Removed 2 too long sentences.
2: INFO - 04/18/20 13:32:18 - 0:00:54 - Removed 2 too long sentences.
3: INFO - 04/18/20 13:32:18 - 0:00:55 - Removed 2 too long sentences.
1: INFO - 04/18/20 13:32:19 - 0:00:55 - Removed 2 too long sentences.
1: 
1: INFO - 04/18/20 13:32:19 - 0:00:56 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
3: INFO - 04/18/20 13:32:20 - 0:00:56 - Removed 2 too long sentences.
1: INFO - 04/18/20 13:32:20 - 0:00:56 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:32:20 - 0:00:56 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
3: 
3: INFO - 04/18/20 13:32:20 - 0:00:56 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
1: INFO - 04/18/20 13:32:20 - 0:00:57 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:32:21 - 0:00:57 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:32:21 - 0:00:57 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
3: INFO - 04/18/20 13:32:21 - 0:00:57 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
2: 
2: INFO - 04/18/20 13:32:22 - 0:00:58 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
2: INFO - 04/18/20 13:32:22 - 0:00:59 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:32:23 - 0:00:59 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
2: 
2: INFO - 04/18/20 13:32:23 - 0:00:59 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
2: INFO - 04/18/20 13:32:23 - 0:00:59 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
2: INFO - 04/18/20 13:32:23 - 0:00:59 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:32:23 - 0:00:59 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
2: INFO - 04/18/20 13:32:23 - 0:01:00 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:32:23 - 0:01:00 - Removed 0 empty sentences.
1: 
1: INFO - 04/18/20 13:32:23 - 0:01:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: 
3: INFO - 04/18/20 13:32:24 - 0:01:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
1: INFO - 04/18/20 13:32:24 - 0:01:00 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:32:24 - 0:01:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
3: INFO - 04/18/20 13:32:24 - 0:01:00 - Removed 0 empty sentences.
3: 
3: INFO - 04/18/20 13:32:24 - 0:01:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/18/20 13:32:24 - 0:01:01 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:32:24 - 0:01:00 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
3: INFO - 04/18/20 13:32:24 - 0:01:01 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:32:24 - 0:01:01 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
3: INFO - 04/18/20 13:32:24 - 0:01:01 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
3: INFO - 04/18/20 13:32:25 - 0:01:01 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: 
1: INFO - 04/18/20 13:32:25 - 0:01:01 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
3: INFO - 04/18/20 13:32:25 - 0:01:01 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:32:25 - 0:01:01 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:32:25 - 0:01:02 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
3: 
3: INFO - 04/18/20 13:32:25 - 0:01:02 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
1: INFO - 04/18/20 13:32:26 - 0:01:02 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
2: INFO - 04/18/20 13:32:26 - 0:01:02 - Removed 0 empty sentences.
2: 
2: INFO - 04/18/20 13:32:26 - 0:01:02 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/18/20 13:32:26 - 0:01:02 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:32:26 - 0:01:02 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
2: INFO - 04/18/20 13:32:26 - 0:01:02 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:32:26 - 0:01:02 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
2: INFO - 04/18/20 13:32:26 - 0:01:02 - Removed 0 empty sentences.
2: 
2: INFO - 04/18/20 13:32:26 - 0:01:02 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/18/20 13:32:26 - 0:01:03 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
2: INFO - 04/18/20 13:32:27 - 0:01:03 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:32:27 - 0:01:03 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
2: INFO - 04/18/20 13:32:27 - 0:01:03 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/18/20 13:32:27 - 0:01:03 - Removed 0 empty sentences.
1: 
1: 
1: INFO - 04/18/20 13:32:27 - 0:01:03 - ============ Parallel data with image regions (de-en)
1: INFO - 04/18/20 13:32:27 - 0:01:03 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
2: INFO - 04/18/20 13:32:27 - 0:01:03 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
0: INFO - 04/18/20 13:32:27 - 0:01:03 - Removed 2 too long sentences.
3: INFO - 04/18/20 13:32:27 - 0:01:04 - Removed 0 empty sentences.
3: 
3: 
3: INFO - 04/18/20 13:32:28 - 0:01:04 - ============ Parallel data with image regions (de-en)
3: INFO - 04/18/20 13:32:28 - 0:01:04 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: INFO - 04/18/20 13:32:29 - 0:01:06 - Removed 0 empty sentences.
3: 
3: INFO - 04/18/20 13:32:29 - 0:01:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
2: INFO - 04/18/20 13:32:29 - 0:01:06 - Removed 0 empty sentences.
2: 
2: 
3: INFO - 04/18/20 13:32:30 - 0:01:06 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:32:30 - 0:01:06 - ============ Parallel data with image regions (de-en)
2: INFO - 04/18/20 13:32:30 - 0:01:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: INFO - 04/18/20 13:32:30 - 0:01:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
0: INFO - 04/18/20 13:32:30 - 0:01:06 - Removed 2 too long sentences.
2: INFO - 04/18/20 13:32:30 - 0:01:06 - Removed 0 empty sentences.
2: 
2: 
2: INFO - 04/18/20 13:32:30 - 0:01:06 - ============ Parallel data with image regions (de-en)
2: INFO - 04/18/20 13:32:30 - 0:01:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: INFO - 04/18/20 13:32:30 - 0:01:06 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: INFO - 04/18/20 13:32:30 - 0:01:06 - Removed 0 empty sentences.
1: 
1: INFO - 04/18/20 13:32:30 - 0:01:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/18/20 13:32:31 - 0:01:07 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:32:31 - 0:01:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
1: INFO - 04/18/20 13:32:31 - 0:01:07 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:32:31 - 0:01:07 - Removed 0 empty sentences.
3: 
3: INFO - 04/18/20 13:32:31 - 0:01:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/18/20 13:32:31 - 0:01:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
3: INFO - 04/18/20 13:32:31 - 0:01:07 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:32:31 - 0:01:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/18/20 13:32:31 - 0:01:08 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
3: INFO - 04/18/20 13:32:32 - 0:01:08 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
3: INFO - 04/18/20 13:32:32 - 0:01:08 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:32:32 - 0:01:08 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
0: 
0: INFO - 04/18/20 13:32:33 - 0:01:09 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
0: INFO - 04/18/20 13:32:33 - 0:01:09 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:32:33 - 0:01:09 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
0: INFO - 04/18/20 13:32:34 - 0:01:10 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
2: INFO - 04/18/20 13:32:34 - 0:01:10 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:32:34 - 0:01:10 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
3: INFO - 04/18/20 13:32:34 - 0:01:11 - Removed 0 empty sentences.
3: 
3: 
2: INFO - 04/18/20 13:32:35 - 0:01:11 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:32:35 - 0:01:11 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
3: INFO - 04/18/20 13:32:35 - 0:01:11 - ============ Parallel data with image regions (de-en)
3: INFO - 04/18/20 13:32:35 - 0:01:11 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
1: INFO - 04/18/20 13:32:35 - 0:01:11 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
0: 
0: INFO - 04/18/20 13:32:36 - 0:01:12 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
3: INFO - 04/18/20 13:32:36 - 0:01:12 - Removed 0 empty sentences.
3: 
3: 
1: INFO - 04/18/20 13:32:36 - 0:01:12 - Removed 0 empty sentences.
1: 
1: 
3: INFO - 04/18/20 13:32:36 - 0:01:12 - ============ Parallel data with image regions (de-en)
3: INFO - 04/18/20 13:32:36 - 0:01:12 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: INFO - 04/18/20 13:32:36 - 0:01:12 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
0: INFO - 04/18/20 13:32:36 - 0:01:12 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:32:36 - 0:01:12 - ============ Parallel data with image regions (de-en)
1: INFO - 04/18/20 13:32:36 - 0:01:12 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
0: INFO - 04/18/20 13:32:36 - 0:01:12 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
0: INFO - 04/18/20 13:32:37 - 0:01:13 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
0: INFO - 04/18/20 13:32:38 - 0:01:14 - Removed 0 empty sentences.
0: 
0: INFO - 04/18/20 13:32:38 - 0:01:14 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
2: INFO - 04/18/20 13:32:38 - 0:01:14 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
2: INFO - 04/18/20 13:32:38 - 0:01:14 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
0: INFO - 04/18/20 13:32:38 - 0:01:14 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:32:38 - 0:01:14 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
0: INFO - 04/18/20 13:32:39 - 0:01:15 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
3: INFO - 04/18/20 13:32:39 - 0:01:16 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:32:39 - 0:01:16 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
3: INFO - 04/18/20 13:32:40 - 0:01:17 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:32:40 - 0:01:17 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
0: INFO - 04/18/20 13:32:41 - 0:01:17 - Removed 0 empty sentences.
0: 
0: INFO - 04/18/20 13:32:41 - 0:01:17 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/18/20 13:32:41 - 0:01:17 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:32:41 - 0:01:17 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
0: INFO - 04/18/20 13:32:41 - 0:01:17 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:32:41 - 0:01:18 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
0: INFO - 04/18/20 13:32:42 - 0:01:18 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
0: INFO - 04/18/20 13:32:43 - 0:01:19 - Removed 0 empty sentences.
0: 
0: 
0: INFO - 04/18/20 13:32:43 - 0:01:19 - ============ Parallel data with image regions (de-en)
0: INFO - 04/18/20 13:32:43 - 0:01:19 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: INFO - 04/18/20 13:32:44 - 0:01:21 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:32:45 - 0:01:21 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:32:46 - 0:01:22 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
0: INFO - 04/18/20 13:32:46 - 0:01:22 - Removed 0 empty sentences.
0: 
0: 
0: INFO - 04/18/20 13:32:46 - 0:01:22 - ============ Parallel data with image regions (de-en)
0: INFO - 04/18/20 13:32:46 - 0:01:22 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
0: INFO - 04/18/20 13:32:48 - 0:01:24 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:32:48 - 0:01:24 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
0: INFO - 04/18/20 13:32:50 - 0:01:26 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:32:50 - 0:01:26 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
0: INFO - 04/18/20 13:32:51 - 0:01:27 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
0: INFO - 04/18/20 13:32:53 - 0:01:29 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:33:38 - 0:02:15 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:33:41 - 0:02:17 - Removed 0 empty sentences.
2: INFO - 04/18/20 13:33:43 - 0:02:19 - Removed 0 empty sentences.
2: INFO - 04/18/20 13:33:43 - 0:02:19 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:33:55 - 0:02:32 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:33:58 - 0:02:34 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:34:00 - 0:02:36 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:34:00 - 0:02:36 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:34:03 - 0:02:39 - Removed 0 empty sentences.
2: INFO - 04/18/20 13:34:04 - 0:02:40 - Removed 0 empty sentences.
2: INFO - 04/18/20 13:34:04 - 0:02:40 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:34:09 - 0:02:45 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:34:12 - 0:02:48 - Removed 2 too long sentences.
0: INFO - 04/18/20 13:34:13 - 0:02:50 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:34:14 - 0:02:50 - Removed 2 too long sentences.
1: 
1: INFO - 04/18/20 13:34:17 - 0:02:53 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
1: INFO - 04/18/20 13:34:17 - 0:02:53 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:34:17 - 0:02:53 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: INFO - 04/18/20 13:34:18 - 0:02:54 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:34:18 - 0:02:55 - Removed 0 empty sentences.
2: INFO - 04/18/20 13:34:19 - 0:02:55 - Removed 2 too long sentences.
3: 
3: INFO - 04/18/20 13:34:19 - 0:02:55 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
2: INFO - 04/18/20 13:34:19 - 0:02:55 - Removed 2 too long sentences.
3: INFO - 04/18/20 13:34:19 - 0:02:56 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:34:20 - 0:02:56 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
3: INFO - 04/18/20 13:34:20 - 0:02:56 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:34:22 - 0:02:58 - Removed 0 empty sentences.
2: 
2: INFO - 04/18/20 13:34:23 - 0:02:59 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
2: INFO - 04/18/20 13:34:23 - 0:03:00 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:34:24 - 0:03:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
2: INFO - 04/18/20 13:34:24 - 0:03:00 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
2: 
2: INFO - 04/18/20 13:34:24 - 0:03:01 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
2: INFO - 04/18/20 13:34:25 - 0:03:01 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:34:25 - 0:03:01 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
2: INFO - 04/18/20 13:34:25 - 0:03:01 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:34:27 - 0:03:03 - Removed 0 empty sentences.
1: 
1: INFO - 04/18/20 13:34:27 - 0:03:03 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/18/20 13:34:27 - 0:03:03 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:34:27 - 0:03:04 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/18/20 13:34:28 - 0:03:04 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: INFO - 04/18/20 13:34:28 - 0:03:04 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:34:30 - 0:03:06 - Removed 0 empty sentences.
3: 
3: INFO - 04/18/20 13:34:30 - 0:03:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/18/20 13:34:30 - 0:03:06 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:34:30 - 0:03:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/18/20 13:34:30 - 0:03:06 - Removed 0 empty sentences.
1: 
1: 
1: INFO - 04/18/20 13:34:30 - 0:03:07 - ============ Data summary
1: INFO - 04/18/20 13:34:30 - 0:03:07 - Parallel data      - train -        de-en:   3308331
1: INFO - 04/18/20 13:34:30 - 0:03:07 - Parallel data      - valid -        de-en:      5000
1: INFO - 04/18/20 13:34:30 - 0:03:07 - Parallel data      -  test -        de-en:      5000
1: 
3: INFO - 04/18/20 13:34:31 - 0:03:07 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
0: INFO - 04/18/20 13:34:32 - 0:03:08 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:34:33 - 0:03:09 - Removed 0 empty sentences.
3: 
3: 
3: INFO - 04/18/20 13:34:33 - 0:03:09 - ============ Data summary
3: INFO - 04/18/20 13:34:33 - 0:03:09 - Parallel data      - train -        de-en:   3308331
3: INFO - 04/18/20 13:34:33 - 0:03:09 - Parallel data      - valid -        de-en:      5000
3: INFO - 04/18/20 13:34:33 - 0:03:09 - Parallel data      -  test -        de-en:      5000
3: 
2: INFO - 04/18/20 13:34:33 - 0:03:09 - Removed 0 empty sentences.
2: 
2: INFO - 04/18/20 13:34:33 - 0:03:09 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
2: INFO - 04/18/20 13:34:34 - 0:03:10 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:34:34 - 0:03:10 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
2: INFO - 04/18/20 13:34:34 - 0:03:10 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
2: INFO - 04/18/20 13:34:34 - 0:03:10 - Removed 0 empty sentences.
2: 
2: INFO - 04/18/20 13:34:34 - 0:03:10 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
2: INFO - 04/18/20 13:34:34 - 0:03:10 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:34:34 - 0:03:11 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
3: INFO - 04/18/20 13:34:35 - 0:03:11 - Removed 2 too long sentences.
2: INFO - 04/18/20 13:34:35 - 0:03:11 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
2: INFO - 04/18/20 13:34:36 - 0:03:12 - Removed 0 empty sentences.
2: 
2: 
2: INFO - 04/18/20 13:34:36 - 0:03:12 - ============ Data summary
2: INFO - 04/18/20 13:34:36 - 0:03:12 - Parallel data      - train -        de-en:   3308331
2: INFO - 04/18/20 13:34:36 - 0:03:12 - Parallel data      - valid -        de-en:      5000
2: INFO - 04/18/20 13:34:36 - 0:03:12 - Parallel data      -  test -        de-en:      5000
2: 
2: INFO - 04/18/20 13:34:37 - 0:03:13 - Removed 0 empty sentences.
2: 
2: 
2: INFO - 04/18/20 13:34:37 - 0:03:13 - ============ Data summary
2: INFO - 04/18/20 13:34:37 - 0:03:13 - Parallel data      - train -        de-en:   3308331
2: INFO - 04/18/20 13:34:37 - 0:03:13 - Parallel data      - valid -        de-en:      5000
2: INFO - 04/18/20 13:34:37 - 0:03:13 - Parallel data      -  test -        de-en:      5000
2: 
3: INFO - 04/18/20 13:34:39 - 0:03:15 - Removed 2 too long sentences.
0: INFO - 04/18/20 13:34:40 - 0:03:16 - Removed 0 empty sentences.
3: 
3: INFO - 04/18/20 13:34:41 - 0:03:17 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
3: INFO - 04/18/20 13:34:41 - 0:03:17 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:34:41 - 0:03:18 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
3: INFO - 04/18/20 13:34:42 - 0:03:18 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:34:43 - 0:03:19 - Model: TransformerModel(
1:                                        (projector): Projector(
1:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
1:                                        )
1:                                        (regional_encodings): RegionalEncodings(
1:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
1:                                        )
1:                                        (position_embeddings): Embedding(512, 512)
1:                                        (lang_embeddings): Embedding(3, 512)
1:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
1:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        (attentions): ModuleList(
1:                                          (0): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (1): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (2): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (3): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (4): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (5): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                        )
1:                                        (layer_norm1): ModuleList(
1:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        )
1:                                        (ffns): ModuleList(
1:                                          (0): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (1): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (2): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (3): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (4): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (5): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                        )
1:                                        (layer_norm2): ModuleList(
1:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        )
1:                                        (memories): ModuleDict()
1:                                        (pred_layer): PredLayer(
1:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
1:                                        )
1:                                        (img_pred_layer): ImgPredLayer(
1:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
1:                                        )
1:                                      )
1: INFO - 04/18/20 13:34:43 - 0:03:19 - Number of parameters (model): 92180120
3: 
3: INFO - 04/18/20 13:34:44 - 0:03:21 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
3: INFO - 04/18/20 13:34:45 - 0:03:21 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:34:45 - 0:03:22 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
3: INFO - 04/18/20 13:34:46 - 0:03:22 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:34:47 - 0:03:23 - Model: TransformerModel(
3:                                        (projector): Projector(
3:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
3:                                        )
3:                                        (regional_encodings): RegionalEncodings(
3:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
3:                                        )
3:                                        (position_embeddings): Embedding(512, 512)
3:                                        (lang_embeddings): Embedding(3, 512)
3:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
3:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        (attentions): ModuleList(
3:                                          (0): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (1): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (2): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (3): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (4): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (5): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm1): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (ffns): ModuleList(
3:                                          (0): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (1): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (2): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (3): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (4): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (5): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm2): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (memories): ModuleDict()
3:                                        (pred_layer): PredLayer(
3:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
3:                                        )
3:                                        (img_pred_layer): ImgPredLayer(
3:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
3:                                        )
3:                                      )
3: INFO - 04/18/20 13:34:47 - 0:03:23 - Number of parameters (model): 92180120
1: INFO - 04/18/20 13:34:47 - 0:03:23 - Removed 2 too long sentences.
0: INFO - 04/18/20 13:34:49 - 0:03:25 - Removed 2 too long sentences.
2: INFO - 04/18/20 13:34:51 - 0:03:27 - Model: TransformerModel(
2:                                        (projector): Projector(
2:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
2:                                        )
2:                                        (regional_encodings): RegionalEncodings(
2:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
2:                                        )
2:                                        (position_embeddings): Embedding(512, 512)
2:                                        (lang_embeddings): Embedding(3, 512)
2:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
2:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        (attentions): ModuleList(
2:                                          (0): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (1): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (2): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (3): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (4): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (5): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                        )
2:                                        (layer_norm1): ModuleList(
2:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        )
2:                                        (ffns): ModuleList(
2:                                          (0): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (1): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (2): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (3): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (4): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (5): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                        )
2:                                        (layer_norm2): ModuleList(
2:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        )
2:                                        (memories): ModuleDict()
2:                                        (pred_layer): PredLayer(
2:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
2:                                        )
2:                                        (img_pred_layer): ImgPredLayer(
2:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
2:                                        )
2:                                      )
2: INFO - 04/18/20 13:34:51 - 0:03:27 - Number of parameters (model): 92180120
1: 
1: INFO - 04/18/20 13:34:53 - 0:03:29 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
2: INFO - 04/18/20 13:34:53 - 0:03:29 - Model: TransformerModel(
2:                                        (projector): Projector(
2:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
2:                                        )
2:                                        (regional_encodings): RegionalEncodings(
2:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
2:                                        )
2:                                        (position_embeddings): Embedding(512, 512)
2:                                        (lang_embeddings): Embedding(3, 512)
2:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
2:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        (attentions): ModuleList(
2:                                          (0): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (1): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (2): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (3): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (4): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (5): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                        )
2:                                        (layer_norm1): ModuleList(
2:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        )
2:                                        (ffns): ModuleList(
2:                                          (0): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (1): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (2): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (3): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (4): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (5): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                        )
2:                                        (layer_norm2): ModuleList(
2:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        )
2:                                        (memories): ModuleDict()
2:                                        (pred_layer): PredLayer(
2:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
2:                                        )
2:                                        (img_pred_layer): ImgPredLayer(
2:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
2:                                        )
2:                                      )
2: INFO - 04/18/20 13:34:53 - 0:03:29 - Number of parameters (model): 92180120
1: INFO - 04/18/20 13:34:54 - 0:03:30 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:34:54 - 0:03:30 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
0: 
0: INFO - 04/18/20 13:34:54 - 0:03:30 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
1: INFO - 04/18/20 13:34:54 - 0:03:30 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
0: INFO - 04/18/20 13:34:54 - 0:03:31 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:34:55 - 0:03:31 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
3: INFO - 04/18/20 13:34:55 - 0:03:31 - Removed 0 empty sentences.
3: 
3: INFO - 04/18/20 13:34:55 - 0:03:31 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
0: INFO - 04/18/20 13:34:55 - 0:03:31 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:34:55 - 0:03:32 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:34:56 - 0:03:32 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
3: INFO - 04/18/20 13:34:56 - 0:03:32 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
0: INFO - 04/18/20 13:34:56 - 0:03:32 - Removed 2 too long sentences.
3: INFO - 04/18/20 13:34:58 - 0:03:34 - Removed 0 empty sentences.
3: 
3: INFO - 04/18/20 13:34:58 - 0:03:34 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/18/20 13:34:59 - 0:03:35 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:34:59 - 0:03:35 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
3: INFO - 04/18/20 13:34:59 - 0:03:35 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
3: INFO - 04/18/20 13:35:00 - 0:03:37 - Removed 0 empty sentences.
3: 
3: 
3: INFO - 04/18/20 13:35:00 - 0:03:37 - ============ Data summary
3: INFO - 04/18/20 13:35:00 - 0:03:37 - Parallel data      - train -        de-en:   3308331
3: INFO - 04/18/20 13:35:00 - 0:03:37 - Parallel data      - valid -        de-en:      5000
3: INFO - 04/18/20 13:35:00 - 0:03:37 - Parallel data      -  test -        de-en:      5000
3: 
0: 
0: INFO - 04/18/20 13:35:02 - 0:03:38 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
0: INFO - 04/18/20 13:35:02 - 0:03:38 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:35:02 - 0:03:38 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
0: INFO - 04/18/20 13:35:03 - 0:03:39 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:35:03 - 0:03:39 - Removed 0 empty sentences.
3: 
3: 
3: INFO - 04/18/20 13:35:03 - 0:03:39 - ============ Data summary
3: INFO - 04/18/20 13:35:03 - 0:03:39 - Parallel data      - train -        de-en:   3308331
3: INFO - 04/18/20 13:35:03 - 0:03:39 - Parallel data      - valid -        de-en:      5000
3: INFO - 04/18/20 13:35:03 - 0:03:39 - Parallel data      -  test -        de-en:      5000
3: 
0: INFO - 04/18/20 13:35:06 - 0:03:42 - Removed 0 empty sentences.
0: 
0: INFO - 04/18/20 13:35:06 - 0:03:42 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/18/20 13:35:06 - 0:03:42 - Removed 0 empty sentences.
1: 
1: INFO - 04/18/20 13:35:06 - 0:03:42 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
0: INFO - 04/18/20 13:35:06 - 0:03:42 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:35:06 - 0:03:42 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:35:06 - 0:03:42 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/18/20 13:35:06 - 0:03:43 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
0: INFO - 04/18/20 13:35:07 - 0:03:43 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: INFO - 04/18/20 13:35:07 - 0:03:43 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
0: INFO - 04/18/20 13:35:10 - 0:03:46 - Removed 0 empty sentences.
0: 
0: 
0: INFO - 04/18/20 13:35:10 - 0:03:46 - ============ Data summary
0: INFO - 04/18/20 13:35:10 - 0:03:46 - Parallel data      - train -        de-en:   3308331
0: INFO - 04/18/20 13:35:10 - 0:03:46 - Parallel data      - valid -        de-en:      5000
0: INFO - 04/18/20 13:35:10 - 0:03:46 - Parallel data      -  test -        de-en:      5000
0: 
1: INFO - 04/18/20 13:35:10 - 0:03:46 - Removed 0 empty sentences.
1: 
1: 
1: INFO - 04/18/20 13:35:10 - 0:03:46 - ============ Data summary
1: INFO - 04/18/20 13:35:10 - 0:03:46 - Parallel data      - train -        de-en:   3308331
1: INFO - 04/18/20 13:35:10 - 0:03:46 - Parallel data      - valid -        de-en:      5000
1: INFO - 04/18/20 13:35:10 - 0:03:46 - Parallel data      -  test -        de-en:      5000
1: 
0: INFO - 04/18/20 13:35:11 - 0:03:48 - Removed 0 empty sentences.
0: 
0: INFO - 04/18/20 13:35:12 - 0:03:48 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
0: INFO - 04/18/20 13:35:12 - 0:03:48 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:35:12 - 0:03:48 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
0: INFO - 04/18/20 13:35:13 - 0:03:49 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
0: INFO - 04/18/20 13:35:16 - 0:03:52 - Removed 0 empty sentences.
0: 
0: 
0: INFO - 04/18/20 13:35:16 - 0:03:52 - ============ Data summary
0: INFO - 04/18/20 13:35:16 - 0:03:52 - Parallel data      - train -        de-en:   3308331
0: INFO - 04/18/20 13:35:16 - 0:03:52 - Parallel data      - valid -        de-en:      5000
0: INFO - 04/18/20 13:35:16 - 0:03:52 - Parallel data      -  test -        de-en:      5000
0: 
3: INFO - 04/18/20 13:35:18 - 0:03:54 - Model: TransformerModel(
3:                                        (projector): Projector(
3:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
3:                                        )
3:                                        (regional_encodings): RegionalEncodings(
3:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
3:                                        )
3:                                        (position_embeddings): Embedding(512, 512)
3:                                        (lang_embeddings): Embedding(3, 512)
3:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
3:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        (attentions): ModuleList(
3:                                          (0): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (1): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (2): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (3): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (4): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (5): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm1): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (ffns): ModuleList(
3:                                          (0): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (1): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (2): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (3): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (4): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (5): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm2): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (memories): ModuleDict()
3:                                        (pred_layer): PredLayer(
3:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
3:                                        )
3:                                        (img_pred_layer): ImgPredLayer(
3:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
3:                                        )
3:                                      )
3: INFO - 04/18/20 13:35:18 - 0:03:54 - Number of parameters (model): 92180120
3: INFO - 04/18/20 13:35:20 - 0:03:57 - Model: TransformerModel(
3:                                        (projector): Projector(
3:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
3:                                        )
3:                                        (regional_encodings): RegionalEncodings(
3:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
3:                                        )
3:                                        (position_embeddings): Embedding(512, 512)
3:                                        (lang_embeddings): Embedding(3, 512)
3:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
3:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        (attentions): ModuleList(
3:                                          (0): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (1): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (2): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (3): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (4): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (5): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm1): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (ffns): ModuleList(
3:                                          (0): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (1): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (2): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (3): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (4): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (5): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm2): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (memories): ModuleDict()
3:                                        (pred_layer): PredLayer(
3:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
3:                                        )
3:                                        (img_pred_layer): ImgPredLayer(
3:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
3:                                        )
3:                                      )
3: INFO - 04/18/20 13:35:20 - 0:03:57 - Number of parameters (model): 92180120
0: INFO - 04/18/20 13:35:28 - 0:04:04 - Model: TransformerModel(
0:                                        (projector): Projector(
0:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
0:                                        )
0:                                        (regional_encodings): RegionalEncodings(
0:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
0:                                        )
0:                                        (position_embeddings): Embedding(512, 512)
0:                                        (lang_embeddings): Embedding(3, 512)
0:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
0:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        (attentions): ModuleList(
0:                                          (0): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (1): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (2): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (3): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (4): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (5): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                        )
0:                                        (layer_norm1): ModuleList(
0:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        )
0:                                        (ffns): ModuleList(
0:                                          (0): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (1): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (2): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (3): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (4): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (5): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                        )
0:                                        (layer_norm2): ModuleList(
0:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        )
0:                                        (memories): ModuleDict()
0:                                        (pred_layer): PredLayer(
0:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
0:                                        )
0:                                        (img_pred_layer): ImgPredLayer(
0:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
0:                                        )
0:                                      )
0: INFO - 04/18/20 13:35:28 - 0:04:04 - Number of parameters (model): 92180120
1: INFO - 04/18/20 13:35:29 - 0:04:06 - Model: TransformerModel(
1:                                        (projector): Projector(
1:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
1:                                        )
1:                                        (regional_encodings): RegionalEncodings(
1:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
1:                                        )
1:                                        (position_embeddings): Embedding(512, 512)
1:                                        (lang_embeddings): Embedding(3, 512)
1:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
1:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        (attentions): ModuleList(
1:                                          (0): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (1): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (2): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (3): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (4): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (5): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                        )
1:                                        (layer_norm1): ModuleList(
1:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        )
1:                                        (ffns): ModuleList(
1:                                          (0): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (1): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (2): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (3): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (4): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (5): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                        )
1:                                        (layer_norm2): ModuleList(
1:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        )
1:                                        (memories): ModuleDict()
1:                                        (pred_layer): PredLayer(
1:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
1:                                        )
1:                                        (img_pred_layer): ImgPredLayer(
1:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
1:                                        )
1:                                      )
1: INFO - 04/18/20 13:35:29 - 0:04:06 - Number of parameters (model): 92180120
0: INFO - 04/18/20 13:35:37 - 0:04:13 - Model: TransformerModel(
0:                                        (projector): Projector(
0:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
0:                                        )
0:                                        (regional_encodings): RegionalEncodings(
0:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
0:                                        )
0:                                        (position_embeddings): Embedding(512, 512)
0:                                        (lang_embeddings): Embedding(3, 512)
0:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
0:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        (attentions): ModuleList(
0:                                          (0): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (1): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (2): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (3): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (4): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (5): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                        )
0:                                        (layer_norm1): ModuleList(
0:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        )
0:                                        (ffns): ModuleList(
0:                                          (0): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (1): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (2): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (3): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (4): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (5): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                        )
0:                                        (layer_norm2): ModuleList(
0:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        )
0:                                        (memories): ModuleDict()
0:                                        (pred_layer): PredLayer(
0:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
0:                                        )
0:                                        (img_pred_layer): ImgPredLayer(
0:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
0:                                        )
0:                                      )
0: INFO - 04/18/20 13:35:37 - 0:04:13 - Number of parameters (model): 92180120
1: INFO - 04/18/20 13:36:03 - 0:04:39 - Found 0 memories.
1: INFO - 04/18/20 13:36:03 - 0:04:39 - Found 6 FFN.
1: INFO - 04/18/20 13:36:03 - 0:04:39 - Found 108 parameters in model.
1: INFO - 04/18/20 13:36:03 - 0:04:39 - Using nn.parallel.DistributedDataParallel ...
3: INFO - 04/18/20 13:36:07 - 0:04:43 - Found 0 memories.
3: INFO - 04/18/20 13:36:07 - 0:04:43 - Found 6 FFN.
3: INFO - 04/18/20 13:36:07 - 0:04:43 - Found 108 parameters in model.
3: INFO - 04/18/20 13:36:07 - 0:04:43 - Using nn.parallel.DistributedDataParallel ...
2: INFO - 04/18/20 13:36:13 - 0:04:49 - Found 0 memories.
2: INFO - 04/18/20 13:36:13 - 0:04:49 - Found 6 FFN.
2: INFO - 04/18/20 13:36:13 - 0:04:49 - Found 108 parameters in model.
2: INFO - 04/18/20 13:36:13 - 0:04:49 - Using nn.parallel.DistributedDataParallel ...
2: INFO - 04/18/20 13:36:15 - 0:04:51 - Found 0 memories.
2: INFO - 04/18/20 13:36:15 - 0:04:51 - Found 6 FFN.
2: INFO - 04/18/20 13:36:15 - 0:04:51 - Found 108 parameters in model.
2: INFO - 04/18/20 13:36:15 - 0:04:51 - Using nn.parallel.DistributedDataParallel ...
3: INFO - 04/18/20 13:36:46 - 0:05:22 - Found 0 memories.
3: INFO - 04/18/20 13:36:46 - 0:05:22 - Found 6 FFN.
3: INFO - 04/18/20 13:36:46 - 0:05:22 - Found 108 parameters in model.
3: INFO - 04/18/20 13:36:46 - 0:05:22 - Using nn.parallel.DistributedDataParallel ...
3: INFO - 04/18/20 13:36:47 - 0:05:23 - Found 0 memories.
3: INFO - 04/18/20 13:36:47 - 0:05:23 - Found 6 FFN.
3: INFO - 04/18/20 13:36:47 - 0:05:23 - Found 108 parameters in model.
3: INFO - 04/18/20 13:36:47 - 0:05:23 - Using nn.parallel.DistributedDataParallel ...
3: INFO - 04/18/20 13:36:48 - 0:05:24 - Using nn.parallel.DistributedDataParallel ...
2: INFO - 04/18/20 13:36:48 - 0:05:24 - Using nn.parallel.DistributedDataParallel ...
3: INFO - 04/18/20 13:36:48 - 0:05:24 - Using nn.parallel.DistributedDataParallel ...
2: INFO - 04/18/20 13:36:48 - 0:05:24 - Optimizers: model
3: INFO - 04/18/20 13:36:48 - 0:05:24 - Optimizers: model
3: INFO - 04/18/20 13:36:48 - 0:05:25 - ============ Starting epoch 0 ... ============
2: INFO - 04/18/20 13:36:48 - 0:05:24 - ============ Starting epoch 0 ... ============
2: INFO - 04/18/20 13:36:48 - 0:05:25 - Creating new training data iterator (pred,en,de) ...
3: INFO - 04/18/20 13:36:48 - 0:05:25 - Creating new training data iterator (pred,en,de) ...
3: INFO - 04/18/20 13:36:48 - 0:05:25 - Optimizers: model
1: INFO - 04/18/20 13:36:59 - 0:05:35 - Found 0 memories.
1: INFO - 04/18/20 13:36:59 - 0:05:35 - Found 6 FFN.
1: INFO - 04/18/20 13:36:59 - 0:05:35 - Found 108 parameters in model.
1: INFO - 04/18/20 13:36:59 - 0:05:35 - Using nn.parallel.DistributedDataParallel ...
0: INFO - 04/18/20 13:37:03 - 0:05:39 - Found 0 memories.
0: INFO - 04/18/20 13:37:03 - 0:05:39 - Found 6 FFN.
0: INFO - 04/18/20 13:37:03 - 0:05:39 - Found 108 parameters in model.
0: INFO - 04/18/20 13:37:03 - 0:05:39 - Using nn.parallel.DistributedDataParallel ...
0: INFO - 04/18/20 13:37:08 - 0:05:44 - Found 0 memories.
0: INFO - 04/18/20 13:37:08 - 0:05:44 - Found 6 FFN.
0: INFO - 04/18/20 13:37:08 - 0:05:44 - Found 108 parameters in model.
0: INFO - 04/18/20 13:37:08 - 0:05:44 - Using nn.parallel.DistributedDataParallel ...
1: Traceback (most recent call last):
1:   File "train.py", line 348, in <module>
1:     main(params)
1:   File "train.py", line 251, in main
1:     trainer = SingleTrainer(model, data, params)
1:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
1:     super().__init__(data, params)
1:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 67, in __init__
1:     setattr(self, name, nn.parallel.DistributedDataParallel(getattr(self, name), device_ids=[params.local_rank], output_device=params.local_rank, broadcast_buffers=True))
1:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 303, in __init__
3: Traceback (most recent call last):
3:   File "train.py", line 348, in <module>
1:     self.broadcast_bucket_size)
1:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 485, in _distributed_broadcast_coalesced
3:     main(params)
3:   File "train.py", line 251, in main
1:     dist._broadcast_coalesced(self.process_group, tensors, buffer_size)
3:     trainer = SingleTrainer(model, data, params)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
1: RuntimeError: NCCL error in: /pytorch/torch/lib/c10d/ProcessGroupNCCL.cpp:410, unhandled system error, NCCL version 2.4.8
3:     super().__init__(data, params)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 67, in __init__
3:     setattr(self, name, nn.parallel.DistributedDataParallel(getattr(self, name), device_ids=[params.local_rank], output_device=params.local_rank, broadcast_buffers=True))
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 303, in __init__
3:     self.broadcast_bucket_size)
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 485, in _distributed_broadcast_coalesced
3:     dist._broadcast_coalesced(self.process_group, tensors, buffer_size)
3: RuntimeError: NCCL error in: /pytorch/torch/lib/c10d/ProcessGroupNCCL.cpp:410, unhandled system error, NCCL version 2.4.8
3: Traceback (most recent call last):
3:   File "train.py", line 348, in <module>
3:     main(params)
3:   File "train.py", line 289, in main
3:     trainer.mlm_step(lang1, lang2, params.lambda_mlm, iter)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 840, in mlm_step
3:     tensor = model('fwd', x=x, lengths=lengths, positions=positions, langs=langs, causal=False)
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
3:     result = self.forward(*input, **kwargs)
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 464, in forward
3:     self.reducer.prepare_for_backward([])
3: RuntimeError: Expected to have finished reduction in the prior iteration before starting a new one. This error indicates that your module has parameters that were not used in producing loss. You can enable unused parameter detection by (1) passing the keyword argument `find_unused_parameters=True` to `torch.nn.parallel.DistributedDataParallel`; (2) making sure all `forward` function outputs participate in calculating loss. If you already have done the above two steps, then the distributed data parallel module wasn't able to locate the output tensors in the return value of your module's `forward` function. Please include the loss function and the structure of the return value of `forward` of your module when reporting this issue (e.g. list, dict, iterable). (prepare_for_backward at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:514)
3: frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x33 (0x7f5543269193 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libc10.so)
3: frame #1: c10d::Reducer::prepare_for_backward(std::vector<at::Tensor, std::allocator<at::Tensor> > const&) + 0x731 (0x7f5585839471 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
3: frame #2: <unknown function> + 0xa0e63a (0x7f558582563a in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
3: frame #3: <unknown function> + 0x2956c4 (0x7f55850ac6c4 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
3: <omitting python frames>
3: frame #35: main + 0x119 (0x400a99 in /home/menekse/virtualenvs/torch_env/bin/python)
3: frame #36: __libc_start_main + 0xf5 (0x7f55961fc3d5 in /lib64/libc.so.6)
3: frame #37: /home/menekse/virtualenvs/torch_env/bin/python() [0x400c20]
3: 
2: Traceback (most recent call last):
2:   File "train.py", line 348, in <module>
2:     main(params)
2:   File "train.py", line 289, in main
2:     trainer.mlm_step(lang1, lang2, params.lambda_mlm, iter)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 840, in mlm_step
2:     tensor = model('fwd', x=x, lengths=lengths, positions=positions, langs=langs, causal=False)
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
2:     result = self.forward(*input, **kwargs)
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 464, in forward
2: Traceback (most recent call last):
2:   File "train.py", line 348, in <module>
2:     self.reducer.prepare_for_backward([])
2: RuntimeError: Expected to have finished reduction in the prior iteration before starting a new one. This error indicates that your module has parameters that were not used in producing loss. You can enable unused parameter detection by (1) passing the keyword argument `find_unused_parameters=True` to `torch.nn.parallel.DistributedDataParallel`; (2) making sure all `forward` function outputs participate in calculating loss. If you already have done the above two steps, then the distributed data parallel module wasn't able to locate the output tensors in the return value of your module's `forward` function. Please include the loss function and the structure of the return value of `forward` of your module when reporting this issue (e.g. list, dict, iterable). (prepare_for_backward at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:514)
2: frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x33 (0x7f1d2ad58193 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libc10.so)
2: frame #1: c10d::Reducer::prepare_for_backward(std::vector<at::Tensor, std::allocator<at::Tensor> > const&) + 0x731 (0x7f1d6d328471 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
2: frame #2: <unknown function> + 0xa0e63a (0x7f1d6d31463a in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
2: frame #3: <unknown function> + 0x2956c4 (0x7f1d6cb9b6c4 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
2: <omitting python frames>
2: frame #35: main + 0x119 (0x400a99 in /home/menekse/virtualenvs/torch_env/bin/python)
2: frame #36: __libc_start_main + 0xf5 (0x7f1d7dceb3d5 in /lib64/libc.so.6)
2: frame #37: /home/menekse/virtualenvs/torch_env/bin/python() [0x400c20]
2: 
2:     main(params)
2:   File "train.py", line 251, in main
2:     trainer = SingleTrainer(model, data, params)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
2:     super().__init__(data, params)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 67, in __init__
2:     setattr(self, name, nn.parallel.DistributedDataParallel(getattr(self, name), device_ids=[params.local_rank], output_device=params.local_rank, broadcast_buffers=True))
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 303, in __init__
2:     self.broadcast_bucket_size)
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 485, in _distributed_broadcast_coalesced
2:     dist._broadcast_coalesced(self.process_group, tensors, buffer_size)
2: RuntimeError: NCCL error in: /pytorch/torch/lib/c10d/ProcessGroupNCCL.cpp:410, unhandled system error, NCCL version 2.4.8
3: INFO - 04/18/20 13:37:26 - 0:06:02 - ============ Starting epoch 0 ... ============
3: INFO - 04/18/20 13:37:26 - 0:06:02 - Creating new training data iterator (pred,en,de) ...
1: Traceback (most recent call last):
1:   File "train.py", line 348, in <module>
1:     main(params)
1:   File "train.py", line 251, in main
1:     trainer = SingleTrainer(model, data, params)
1:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
1:     super().__init__(data, params)
1:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 67, in __init__
1:     setattr(self, name, nn.parallel.DistributedDataParallel(getattr(self, name), device_ids=[params.local_rank], output_device=params.local_rank, broadcast_buffers=True))
1:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 303, in __init__
1:     self.broadcast_bucket_size)
1:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 485, in _distributed_broadcast_coalesced
1:     dist._broadcast_coalesced(self.process_group, tensors, buffer_size)
1: RuntimeError: NCCL error in: /pytorch/torch/lib/c10d/ProcessGroupNCCL.cpp:410, unhandled system error, NCCL version 2.4.8
0: Traceback (most recent call last):
0:   File "train.py", line 348, in <module>
0:     main(params)
0:   File "train.py", line 251, in main
0:     trainer = SingleTrainer(model, data, params)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
0:     super().__init__(data, params)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 67, in __init__
0:     setattr(self, name, nn.parallel.DistributedDataParallel(getattr(self, name), device_ids=[params.local_rank], output_device=params.local_rank, broadcast_buffers=True))
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 303, in __init__
0:     self.broadcast_bucket_size)
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 485, in _distributed_broadcast_coalesced
0:     dist._broadcast_coalesced(self.process_group, tensors, buffer_size)
0: RuntimeError: NCCL error in: /pytorch/torch/lib/c10d/ProcessGroupNCCL.cpp:410, unhandled system error, NCCL version 2.4.8
0: Traceback (most recent call last):
0:   File "train.py", line 348, in <module>
0:     main(params)
0:   File "train.py", line 251, in main
0:     trainer = SingleTrainer(model, data, params)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
0:     super().__init__(data, params)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 67, in __init__
0:     setattr(self, name, nn.parallel.DistributedDataParallel(getattr(self, name), device_ids=[params.local_rank], output_device=params.local_rank, broadcast_buffers=True))
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 303, in __init__
0:     self.broadcast_bucket_size)
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 485, in _distributed_broadcast_coalesced
0:     dist._broadcast_coalesced(self.process_group, tensors, buffer_size)
0: RuntimeError: NCCL error in: /pytorch/torch/lib/c10d/ProcessGroupNCCL.cpp:410, unhandled system error, NCCL version 2.4.8
3: Traceback (most recent call last):
3:   File "train.py", line 348, in <module>
3:     main(params)
3:   File "train.py", line 289, in main
3:     trainer.mlm_step(lang1, lang2, params.lambda_mlm, iter)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 840, in mlm_step
3:     tensor = model('fwd', x=x, lengths=lengths, positions=positions, langs=langs, causal=False)
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
3:     result = self.forward(*input, **kwargs)
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 464, in forward
3:     self.reducer.prepare_for_backward([])
3: RuntimeError: Expected to have finished reduction in the prior iteration before starting a new one. This error indicates that your module has parameters that were not used in producing loss. You can enable unused parameter detection by (1) passing the keyword argument `find_unused_parameters=True` to `torch.nn.parallel.DistributedDataParallel`; (2) making sure all `forward` function outputs participate in calculating loss. If you already have done the above two steps, then the distributed data parallel module wasn't able to locate the output tensors in the return value of your module's `forward` function. Please include the loss function and the structure of the return value of `forward` of your module when reporting this issue (e.g. list, dict, iterable). (prepare_for_backward at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:514)
3: frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x33 (0x7f3ac957e193 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libc10.so)
3: frame #1: c10d::Reducer::prepare_for_backward(std::vector<at::Tensor, std::allocator<at::Tensor> > const&) + 0x731 (0x7f3b0bb4e471 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
3: frame #2: <unknown function> + 0xa0e63a (0x7f3b0bb3a63a in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
3: frame #3: <unknown function> + 0x2956c4 (0x7f3b0b3c16c4 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
3: <omitting python frames>
3: frame #35: main + 0x119 (0x400a99 in /home/menekse/virtualenvs/torch_env/bin/python)
3: frame #36: __libc_start_main + 0xf5 (0x7f3b1c5113d5 in /lib64/libc.so.6)
3: frame #37: /home/menekse/virtualenvs/torch_env/bin/python() [0x400c20]
3: 
3: Traceback (most recent call last):
3:   File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
3:     "__main__", mod_spec)
3:   File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
3:     exec(code, run_globals)
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 263, in <module>
3:     main()
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 259, in main
3:     cmd=cmd)
3: subprocess.CalledProcessError: Command '['/home/menekse/virtualenvs/torch_env/bin/python', '-u', 'train.py', '--local_rank=2', '--exp_name', 'xlm_en_de_tlm', '--dump_path', './dumped', '--data_path', '/data/shared/ConceptualCaptions/XLM_data/50k', '--lgs', 'en-de', '--clm_steps', '', '--mlm_steps', 'en-de', '--emb_dim', '512', '--n_layers', '6', '--n_heads', '8', '--dropout', '0.1', '--attention_dropout', '0.1', '--gelu_activation', 'true', '--batch_size', '64', '--bptt', '256', '--optimizer', 'adam,lr=0.0001', '--epoch_size', '300000', '--max_epoch', '100000', '--validation_metrics', 'valid_en_de_mlm_ppl', '--stopping_criterion', '_valid_mlm_ppl,25', '--fp16', 'false', '--image_names', '/data/shared/ConceptualCaptions/XLM_data/50k']' returned non-zero exit status 1.
srun: error: hanabi: task 3: Exited with exit code 1
