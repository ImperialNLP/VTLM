/var/spool/slurm/d/job03081/slurm_script: line 15: {workdir}/3081.stdout: No such file or directory
/var/spool/slurm/d/job03081/slurm_script: line 16: {workdir}/3081.stdout: No such file or directory
/var/spool/slurm/d/job03081/slurm_script: line 17: {workdir}/3081.stdout: No such file or directory
/var/spool/slurm/d/job03081/slurm_script: line 18: {workdir}/3081.stdout: No such file or directory
/var/spool/slurm/d/job03081/slurm_script: line 19: {workdir}/3081.stdout: No such file or directory
/var/spool/slurm/d/job03081/slurm_script: line 20: {workdir}/3081.stdout: No such file or directory
3: FAISS library was not found.
3: FAISS not available. Switching to standard nearest neighbors search implementation.
0: FAISS library was not found.
0: FAISS not available. Switching to standard nearest neighbors search implementation.
3: FAISS library was not found.
3: FAISS not available. Switching to standard nearest neighbors search implementation.
0: FAISS library was not found.
0: FAISS not available. Switching to standard nearest neighbors search implementation.
2: FAISS library was not found.
2: FAISS not available. Switching to standard nearest neighbors search implementation.
0: FAISS library was not found.
0: FAISS not available. Switching to standard nearest neighbors search implementation.
1: FAISS library was not found.
1: FAISS not available. Switching to standard nearest neighbors search implementation.
1: FAISS library was not found.
1: FAISS not available. Switching to standard nearest neighbors search implementation.
2: FAISS library was not found.
2: FAISS not available. Switching to standard nearest neighbors search implementation.
1: FAISS library was not found.
1: FAISS not available. Switching to standard nearest neighbors search implementation.
2: FAISS library was not found.
2: FAISS not available. Switching to standard nearest neighbors search implementation.
3: FAISS library was not found.
3: FAISS not available. Switching to standard nearest neighbors search implementation.
2: Traceback (most recent call last):
2:   File "train.py", line 348, in <module>
2:     main(params)
2:   File "train.py", line 230, in main
2:     init_distributed_mode(params)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/slurm.py", line 171, in init_distributed_mode
2:     backend='nccl',
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py", line 397, in init_process_group
2:     store, rank, world_size = next(rendezvous_iterator)
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/rendezvous.py", line 168, in _env_rendezvous_handler
2:     store = TCPStore(master_addr, master_port, world_size, start_daemon)
2: RuntimeError: Address already in use
0: INFO - 04/18/20 13:22:45 - 0:00:00 - ============ Initialized logger ============
0: INFO - 04/18/20 13:22:45 - 0:00:00 - accumulate_gradients: 1
0:                                      ae_steps: []
0:                                      amp: -1
0:                                      asm: False
0:                                      attention_dropout: 0.1
0:                                      batch_size: 64
0:                                      beam_size: 1
0:                                      bptt: 256
0:                                      bt_src_langs: []
0:                                      bt_steps: []
0:                                      clip_grad_norm: 5
0:                                      clm_steps: []
0:                                      command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3081"
0:                                      context_size: 0
0:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
0:                                      debug: False
0:                                      debug_slurm: False
0:                                      debug_train: False
0:                                      dropout: 0.1
0:                                      dump_path: ./dumped/xlm_en_de_tlm/3081
0:                                      early_stopping: False
0:                                      emb_dim: 512
0:                                      encoder_only: True
0:                                      epoch_size: 300000
0:                                      eval_bleu: False
0:                                      eval_only: False
0:                                      exp_id: 3081
0:                                      exp_name: xlm_en_de_tlm
0:                                      fp16: False
0:                                      gelu_activation: True
0:                                      global_rank: 1
0:                                      group_by_size: True
0:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
0:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
0:                                      is_master: False
0:                                      is_slurm_job: False
0:                                      lambda_ae: 1
0:                                      lambda_bt: 1
0:                                      lambda_clm: 1
0:                                      lambda_mlm: 1
0:                                      lambda_mt: 1
0:                                      lambda_pc: 1
0:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
0:                                      langs: ['en', 'de', 'img']
0:                                      length_penalty: 1
0:                                      lg_sampling_factor: -1
0:                                      lgs: en-de
0:                                      local_rank: 1
0:                                      master_port: -1
0:                                      max_batch_size: 0
0:                                      max_epoch: 100000
0:                                      max_len: 100
0:                                      max_vocab: -1
0:                                      min_count: 0
0:                                      mlm_steps: [('en', 'de')]
0:                                      mono_dataset: {}
0:                                      mt_steps: []
0:                                      multi_gpu: True
0:                                      multi_node: False
0:                                      n_gpu_per_node: 3
0:                                      n_heads: 8
0:                                      n_langs: 3
0:                                      n_layers: 6
0:                                      n_nodes: 1
0:                                      node_id: 0
0:                                      only_vlm: False
0:                                      optimizer: adam,lr=0.0001
0:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
0:                                      pc_steps: []
0:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
0:                                      reload_checkpoint: 
0:                                      reload_emb: 
0:                                      reload_model: 
0:                                      sample_alpha: 0
0:                                      save_periodic: 0
0:                                      share_inout_emb: True
0:                                      sinusoidal_embeddings: False
0:                                      split_data: False
0:                                      stopping_criterion: _valid_mlm_ppl,25
0:                                      tokens_per_batch: -1
0:                                      use_lang_emb: True
0:                                      use_memory: False
0:                                      validation_metrics: valid_en_de_mlm_ppl
0:                                      vlm_steps: [('en', 'de')]
0:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
0:                                      word_blank: 0
0:                                      word_dropout: 0
0:                                      word_keep: 0.1
0:                                      word_mask: 0.8
0:                                      word_mask_keep_rand: 0.8,0.1,0.1
0:                                      word_pred: 0.15
0:                                      word_rand: 0.1
0:                                      word_shuffle: 0
0:                                      world_size: 3
0: INFO - 04/18/20 13:22:45 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3081
0:                                      
0: INFO - 04/18/20 13:22:45 - 0:00:00 - Running command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
0: 
0: WARNING - 04/18/20 13:22:45 - 0:00:00 - Signal handler installed.
0: 
0: INFO - 04/18/20 13:22:45 - 0:00:00 - ============ Parallel data (de-en)
0: INFO - 04/18/20 13:22:45 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
2: Traceback (most recent call last):
2:   File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
2:     "__main__", mod_spec)
2:   File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
2:     exec(code, run_globals)
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 263, in <module>
2:     main()
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 259, in main
2:     cmd=cmd)
2: subprocess.CalledProcessError: Command '['/home/menekse/virtualenvs/torch_env/bin/python', '-u', 'train.py', '--local_rank=2', '--exp_name', 'xlm_en_de_tlm', '--dump_path', './dumped', '--data_path', '/data/shared/ConceptualCaptions/XLM_data/50k', '--lgs', 'en-de', '--clm_steps', '', '--mlm_steps', 'en-de', '--emb_dim', '512', '--n_layers', '6', '--n_heads', '8', '--dropout', '0.1', '--attention_dropout', '0.1', '--gelu_activation', 'true', '--batch_size', '64', '--bptt', '256', '--optimizer', 'adam,lr=0.0001', '--epoch_size', '300000', '--max_epoch', '100000', '--validation_metrics', 'valid_en_de_mlm_ppl', '--stopping_criterion', '_valid_mlm_ppl,25', '--fp16', 'false', '--image_names', '/data/shared/ConceptualCaptions/XLM_data/50k']' returned non-zero exit status 1.
1: Traceback (most recent call last):
1:   File "train.py", line 348, in <module>
1:     main(params)
1:   File "train.py", line 230, in main
1:     init_distributed_mode(params)
1:   File "/home/menekse/xlm/Animal/XLM-master/src/slurm.py", line 171, in init_distributed_mode
2: INFO - 04/18/20 13:22:45 - 0:00:00 - ============ Initialized logger ============
3: INFO - 04/18/20 13:22:45 - 0:00:00 - ============ Initialized logger ============
1:     backend='nccl',
1:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py", line 397, in init_process_group
2: INFO - 04/18/20 13:22:45 - 0:00:00 - accumulate_gradients: 1
2:                                      ae_steps: []
2:                                      amp: -1
2:                                      asm: False
2:                                      attention_dropout: 0.1
2:                                      batch_size: 64
2:                                      beam_size: 1
2:                                      bptt: 256
2:                                      bt_src_langs: []
2:                                      bt_steps: []
2:                                      clip_grad_norm: 5
2:                                      clm_steps: []
2:                                      command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3081"
2:                                      context_size: 0
2:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
2:                                      debug: False
2:                                      debug_slurm: False
2:                                      debug_train: False
2:                                      dropout: 0.1
2:                                      dump_path: ./dumped/xlm_en_de_tlm/3081
2:                                      early_stopping: False
2:                                      emb_dim: 512
2:                                      encoder_only: True
2:                                      epoch_size: 300000
2:                                      eval_bleu: False
2:                                      eval_only: False
2:                                      exp_id: 3081
2:                                      exp_name: xlm_en_de_tlm
2:                                      fp16: False
2:                                      gelu_activation: True
2:                                      global_rank: 1
2:                                      group_by_size: True
2:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
2:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
2:                                      is_master: False
2:                                      is_slurm_job: False
2:                                      lambda_ae: 1
2:                                      lambda_bt: 1
2:                                      lambda_clm: 1
2:                                      lambda_mlm: 1
2:                                      lambda_mt: 1
2:                                      lambda_pc: 1
2:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
2:                                      langs: ['en', 'de', 'img']
2:                                      length_penalty: 1
2:                                      lg_sampling_factor: -1
2:                                      lgs: en-de
2:                                      local_rank: 1
2:                                      master_port: -1
2:                                      max_batch_size: 0
2:                                      max_epoch: 100000
2:                                      max_len: 100
2:                                      max_vocab: -1
2:                                      min_count: 0
2:                                      mlm_steps: [('en', 'de')]
2:                                      mono_dataset: {}
2:                                      mt_steps: []
2:                                      multi_gpu: True
2:                                      multi_node: False
2:                                      n_gpu_per_node: 3
2:                                      n_heads: 8
2:                                      n_langs: 3
2:                                      n_layers: 6
2:                                      n_nodes: 1
2:                                      node_id: 0
2:                                      only_vlm: False
2:                                      optimizer: adam,lr=0.0001
2:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
2:                                      pc_steps: []
2:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
2:                                      reload_checkpoint: 
2:                                      reload_emb: 
2:                                      reload_model: 
2:                                      sample_alpha: 0
2:                                      save_periodic: 0
2:                                      share_inout_emb: True
2:                                      sinusoidal_embeddings: False
2:                                      split_data: False
2:                                      stopping_criterion: _valid_mlm_ppl,25
2:                                      tokens_per_batch: -1
2:                                      use_lang_emb: True
2:                                      use_memory: False
2:                                      validation_metrics: valid_en_de_mlm_ppl
2:                                      vlm_steps: [('en', 'de')]
2:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
2:                                      word_blank: 0
2:                                      word_dropout: 0
2:                                      word_keep: 0.1
2:                                      word_mask: 0.8
2:                                      word_mask_keep_rand: 0.8,0.1,0.1
2:                                      word_pred: 0.15
2:                                      word_rand: 0.1
2:                                      word_shuffle: 0
2:                                      world_size: 3
2: INFO - 04/18/20 13:22:45 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3081
2:                                      
3: INFO - 04/18/20 13:22:45 - 0:00:00 - accumulate_gradients: 1
3:                                      ae_steps: []
3:                                      amp: -1
3:                                      asm: False
3:                                      attention_dropout: 0.1
3:                                      batch_size: 64
3:                                      beam_size: 1
3:                                      bptt: 256
3:                                      bt_src_langs: []
3:                                      bt_steps: []
3:                                      clip_grad_norm: 5
3:                                      clm_steps: []
3:                                      command: python train.py --local_rank=0 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3081"
3:                                      context_size: 0
3:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      debug: False
3:                                      debug_slurm: False
3:                                      debug_train: False
3:                                      dropout: 0.1
3:                                      dump_path: ./dumped/xlm_en_de_tlm/3081
3:                                      early_stopping: False
3:                                      emb_dim: 512
3:                                      encoder_only: True
3:                                      epoch_size: 300000
3:                                      eval_bleu: False
3:                                      eval_only: False
3:                                      exp_id: 3081
3:                                      exp_name: xlm_en_de_tlm
3:                                      fp16: False
3:                                      gelu_activation: True
3:                                      global_rank: 0
3:                                      group_by_size: True
3:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
3:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      is_master: True
3:                                      is_slurm_job: False
3:                                      lambda_ae: 1
3:                                      lambda_bt: 1
3:                                      lambda_clm: 1
3:                                      lambda_mlm: 1
3:                                      lambda_mt: 1
3:                                      lambda_pc: 1
3:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
3:                                      langs: ['en', 'de', 'img']
3:                                      length_penalty: 1
3:                                      lg_sampling_factor: -1
3:                                      lgs: en-de
3:                                      local_rank: 0
3:                                      master_port: -1
3:                                      max_batch_size: 0
3:                                      max_epoch: 100000
3:                                      max_len: 100
3:                                      max_vocab: -1
3:                                      min_count: 0
3:                                      mlm_steps: [('en', 'de')]
3:                                      mono_dataset: {}
3:                                      mt_steps: []
3:                                      multi_gpu: True
3:                                      multi_node: False
3:                                      n_gpu_per_node: 3
3:                                      n_heads: 8
3:                                      n_langs: 3
3:                                      n_layers: 6
3:                                      n_nodes: 1
2: INFO - 04/18/20 13:22:45 - 0:00:00 - Running command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
2: 
3:                                      node_id: 0
3:                                      only_vlm: False
3:                                      optimizer: adam,lr=0.0001
3:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      pc_steps: []
3:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
3:                                      reload_checkpoint: 
3:                                      reload_emb: 
3:                                      reload_model: 
3:                                      sample_alpha: 0
3:                                      save_periodic: 0
3:                                      share_inout_emb: True
3:                                      sinusoidal_embeddings: False
3:                                      split_data: False
3:                                      stopping_criterion: _valid_mlm_ppl,25
3:                                      tokens_per_batch: -1
3:                                      use_lang_emb: True
3:                                      use_memory: False
3:                                      validation_metrics: valid_en_de_mlm_ppl
3:                                      vlm_steps: [('en', 'de')]
3:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      word_blank: 0
3:                                      word_dropout: 0
3:                                      word_keep: 0.1
3:                                      word_mask: 0.8
3:                                      word_mask_keep_rand: 0.8,0.1,0.1
3:                                      word_pred: 0.15
3:                                      word_rand: 0.1
3:                                      word_shuffle: 0
3:                                      world_size: 3
3: INFO - 04/18/20 13:22:45 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3081
3:                                      
3: INFO - 04/18/20 13:22:45 - 0:00:00 - Running command: python train.py --local_rank=0 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
2: WARNING - 04/18/20 13:22:45 - 0:00:00 - Signal handler installed.
3: 
1:     store, rank, world_size = next(rendezvous_iterator)
1:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/rendezvous.py", line 168, in _env_rendezvous_handler
2: 
3: WARNING - 04/18/20 13:22:45 - 0:00:00 - Signal handler installed.
2: INFO - 04/18/20 13:22:45 - 0:00:00 - ============ Parallel data (de-en)
3: 
2: INFO - 04/18/20 13:22:45 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: INFO - 04/18/20 13:22:45 - 0:00:00 - ============ Parallel data (de-en)
3: INFO - 04/18/20 13:22:45 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
1:     store = TCPStore(master_addr, master_port, world_size, start_daemon)
1: RuntimeError: Address already in use
2: INFO - 04/18/20 13:22:45 - 0:00:00 - ============ Initialized logger ============
2: INFO - 04/18/20 13:22:45 - 0:00:00 - accumulate_gradients: 1
2:                                      ae_steps: []
2:                                      amp: -1
2:                                      asm: False
2:                                      attention_dropout: 0.1
2:                                      batch_size: 64
2:                                      beam_size: 1
2:                                      bptt: 256
2:                                      bt_src_langs: []
2:                                      bt_steps: []
2:                                      clip_grad_norm: 5
2:                                      clm_steps: []
2:                                      command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3081"
2:                                      context_size: 0
2:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
2:                                      debug: False
2:                                      debug_slurm: False
2:                                      debug_train: False
2:                                      dropout: 0.1
2:                                      dump_path: ./dumped/xlm_en_de_tlm/3081
2:                                      early_stopping: False
2:                                      emb_dim: 512
2:                                      encoder_only: True
2:                                      epoch_size: 300000
2:                                      eval_bleu: False
2:                                      eval_only: False
2:                                      exp_id: 3081
2:                                      exp_name: xlm_en_de_tlm
2:                                      fp16: False
2:                                      gelu_activation: True
2:                                      global_rank: 2
2:                                      group_by_size: True
2:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
2:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
2:                                      is_master: False
2:                                      is_slurm_job: False
2:                                      lambda_ae: 1
2:                                      lambda_bt: 1
2:                                      lambda_clm: 1
2:                                      lambda_mlm: 1
2:                                      lambda_mt: 1
2:                                      lambda_pc: 1
2:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
2:                                      langs: ['en', 'de', 'img']
2:                                      length_penalty: 1
2:                                      lg_sampling_factor: -1
2:                                      lgs: en-de
2:                                      local_rank: 2
2:                                      master_port: -1
2:                                      max_batch_size: 0
2:                                      max_epoch: 100000
2:                                      max_len: 100
2:                                      max_vocab: -1
2:                                      min_count: 0
2:                                      mlm_steps: [('en', 'de')]
2:                                      mono_dataset: {}
2:                                      mt_steps: []
2:                                      multi_gpu: True
2:                                      multi_node: False
2:                                      n_gpu_per_node: 3
2:                                      n_heads: 8
2:                                      n_langs: 3
2:                                      n_layers: 6
2:                                      n_nodes: 1
2:                                      node_id: 0
2:                                      only_vlm: False
2:                                      optimizer: adam,lr=0.0001
2:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
2:                                      pc_steps: []
2:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
2:                                      reload_checkpoint: 
2:                                      reload_emb: 
2:                                      reload_model: 
2:                                      sample_alpha: 0
2:                                      save_periodic: 0
2:                                      share_inout_emb: True
2:                                      sinusoidal_embeddings: False
2:                                      split_data: False
2:                                      stopping_criterion: _valid_mlm_ppl,25
2:                                      tokens_per_batch: -1
2:                                      use_lang_emb: True
2:                                      use_memory: False
2:                                      validation_metrics: valid_en_de_mlm_ppl
2:                                      vlm_steps: [('en', 'de')]
2:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
2:                                      word_blank: 0
2:                                      word_dropout: 0
2:                                      word_keep: 0.1
2:                                      word_mask: 0.8
2:                                      word_mask_keep_rand: 0.8,0.1,0.1
2:                                      word_pred: 0.15
2:                                      word_rand: 0.1
2:                                      word_shuffle: 0
2:                                      world_size: 3
2: INFO - 04/18/20 13:22:45 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3081
2:                                      
2: INFO - 04/18/20 13:22:45 - 0:00:00 - Running command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
2: 
2: WARNING - 04/18/20 13:22:45 - 0:00:00 - Signal handler installed.
2: 
2: INFO - 04/18/20 13:22:45 - 0:00:00 - ============ Parallel data (de-en)
2: INFO - 04/18/20 13:22:45 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
0: Traceback (most recent call last):
0:   File "train.py", line 348, in <module>
0:     main(params)
0:   File "train.py", line 230, in main
1: INFO - 04/18/20 13:22:45 - 0:00:00 - ============ Initialized logger ============
1: INFO - 04/18/20 13:22:45 - 0:00:00 - accumulate_gradients: 1
1:                                      ae_steps: []
1:                                      amp: -1
1:                                      asm: False
1:                                      attention_dropout: 0.1
1:                                      batch_size: 64
1:                                      beam_size: 1
1:                                      bptt: 256
1:                                      bt_src_langs: []
1:                                      bt_steps: []
1:                                      clip_grad_norm: 5
1:                                      clm_steps: []
1:                                      command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3081"
1:                                      context_size: 0
1:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
1:                                      debug: False
1:                                      debug_slurm: False
1:                                      debug_train: False
1:                                      dropout: 0.1
1:                                      dump_path: ./dumped/xlm_en_de_tlm/3081
1:                                      early_stopping: False
1:                                      emb_dim: 512
1:                                      encoder_only: True
1:                                      epoch_size: 300000
1:                                      eval_bleu: False
1:                                      eval_only: False
1:                                      exp_id: 3081
1:                                      exp_name: xlm_en_de_tlm
1:                                      fp16: False
1:                                      gelu_activation: True
1:                                      global_rank: 1
1:                                      group_by_size: True
1:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
1:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
1:                                      is_master: False
1:                                      is_slurm_job: False
1:                                      lambda_ae: 1
1:                                      lambda_bt: 1
1:                                      lambda_clm: 1
1:                                      lambda_mlm: 1
1:                                      lambda_mt: 1
1:                                      lambda_pc: 1
1:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
1:                                      langs: ['en', 'de', 'img']
1:                                      length_penalty: 1
1:                                      lg_sampling_factor: -1
1:                                      lgs: en-de
1:                                      local_rank: 1
1:                                      master_port: -1
1:                                      max_batch_size: 0
1:                                      max_epoch: 100000
1:                                      max_len: 100
1:                                      max_vocab: -1
1:                                      min_count: 0
1:                                      mlm_steps: [('en', 'de')]
1:                                      mono_dataset: {}
1:                                      mt_steps: []
1:                                      multi_gpu: True
1:                                      multi_node: False
1:                                      n_gpu_per_node: 3
1:                                      n_heads: 8
1:                                      n_langs: 3
1:                                      n_layers: 6
1:                                      n_nodes: 1
0:     init_distributed_mode(params)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/slurm.py", line 171, in init_distributed_mode
1:                                      node_id: 0
1:                                      only_vlm: False
1:                                      optimizer: adam,lr=0.0001
1:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
1:                                      pc_steps: []
1:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
1:                                      reload_checkpoint: 
1:                                      reload_emb: 
1:                                      reload_model: 
1:                                      sample_alpha: 0
1:                                      save_periodic: 0
1:                                      share_inout_emb: True
1:                                      sinusoidal_embeddings: False
1:                                      split_data: False
1:                                      stopping_criterion: _valid_mlm_ppl,25
1:                                      tokens_per_batch: -1
1:                                      use_lang_emb: True
1:                                      use_memory: False
1:                                      validation_metrics: valid_en_de_mlm_ppl
1:                                      vlm_steps: [('en', 'de')]
1:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
1:                                      word_blank: 0
1:                                      word_dropout: 0
1:                                      word_keep: 0.1
1:                                      word_mask: 0.8
1:                                      word_mask_keep_rand: 0.8,0.1,0.1
1:                                      word_pred: 0.15
1:                                      word_rand: 0.1
1:                                      word_shuffle: 0
1:                                      world_size: 3
1: INFO - 04/18/20 13:22:45 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3081
1:                                      
1: INFO - 04/18/20 13:22:45 - 0:00:00 - Running command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
1: 
1: WARNING - 04/18/20 13:22:45 - 0:00:00 - Signal handler installed.
1: 
0:     backend='nccl',
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py", line 397, in init_process_group
1: INFO - 04/18/20 13:22:45 - 0:00:00 - ============ Parallel data (de-en)
1: INFO - 04/18/20 13:22:45 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
0:     store, rank, world_size = next(rendezvous_iterator)
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/rendezvous.py", line 168, in _env_rendezvous_handler
0:     store = TCPStore(master_addr, master_port, world_size, start_daemon)
0: RuntimeError: Address already in use
0: INFO - 04/18/20 13:22:45 - 0:00:00 - ============ Initialized logger ============
0: INFO - 04/18/20 13:22:45 - 0:00:00 - accumulate_gradients: 1
0:                                      ae_steps: []
0:                                      amp: -1
0:                                      asm: False
0:                                      attention_dropout: 0.1
0:                                      batch_size: 64
0:                                      beam_size: 1
0:                                      bptt: 256
0:                                      bt_src_langs: []
0:                                      bt_steps: []
0:                                      clip_grad_norm: 5
0:                                      clm_steps: []
0:                                      command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3081"
0:                                      context_size: 0
0:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
0:                                      debug: False
0:                                      debug_slurm: False
0:                                      debug_train: False
0:                                      dropout: 0.1
0:                                      dump_path: ./dumped/xlm_en_de_tlm/3081
0:                                      early_stopping: False
0:                                      emb_dim: 512
0:                                      encoder_only: True
0:                                      epoch_size: 300000
0:                                      eval_bleu: False
0:                                      eval_only: False
0:                                      exp_id: 3081
0:                                      exp_name: xlm_en_de_tlm
0:                                      fp16: False
0:                                      gelu_activation: True
0:                                      global_rank: 2
0:                                      group_by_size: True
0:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
0:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
0:                                      is_master: False
0:                                      is_slurm_job: False
0:                                      lambda_ae: 1
0:                                      lambda_bt: 1
0:                                      lambda_clm: 1
0:                                      lambda_mlm: 1
0:                                      lambda_mt: 1
0:                                      lambda_pc: 1
0:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
0:                                      langs: ['en', 'de', 'img']
0:                                      length_penalty: 1
0:                                      lg_sampling_factor: -1
0:                                      lgs: en-de
0:                                      local_rank: 2
0:                                      master_port: -1
0:                                      max_batch_size: 0
0:                                      max_epoch: 100000
0:                                      max_len: 100
0:                                      max_vocab: -1
0:                                      min_count: 0
0:                                      mlm_steps: [('en', 'de')]
0:                                      mono_dataset: {}
0:                                      mt_steps: []
0:                                      multi_gpu: True
0:                                      multi_node: False
0:                                      n_gpu_per_node: 3
0:                                      n_heads: 8
0:                                      n_langs: 3
0:                                      n_layers: 6
0:                                      n_nodes: 1
0:                                      node_id: 0
0:                                      only_vlm: False
0:                                      optimizer: adam,lr=0.0001
0:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
0:                                      pc_steps: []
0:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
0:                                      reload_checkpoint: 
0:                                      reload_emb: 
0:                                      reload_model: 
0:                                      sample_alpha: 0
0:                                      save_periodic: 0
0:                                      share_inout_emb: True
0:                                      sinusoidal_embeddings: False
0:                                      split_data: False
0:                                      stopping_criterion: _valid_mlm_ppl,25
0:                                      tokens_per_batch: -1
0:                                      use_lang_emb: True
0:                                      use_memory: False
0:                                      validation_metrics: valid_en_de_mlm_ppl
0:                                      vlm_steps: [('en', 'de')]
0:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
0:                                      word_blank: 0
0:                                      word_dropout: 0
0:                                      word_keep: 0.1
0:                                      word_mask: 0.8
0:                                      word_mask_keep_rand: 0.8,0.1,0.1
0:                                      word_pred: 0.15
0:                                      word_rand: 0.1
0:                                      word_shuffle: 0
0:                                      world_size: 3
0: INFO - 04/18/20 13:22:45 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3081
0:                                      
0: INFO - 04/18/20 13:22:45 - 0:00:00 - Running command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
0: 
0: WARNING - 04/18/20 13:22:45 - 0:00:00 - Signal handler installed.
0: 
0: INFO - 04/18/20 13:22:45 - 0:00:00 - ============ Parallel data (de-en)
0: INFO - 04/18/20 13:22:45 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: INFO - 04/18/20 13:22:45 - 0:00:00 - ============ Initialized logger ============
1: INFO - 04/18/20 13:22:45 - 0:00:00 - ============ Initialized logger ============
1: INFO - 04/18/20 13:22:45 - 0:00:00 - accumulate_gradients: 1
1:                                      ae_steps: []
1:                                      amp: -1
1:                                      asm: False
1:                                      attention_dropout: 0.1
1:                                      batch_size: 64
1:                                      beam_size: 1
1:                                      bptt: 256
1:                                      bt_src_langs: []
1:                                      bt_steps: []
1:                                      clip_grad_norm: 5
1:                                      clm_steps: []
1:                                      command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3081"
1:                                      context_size: 0
1:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
1:                                      debug: False
1:                                      debug_slurm: False
1:                                      debug_train: False
1:                                      dropout: 0.1
1:                                      dump_path: ./dumped/xlm_en_de_tlm/3081
1:                                      early_stopping: False
1:                                      emb_dim: 512
1:                                      encoder_only: True
1:                                      epoch_size: 300000
1:                                      eval_bleu: False
1:                                      eval_only: False
1:                                      exp_id: 3081
1:                                      exp_name: xlm_en_de_tlm
1:                                      fp16: False
1:                                      gelu_activation: True
1:                                      global_rank: 2
1:                                      group_by_size: True
1:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
1:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
1:                                      is_master: False
1:                                      is_slurm_job: False
1:                                      lambda_ae: 1
1:                                      lambda_bt: 1
1:                                      lambda_clm: 1
1:                                      lambda_mlm: 1
1:                                      lambda_mt: 1
1:                                      lambda_pc: 1
1:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
1:                                      langs: ['en', 'de', 'img']
1:                                      length_penalty: 1
1:                                      lg_sampling_factor: -1
1:                                      lgs: en-de
1:                                      local_rank: 2
1:                                      master_port: -1
1:                                      max_batch_size: 0
1:                                      max_epoch: 100000
1:                                      max_len: 100
1:                                      max_vocab: -1
1:                                      min_count: 0
1:                                      mlm_steps: [('en', 'de')]
1:                                      mono_dataset: {}
1:                                      mt_steps: []
1:                                      multi_gpu: True
1:                                      multi_node: False
1:                                      n_gpu_per_node: 3
1:                                      n_heads: 8
1:                                      n_langs: 3
1:                                      n_layers: 6
1:                                      n_nodes: 1
1:                                      node_id: 0
1:                                      only_vlm: False
1:                                      optimizer: adam,lr=0.0001
1:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
1:                                      pc_steps: []
1:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
1:                                      reload_checkpoint: 
1:                                      reload_emb: 
1:                                      reload_model: 
1:                                      sample_alpha: 0
1:                                      save_periodic: 0
1:                                      share_inout_emb: True
1:                                      sinusoidal_embeddings: False
1:                                      split_data: False
1:                                      stopping_criterion: _valid_mlm_ppl,25
1:                                      tokens_per_batch: -1
1:                                      use_lang_emb: True
1:                                      use_memory: False
1:                                      validation_metrics: valid_en_de_mlm_ppl
1:                                      vlm_steps: [('en', 'de')]
1:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
1:                                      word_blank: 0
1:                                      word_dropout: 0
1:                                      word_keep: 0.1
1:                                      word_mask: 0.8
1:                                      word_mask_keep_rand: 0.8,0.1,0.1
1:                                      word_pred: 0.15
1:                                      word_rand: 0.1
1:                                      word_shuffle: 0
1:                                      world_size: 3
1: INFO - 04/18/20 13:22:45 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3081
1:                                      
1: INFO - 04/18/20 13:22:45 - 0:00:00 - Running command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
3: INFO - 04/18/20 13:22:45 - 0:00:00 - accumulate_gradients: 1
3:                                      ae_steps: []
3:                                      amp: -1
3:                                      asm: False
3:                                      attention_dropout: 0.1
3:                                      batch_size: 64
3:                                      beam_size: 1
3:                                      bptt: 256
3:                                      bt_src_langs: []
3:                                      bt_steps: []
3:                                      clip_grad_norm: 5
3:                                      clm_steps: []
3:                                      command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3081"
3:                                      context_size: 0
3:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      debug: False
3:                                      debug_slurm: False
3:                                      debug_train: False
3:                                      dropout: 0.1
3:                                      dump_path: ./dumped/xlm_en_de_tlm/3081
3:                                      early_stopping: False
3:                                      emb_dim: 512
3:                                      encoder_only: True
3:                                      epoch_size: 300000
3:                                      eval_bleu: False
3:                                      eval_only: False
3:                                      exp_id: 3081
3:                                      exp_name: xlm_en_de_tlm
3:                                      fp16: False
3:                                      gelu_activation: True
3:                                      global_rank: 2
3:                                      group_by_size: True
3:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
3:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      is_master: False
3:                                      is_slurm_job: False
3:                                      lambda_ae: 1
3:                                      lambda_bt: 1
3:                                      lambda_clm: 1
3:                                      lambda_mlm: 1
3:                                      lambda_mt: 1
3:                                      lambda_pc: 1
3:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
3:                                      langs: ['en', 'de', 'img']
3:                                      length_penalty: 1
3:                                      lg_sampling_factor: -1
3:                                      lgs: en-de
3:                                      local_rank: 2
3:                                      master_port: -1
3:                                      max_batch_size: 0
3:                                      max_epoch: 100000
3:                                      max_len: 100
3:                                      max_vocab: -1
3:                                      min_count: 0
3:                                      mlm_steps: [('en', 'de')]
3:                                      mono_dataset: {}
3:                                      mt_steps: []
3:                                      multi_gpu: True
3:                                      multi_node: False
3:                                      n_gpu_per_node: 3
3:                                      n_heads: 8
3:                                      n_langs: 3
3:                                      n_layers: 6
3:                                      n_nodes: 1
1: 
3:                                      node_id: 0
3:                                      only_vlm: False
3:                                      optimizer: adam,lr=0.0001
3:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      pc_steps: []
3:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
3:                                      reload_checkpoint: 
3:                                      reload_emb: 
3:                                      reload_model: 
3:                                      sample_alpha: 0
3:                                      save_periodic: 0
3:                                      share_inout_emb: True
3:                                      sinusoidal_embeddings: False
3:                                      split_data: False
3:                                      stopping_criterion: _valid_mlm_ppl,25
3:                                      tokens_per_batch: -1
3:                                      use_lang_emb: True
3:                                      use_memory: False
3:                                      validation_metrics: valid_en_de_mlm_ppl
3:                                      vlm_steps: [('en', 'de')]
3:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      word_blank: 0
3:                                      word_dropout: 0
3:                                      word_keep: 0.1
3:                                      word_mask: 0.8
3:                                      word_mask_keep_rand: 0.8,0.1,0.1
3:                                      word_pred: 0.15
3:                                      word_rand: 0.1
3:                                      word_shuffle: 0
3:                                      world_size: 3
1: WARNING - 04/18/20 13:22:45 - 0:00:00 - Signal handler installed.
3: INFO - 04/18/20 13:22:45 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3081
3:                                      
1: 
3: INFO - 04/18/20 13:22:45 - 0:00:00 - Running command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
1: INFO - 04/18/20 13:22:45 - 0:00:00 - ============ Parallel data (de-en)
3: 
1: INFO - 04/18/20 13:22:45 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: INFO - 04/18/20 13:22:45 - 0:00:00 - ============ Initialized logger ============
3: WARNING - 04/18/20 13:22:45 - 0:00:00 - Signal handler installed.
3: 
3: INFO - 04/18/20 13:22:45 - 0:00:00 - ============ Parallel data (de-en)
3: INFO - 04/18/20 13:22:45 - 0:00:00 - accumulate_gradients: 1
3:                                      ae_steps: []
3:                                      amp: -1
3:                                      asm: False
3:                                      attention_dropout: 0.1
3:                                      batch_size: 64
3:                                      beam_size: 1
3:                                      bptt: 256
3:                                      bt_src_langs: []
3:                                      bt_steps: []
3:                                      clip_grad_norm: 5
3:                                      clm_steps: []
3:                                      command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3081"
3:                                      context_size: 0
3:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      debug: False
3:                                      debug_slurm: False
3:                                      debug_train: False
3:                                      dropout: 0.1
3:                                      dump_path: ./dumped/xlm_en_de_tlm/3081
3:                                      early_stopping: False
3:                                      emb_dim: 512
3:                                      encoder_only: True
3:                                      epoch_size: 300000
3:                                      eval_bleu: False
3:                                      eval_only: False
3:                                      exp_id: 3081
3:                                      exp_name: xlm_en_de_tlm
3:                                      fp16: False
3:                                      gelu_activation: True
3:                                      global_rank: 1
3:                                      group_by_size: True
3:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
3:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      is_master: False
3:                                      is_slurm_job: False
3:                                      lambda_ae: 1
3:                                      lambda_bt: 1
3:                                      lambda_clm: 1
3:                                      lambda_mlm: 1
3:                                      lambda_mt: 1
3:                                      lambda_pc: 1
3:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
3:                                      langs: ['en', 'de', 'img']
3:                                      length_penalty: 1
3:                                      lg_sampling_factor: -1
3:                                      lgs: en-de
3:                                      local_rank: 1
3:                                      master_port: -1
3:                                      max_batch_size: 0
3:                                      max_epoch: 100000
3:                                      max_len: 100
3:                                      max_vocab: -1
3:                                      min_count: 0
3:                                      mlm_steps: [('en', 'de')]
3:                                      mono_dataset: {}
3:                                      mt_steps: []
3:                                      multi_gpu: True
3:                                      multi_node: False
3:                                      n_gpu_per_node: 3
3:                                      n_heads: 8
3:                                      n_langs: 3
3:                                      n_layers: 6
3:                                      n_nodes: 1
3:                                      node_id: 0
3:                                      only_vlm: False
3:                                      optimizer: adam,lr=0.0001
3:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      pc_steps: []
3:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
3:                                      reload_checkpoint: 
3:                                      reload_emb: 
3:                                      reload_model: 
3:                                      sample_alpha: 0
3:                                      save_periodic: 0
3:                                      share_inout_emb: True
3:                                      sinusoidal_embeddings: False
3:                                      split_data: False
3:                                      stopping_criterion: _valid_mlm_ppl,25
3:                                      tokens_per_batch: -1
3:                                      use_lang_emb: True
3:                                      use_memory: False
3:                                      validation_metrics: valid_en_de_mlm_ppl
3:                                      vlm_steps: [('en', 'de')]
3:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      word_blank: 0
3:                                      word_dropout: 0
3:                                      word_keep: 0.1
3:                                      word_mask: 0.8
3:                                      word_mask_keep_rand: 0.8,0.1,0.1
3:                                      word_pred: 0.15
3:                                      word_rand: 0.1
3:                                      word_shuffle: 0
3:                                      world_size: 3
3: INFO - 04/18/20 13:22:45 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: INFO - 04/18/20 13:22:45 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3081
3:                                      
3: INFO - 04/18/20 13:22:45 - 0:00:00 - Running command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 64 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
3: 
3: WARNING - 04/18/20 13:22:45 - 0:00:00 - Signal handler installed.
3: 
3: INFO - 04/18/20 13:22:45 - 0:00:00 - ============ Parallel data (de-en)
3: INFO - 04/18/20 13:22:45 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
srun: error: hanabi: task 2: Exited with exit code 1
0: INFO - 04/18/20 13:22:49 - 0:00:05 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:22:49 - 0:00:05 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
3: INFO - 04/18/20 13:22:52 - 0:00:07 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:22:52 - 0:00:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
1: INFO - 04/18/20 13:22:52 - 0:00:07 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:22:52 - 0:00:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
2: INFO - 04/18/20 13:22:52 - 0:00:07 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:22:52 - 0:00:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
3: INFO - 04/18/20 13:22:52 - 0:00:07 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:22:52 - 0:00:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
1: INFO - 04/18/20 13:22:52 - 0:00:07 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:22:52 - 0:00:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
2: INFO - 04/18/20 13:22:53 - 0:00:07 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:22:53 - 0:00:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
3: INFO - 04/18/20 13:22:53 - 0:00:08 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:22:53 - 0:00:08 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
0: INFO - 04/18/20 13:22:53 - 0:00:08 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:22:53 - 0:00:08 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
0: Traceback (most recent call last):
0:   File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
0:     "__main__", mod_spec)
0:   File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
0:     exec(code, run_globals)
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 263, in <module>
0:     main()
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 259, in main
0:     cmd=cmd)
0: subprocess.CalledProcessError: Command '['/home/menekse/virtualenvs/torch_env/bin/python', '-u', 'train.py', '--local_rank=2', '--exp_name', 'xlm_en_de_tlm', '--dump_path', './dumped', '--data_path', '/data/shared/ConceptualCaptions/XLM_data/50k', '--lgs', 'en-de', '--clm_steps', '', '--mlm_steps', 'en-de', '--emb_dim', '512', '--n_layers', '6', '--n_heads', '8', '--dropout', '0.1', '--attention_dropout', '0.1', '--gelu_activation', 'true', '--batch_size', '64', '--bptt', '256', '--optimizer', 'adam,lr=0.0001', '--epoch_size', '300000', '--max_epoch', '100000', '--validation_metrics', 'valid_en_de_mlm_ppl', '--stopping_criterion', '_valid_mlm_ppl,25', '--fp16', 'false', '--image_names', '/data/shared/ConceptualCaptions/XLM_data/50k']' returned non-zero exit status 1.
1: Traceback (most recent call last):
1:   File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
1:     "__main__", mod_spec)
1:   File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
1:     exec(code, run_globals)
1:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 263, in <module>
1:     main()
1:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 259, in main
1:     cmd=cmd)
1: subprocess.CalledProcessError: Command '['/home/menekse/virtualenvs/torch_env/bin/python', '-u', 'train.py', '--local_rank=2', '--exp_name', 'xlm_en_de_tlm', '--dump_path', './dumped', '--data_path', '/data/shared/ConceptualCaptions/XLM_data/50k', '--lgs', 'en-de', '--clm_steps', '', '--mlm_steps', 'en-de', '--emb_dim', '512', '--n_layers', '6', '--n_heads', '8', '--dropout', '0.1', '--attention_dropout', '0.1', '--gelu_activation', 'true', '--batch_size', '64', '--bptt', '256', '--optimizer', 'adam,lr=0.0001', '--epoch_size', '300000', '--max_epoch', '100000', '--validation_metrics', 'valid_en_de_mlm_ppl', '--stopping_criterion', '_valid_mlm_ppl,25', '--fp16', 'false', '--image_names', '/data/shared/ConceptualCaptions/XLM_data/50k']' returned non-zero exit status 1.
0: INFO - 04/18/20 13:22:54 - 0:00:10 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:22:57 - 0:00:12 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:22:58 - 0:00:13 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
2: INFO - 04/18/20 13:22:58 - 0:00:13 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
srun: error: hanabi: task 1: Exited with exit code 1
1: INFO - 04/18/20 13:22:59 - 0:00:14 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
0: INFO - 04/18/20 13:23:00 - 0:00:14 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
2: INFO - 04/18/20 13:23:00 - 0:00:14 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:23:00 - 0:00:14 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:23:00 - 0:00:14 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
srun: error: hanabi: task 0: Exited with exit code 1
0: INFO - 04/18/20 13:23:03 - 0:00:19 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:23:06 - 0:00:21 - Removed 0 empty sentences.
2: INFO - 04/18/20 13:23:10 - 0:00:24 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:23:12 - 0:00:26 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:23:12 - 0:00:27 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:23:12 - 0:00:27 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:23:12 - 0:00:27 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:23:13 - 0:00:27 - Removed 0 empty sentences.
2: INFO - 04/18/20 13:23:14 - 0:00:29 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:23:20 - 0:00:36 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:23:22 - 0:00:37 - Removed 0 empty sentences.
2: INFO - 04/18/20 13:23:27 - 0:00:42 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:23:30 - 0:00:45 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:23:30 - 0:00:45 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:23:33 - 0:00:47 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:23:33 - 0:00:48 - Removed 2 too long sentences.
1: INFO - 04/18/20 13:23:33 - 0:00:48 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:23:34 - 0:00:49 - Removed 2 too long sentences.
3: INFO - 04/18/20 13:23:36 - 0:00:51 - Removed 0 empty sentences.
2: INFO - 04/18/20 13:23:37 - 0:00:52 - Removed 0 empty sentences.
2: INFO - 04/18/20 13:23:38 - 0:00:53 - Removed 2 too long sentences.
0: 
0: INFO - 04/18/20 13:23:39 - 0:00:54 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
0: INFO - 04/18/20 13:23:39 - 0:00:55 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:23:39 - 0:00:55 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
0: INFO - 04/18/20 13:23:40 - 0:00:55 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
3: 
3: INFO - 04/18/20 13:23:40 - 0:00:55 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
3: INFO - 04/18/20 13:23:40 - 0:00:55 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:23:41 - 0:00:55 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
3: INFO - 04/18/20 13:23:41 - 0:00:56 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:23:42 - 0:00:57 - Removed 2 too long sentences.
2: 
2: INFO - 04/18/20 13:23:44 - 0:00:58 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
0: INFO - 04/18/20 13:23:44 - 0:00:59 - Removed 0 empty sentences.
0: 
0: INFO - 04/18/20 13:23:44 - 0:00:59 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
0: INFO - 04/18/20 13:23:44 - 0:00:59 - Removed 2 too long sentences.
2: INFO - 04/18/20 13:23:44 - 0:00:59 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:23:44 - 0:01:00 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:23:44 - 0:00:59 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
0: INFO - 04/18/20 13:23:44 - 0:01:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
2: INFO - 04/18/20 13:23:45 - 0:00:59 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
0: INFO - 04/18/20 13:23:45 - 0:01:00 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
3: INFO - 04/18/20 13:23:45 - 0:01:00 - Removed 0 empty sentences.
3: 
3: INFO - 04/18/20 13:23:45 - 0:01:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/18/20 13:23:45 - 0:01:00 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:23:46 - 0:01:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/18/20 13:23:46 - 0:01:00 - Removed 2 too long sentences.
3: INFO - 04/18/20 13:23:46 - 0:01:01 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
3: INFO - 04/18/20 13:23:46 - 0:01:01 - Removed 2 too long sentences.
1: 
1: INFO - 04/18/20 13:23:47 - 0:01:02 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
1: INFO - 04/18/20 13:23:48 - 0:01:03 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:23:48 - 0:01:03 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: INFO - 04/18/20 13:23:48 - 0:01:03 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
0: INFO - 04/18/20 13:23:48 - 0:01:04 - Removed 0 empty sentences.
0: 
0: 
0: INFO - 04/18/20 13:23:49 - 0:01:04 - ============ Parallel data with image regions (de-en)
0: INFO - 04/18/20 13:23:49 - 0:01:04 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
2: INFO - 04/18/20 13:23:49 - 0:01:04 - Removed 0 empty sentences.
2: 
2: INFO - 04/18/20 13:23:49 - 0:01:04 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
2: INFO - 04/18/20 13:23:49 - 0:01:04 - Removed 2 too long sentences.
2: INFO - 04/18/20 13:23:49 - 0:01:04 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:23:49 - 0:01:04 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
2: INFO - 04/18/20 13:23:50 - 0:01:04 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
0: 
0: INFO - 04/18/20 13:23:50 - 0:01:04 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
3: INFO - 04/18/20 13:23:50 - 0:01:05 - Removed 0 empty sentences.
3: 
3: 
0: INFO - 04/18/20 13:23:50 - 0:01:05 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:23:50 - 0:01:05 - ============ Parallel data with image regions (de-en)
3: INFO - 04/18/20 13:23:50 - 0:01:05 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
0: INFO - 04/18/20 13:23:50 - 0:01:05 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: 
1: INFO - 04/18/20 13:23:50 - 0:01:05 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
0: INFO - 04/18/20 13:23:51 - 0:01:05 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:23:51 - 0:01:06 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:23:51 - 0:01:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
3: 
3: INFO - 04/18/20 13:23:51 - 0:01:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
1: INFO - 04/18/20 13:23:51 - 0:01:06 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:23:51 - 0:01:06 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:23:52 - 0:01:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
3: INFO - 04/18/20 13:23:52 - 0:01:06 - Removed 2 too long sentences.
1: INFO - 04/18/20 13:23:52 - 0:01:07 - Removed 0 empty sentences.
1: 
1: INFO - 04/18/20 13:23:52 - 0:01:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/18/20 13:23:52 - 0:01:07 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:23:52 - 0:01:07 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:23:52 - 0:01:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/18/20 13:23:53 - 0:01:07 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
2: INFO - 04/18/20 13:23:53 - 0:01:08 - Removed 0 empty sentences.
2: 
2: 
0: INFO - 04/18/20 13:23:53 - 0:01:08 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:23:53 - 0:01:08 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
2: INFO - 04/18/20 13:23:53 - 0:01:08 - ============ Parallel data with image regions (de-en)
2: INFO - 04/18/20 13:23:53 - 0:01:08 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
0: INFO - 04/18/20 13:23:54 - 0:01:09 - Removed 0 empty sentences.
0: 
0: INFO - 04/18/20 13:23:54 - 0:01:09 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
2: 
2: INFO - 04/18/20 13:23:54 - 0:01:09 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
3: INFO - 04/18/20 13:23:54 - 0:01:09 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:23:54 - 0:01:09 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
0: INFO - 04/18/20 13:23:55 - 0:01:09 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:23:55 - 0:01:09 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
2: INFO - 04/18/20 13:23:55 - 0:01:09 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:23:55 - 0:01:10 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
0: INFO - 04/18/20 13:23:55 - 0:01:10 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
2: INFO - 04/18/20 13:23:55 - 0:01:10 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:23:55 - 0:01:10 - Removed 0 empty sentences.
3: 
3: INFO - 04/18/20 13:23:55 - 0:01:10 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/18/20 13:23:56 - 0:01:10 - Removed 0 empty sentences.
1: 
1: INFO - 04/18/20 13:23:56 - 0:01:10 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/18/20 13:23:56 - 0:01:10 - Removed 0 empty sentences.
1: 
1: 
3: INFO - 04/18/20 13:23:56 - 0:01:10 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:23:56 - 0:01:11 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/18/20 13:23:56 - 0:01:11 - ============ Parallel data with image regions (de-en)
1: INFO - 04/18/20 13:23:56 - 0:01:11 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
1: INFO - 04/18/20 13:23:56 - 0:01:11 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:23:56 - 0:01:11 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: INFO - 04/18/20 13:23:56 - 0:01:11 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/18/20 13:23:57 - 0:01:11 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
2: INFO - 04/18/20 13:23:57 - 0:01:12 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:23:57 - 0:01:12 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
0: INFO - 04/18/20 13:23:57 - 0:01:13 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: 
3: INFO - 04/18/20 13:23:58 - 0:01:12 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
3: INFO - 04/18/20 13:23:58 - 0:01:13 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:23:58 - 0:01:13 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
3: INFO - 04/18/20 13:23:58 - 0:01:13 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
0: INFO - 04/18/20 13:23:59 - 0:01:13 - Removed 0 empty sentences.
0: 
0: 
3: INFO - 04/18/20 13:23:59 - 0:01:13 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
0: INFO - 04/18/20 13:23:59 - 0:01:13 - ============ Parallel data with image regions (de-en)
0: INFO - 04/18/20 13:23:59 - 0:01:13 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
2: INFO - 04/18/20 13:23:59 - 0:01:14 - Removed 0 empty sentences.
2: 
2: INFO - 04/18/20 13:23:59 - 0:01:14 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/18/20 13:23:59 - 0:01:14 - Removed 0 empty sentences.
3: 
3: 
2: INFO - 04/18/20 13:24:00 - 0:01:14 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:24:00 - 0:01:14 - ============ Parallel data with image regions (de-en)
3: INFO - 04/18/20 13:24:00 - 0:01:14 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
2: INFO - 04/18/20 13:24:00 - 0:01:14 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/18/20 13:24:00 - 0:01:14 - Removed 0 empty sentences.
1: 
1: 
1: INFO - 04/18/20 13:24:00 - 0:01:15 - ============ Parallel data with image regions (de-en)
1: INFO - 04/18/20 13:24:00 - 0:01:15 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
2: INFO - 04/18/20 13:24:00 - 0:01:15 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: INFO - 04/18/20 13:24:00 - 0:01:15 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:24:00 - 0:01:15 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
2: INFO - 04/18/20 13:24:01 - 0:01:16 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:24:02 - 0:01:16 - Removed 0 empty sentences.
3: 
3: INFO - 04/18/20 13:24:02 - 0:01:16 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/18/20 13:24:02 - 0:01:17 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:24:02 - 0:01:17 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
3: INFO - 04/18/20 13:24:03 - 0:01:17 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
0: INFO - 04/18/20 13:24:03 - 0:01:17 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:24:03 - 0:01:17 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
2: INFO - 04/18/20 13:24:03 - 0:01:18 - Removed 0 empty sentences.
2: 
2: 
2: INFO - 04/18/20 13:24:03 - 0:01:18 - ============ Parallel data with image regions (de-en)
2: INFO - 04/18/20 13:24:03 - 0:01:18 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
1: INFO - 04/18/20 13:24:03 - 0:01:18 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:24:03 - 0:01:18 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
3: INFO - 04/18/20 13:24:04 - 0:01:18 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:24:04 - 0:01:18 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
1: INFO - 04/18/20 13:24:04 - 0:01:19 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:24:06 - 0:01:20 - Removed 0 empty sentences.
3: 
3: 
3: INFO - 04/18/20 13:24:06 - 0:01:21 - ============ Parallel data with image regions (de-en)
3: INFO - 04/18/20 13:24:06 - 0:01:21 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
0: INFO - 04/18/20 13:24:06 - 0:01:21 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
2: INFO - 04/18/20 13:24:07 - 0:01:22 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:24:07 - 0:01:22 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
3: INFO - 04/18/20 13:24:07 - 0:01:22 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:24:07 - 0:01:22 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:24:09 - 0:01:24 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:24:09 - 0:01:24 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
2: INFO - 04/18/20 13:24:10 - 0:01:25 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:24:13 - 0:01:27 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:25:02 - 0:02:17 - Removed 0 empty sentences.
2: INFO - 04/18/20 13:25:03 - 0:02:17 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:25:03 - 0:02:19 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:25:11 - 0:02:25 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:25:16 - 0:02:30 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:25:19 - 0:02:34 - Removed 0 empty sentences.
2: INFO - 04/18/20 13:25:20 - 0:02:35 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:25:20 - 0:02:35 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:25:22 - 0:02:37 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:25:25 - 0:02:41 - Removed 0 empty sentences.
2: INFO - 04/18/20 13:25:26 - 0:02:40 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:25:31 - 0:02:45 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:25:33 - 0:02:48 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:25:36 - 0:02:51 - Removed 2 too long sentences.
3: INFO - 04/18/20 13:25:39 - 0:02:54 - Removed 0 empty sentences.
2: INFO - 04/18/20 13:25:40 - 0:02:55 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:25:41 - 0:02:57 - Removed 2 too long sentences.
3: 
3: INFO - 04/18/20 13:25:42 - 0:02:56 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
3: INFO - 04/18/20 13:25:42 - 0:02:57 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:25:42 - 0:02:57 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: INFO - 04/18/20 13:25:42 - 0:02:57 - Removed 0 empty sentences.
2: INFO - 04/18/20 13:25:42 - 0:02:57 - Removed 2 too long sentences.
3: INFO - 04/18/20 13:25:43 - 0:02:57 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
0: INFO - 04/18/20 13:25:43 - 0:02:58 - Removed 0 empty sentences.
0: 
0: INFO - 04/18/20 13:25:47 - 0:03:02 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
0: INFO - 04/18/20 13:25:47 - 0:03:02 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:25:47 - 0:03:03 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
0: INFO - 04/18/20 13:25:48 - 0:03:03 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
2: 
2: INFO - 04/18/20 13:25:48 - 0:03:03 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
2: INFO - 04/18/20 13:25:49 - 0:03:03 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:25:49 - 0:03:04 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
2: INFO - 04/18/20 13:25:49 - 0:03:04 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:25:50 - 0:03:05 - Removed 2 too long sentences.
3: INFO - 04/18/20 13:25:53 - 0:03:08 - Removed 0 empty sentences.
3: 
3: INFO - 04/18/20 13:25:53 - 0:03:08 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/18/20 13:25:53 - 0:03:08 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:25:53 - 0:03:08 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
3: INFO - 04/18/20 13:25:54 - 0:03:08 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
2: INFO - 04/18/20 13:25:54 - 0:03:09 - Removed 2 too long sentences.
3: INFO - 04/18/20 13:25:55 - 0:03:10 - Removed 2 too long sentences.
3: INFO - 04/18/20 13:25:56 - 0:03:10 - Removed 0 empty sentences.
1: 
1: INFO - 04/18/20 13:25:56 - 0:03:11 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
1: INFO - 04/18/20 13:25:57 - 0:03:11 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:25:57 - 0:03:12 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: INFO - 04/18/20 13:25:57 - 0:03:12 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:25:57 - 0:03:12 - Removed 2 too long sentences.
3: INFO - 04/18/20 13:25:58 - 0:03:13 - Removed 0 empty sentences.
3: 
3: 
3: INFO - 04/18/20 13:25:58 - 0:03:13 - ============ Data summary
3: INFO - 04/18/20 13:25:58 - 0:03:13 - Parallel data      - train -        de-en:   3308331
3: INFO - 04/18/20 13:25:58 - 0:03:13 - Parallel data      - valid -        de-en:      5000
3: INFO - 04/18/20 13:25:58 - 0:03:13 - Parallel data      -  test -        de-en:      5000
3: 
2: 
2: INFO - 04/18/20 13:25:58 - 0:03:13 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
2: INFO - 04/18/20 13:25:59 - 0:03:13 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:25:59 - 0:03:14 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
2: INFO - 04/18/20 13:25:59 - 0:03:14 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
0: INFO - 04/18/20 13:25:59 - 0:03:15 - Removed 0 empty sentences.
0: 
0: INFO - 04/18/20 13:25:59 - 0:03:15 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
0: INFO - 04/18/20 13:26:00 - 0:03:14 - Removed 2 too long sentences.
0: INFO - 04/18/20 13:26:00 - 0:03:15 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:26:00 - 0:03:15 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
0: INFO - 04/18/20 13:26:00 - 0:03:15 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
3: 
3: INFO - 04/18/20 13:26:01 - 0:03:16 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
2: INFO - 04/18/20 13:26:01 - 0:03:16 - Removed 0 empty sentences.
2: 
2: INFO - 04/18/20 13:26:01 - 0:03:16 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/18/20 13:26:02 - 0:03:16 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:26:02 - 0:03:17 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:26:02 - 0:03:17 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
2: INFO - 04/18/20 13:26:02 - 0:03:17 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: 
1: INFO - 04/18/20 13:26:02 - 0:03:17 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
3: INFO - 04/18/20 13:26:02 - 0:03:17 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
2: INFO - 04/18/20 13:26:02 - 0:03:17 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: INFO - 04/18/20 13:26:02 - 0:03:17 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:26:03 - 0:03:17 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: INFO - 04/18/20 13:26:03 - 0:03:18 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
0: INFO - 04/18/20 13:26:04 - 0:03:19 - Removed 0 empty sentences.
0: 
0: 
0: INFO - 04/18/20 13:26:04 - 0:03:19 - ============ Data summary
0: INFO - 04/18/20 13:26:04 - 0:03:19 - Parallel data      - train -        de-en:   3308331
0: INFO - 04/18/20 13:26:04 - 0:03:19 - Parallel data      - valid -        de-en:      5000
0: INFO - 04/18/20 13:26:04 - 0:03:19 - Parallel data      -  test -        de-en:      5000
0: 
0: 
0: INFO - 04/18/20 13:26:06 - 0:03:20 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
2: INFO - 04/18/20 13:26:06 - 0:03:21 - Removed 0 empty sentences.
2: 
2: 
0: INFO - 04/18/20 13:26:06 - 0:03:21 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:26:06 - 0:03:21 - ============ Data summary
2: INFO - 04/18/20 13:26:06 - 0:03:21 - Parallel data      - train -        de-en:   3308331
2: INFO - 04/18/20 13:26:06 - 0:03:21 - Parallel data      - valid -        de-en:      5000
2: INFO - 04/18/20 13:26:06 - 0:03:21 - Parallel data      -  test -        de-en:      5000
2: 
0: INFO - 04/18/20 13:26:06 - 0:03:21 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
0: INFO - 04/18/20 13:26:06 - 0:03:21 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
2: INFO - 04/18/20 13:26:08 - 0:03:22 - Removed 0 empty sentences.
2: 
2: INFO - 04/18/20 13:26:08 - 0:03:22 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
2: INFO - 04/18/20 13:26:08 - 0:03:23 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:26:08 - 0:03:23 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
2: INFO - 04/18/20 13:26:08 - 0:03:23 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: INFO - 04/18/20 13:26:09 - 0:03:23 - Removed 0 empty sentences.
1: 
1: INFO - 04/18/20 13:26:09 - 0:03:23 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/18/20 13:26:09 - 0:03:24 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:26:09 - 0:03:24 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/18/20 13:26:09 - 0:03:24 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
3: INFO - 04/18/20 13:26:11 - 0:03:26 - Removed 2 too long sentences.
2: INFO - 04/18/20 13:26:12 - 0:03:27 - Removed 0 empty sentences.
2: 
2: 
2: INFO - 04/18/20 13:26:12 - 0:03:27 - ============ Data summary
2: INFO - 04/18/20 13:26:12 - 0:03:27 - Parallel data      - train -        de-en:   3308331
2: INFO - 04/18/20 13:26:12 - 0:03:27 - Parallel data      - valid -        de-en:      5000
2: INFO - 04/18/20 13:26:12 - 0:03:27 - Parallel data      -  test -        de-en:      5000
2: 
1: INFO - 04/18/20 13:26:12 - 0:03:27 - Removed 0 empty sentences.
1: 
1: 
1: INFO - 04/18/20 13:26:12 - 0:03:27 - ============ Data summary
1: INFO - 04/18/20 13:26:12 - 0:03:27 - Parallel data      - train -        de-en:   3308331
1: INFO - 04/18/20 13:26:12 - 0:03:27 - Parallel data      - valid -        de-en:      5000
1: INFO - 04/18/20 13:26:12 - 0:03:27 - Parallel data      -  test -        de-en:      5000
1: 
3: INFO - 04/18/20 13:26:13 - 0:03:27 - Removed 0 empty sentences.
3: 
3: INFO - 04/18/20 13:26:13 - 0:03:27 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/18/20 13:26:13 - 0:03:28 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:26:13 - 0:03:28 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
3: INFO - 04/18/20 13:26:13 - 0:03:28 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: INFO - 04/18/20 13:26:13 - 0:03:28 - Removed 0 empty sentences.
1: 
1: INFO - 04/18/20 13:26:13 - 0:03:28 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/18/20 13:26:14 - 0:03:29 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:26:14 - 0:03:29 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/18/20 13:26:14 - 0:03:29 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
3: INFO - 04/18/20 13:26:15 - 0:03:30 - Model: TransformerModel(
3:                                        (projector): Projector(
3:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
3:                                        )
3:                                        (regional_encodings): RegionalEncodings(
3:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
3:                                        )
3:                                        (position_embeddings): Embedding(512, 512)
3:                                        (lang_embeddings): Embedding(3, 512)
3:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
3:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        (attentions): ModuleList(
3:                                          (0): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (1): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (2): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (3): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (4): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (5): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm1): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (ffns): ModuleList(
3:                                          (0): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (1): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (2): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (3): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (4): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (5): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm2): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (memories): ModuleDict()
3:                                        (pred_layer): PredLayer(
3:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
3:                                        )
3:                                        (img_pred_layer): ImgPredLayer(
3:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
3:                                        )
3:                                      )
3: INFO - 04/18/20 13:26:15 - 0:03:30 - Number of parameters (model): 92180120
3: INFO - 04/18/20 13:26:16 - 0:03:31 - Removed 0 empty sentences.
3: 
3: 
3: INFO - 04/18/20 13:26:17 - 0:03:31 - ============ Data summary
3: INFO - 04/18/20 13:26:17 - 0:03:31 - Parallel data      - train -        de-en:   3308331
3: INFO - 04/18/20 13:26:17 - 0:03:31 - Parallel data      - valid -        de-en:      5000
3: INFO - 04/18/20 13:26:17 - 0:03:31 - Parallel data      -  test -        de-en:      5000
3: 
0: INFO - 04/18/20 13:26:17 - 0:03:31 - Removed 0 empty sentences.
0: 
0: INFO - 04/18/20 13:26:17 - 0:03:31 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: 
3: INFO - 04/18/20 13:26:17 - 0:03:31 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
0: INFO - 04/18/20 13:26:17 - 0:03:32 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:26:17 - 0:03:32 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
3: INFO - 04/18/20 13:26:17 - 0:03:32 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:26:17 - 0:03:32 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
0: INFO - 04/18/20 13:26:17 - 0:03:32 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: INFO - 04/18/20 13:26:18 - 0:03:32 - Removed 0 empty sentences.
1: 
1: 
3: INFO - 04/18/20 13:26:18 - 0:03:32 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:26:18 - 0:03:33 - ============ Data summary
1: INFO - 04/18/20 13:26:18 - 0:03:33 - Parallel data      - train -        de-en:   3308331
1: INFO - 04/18/20 13:26:18 - 0:03:33 - Parallel data      - valid -        de-en:      5000
1: INFO - 04/18/20 13:26:18 - 0:03:33 - Parallel data      -  test -        de-en:      5000
1: 
2: INFO - 04/18/20 13:26:20 - 0:03:34 - Model: TransformerModel(
2:                                        (projector): Projector(
2:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
2:                                        )
2:                                        (regional_encodings): RegionalEncodings(
2:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
2:                                        )
2:                                        (position_embeddings): Embedding(512, 512)
2:                                        (lang_embeddings): Embedding(3, 512)
2:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
2:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        (attentions): ModuleList(
2:                                          (0): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (1): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (2): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (3): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (4): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (5): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                        )
2:                                        (layer_norm1): ModuleList(
2:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        )
2:                                        (ffns): ModuleList(
2:                                          (0): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (1): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (2): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (3): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (4): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (5): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                        )
2:                                        (layer_norm2): ModuleList(
2:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        )
2:                                        (memories): ModuleDict()
2:                                        (pred_layer): PredLayer(
2:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
2:                                        )
2:                                        (img_pred_layer): ImgPredLayer(
2:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
2:                                        )
2:                                      )
2: INFO - 04/18/20 13:26:20 - 0:03:34 - Number of parameters (model): 92180120
0: INFO - 04/18/20 13:26:21 - 0:03:36 - Removed 0 empty sentences.
0: 
0: 
0: INFO - 04/18/20 13:26:21 - 0:03:36 - ============ Data summary
0: INFO - 04/18/20 13:26:21 - 0:03:36 - Parallel data      - train -        de-en:   3308331
0: INFO - 04/18/20 13:26:21 - 0:03:36 - Parallel data      - valid -        de-en:      5000
0: INFO - 04/18/20 13:26:21 - 0:03:36 - Parallel data      -  test -        de-en:      5000
0: 
0: INFO - 04/18/20 13:26:22 - 0:03:37 - Model: TransformerModel(
0:                                        (projector): Projector(
0:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
0:                                        )
0:                                        (regional_encodings): RegionalEncodings(
0:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
0:                                        )
0:                                        (position_embeddings): Embedding(512, 512)
0:                                        (lang_embeddings): Embedding(3, 512)
0:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
0:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        (attentions): ModuleList(
0:                                          (0): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (1): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (2): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (3): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (4): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (5): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                        )
0:                                        (layer_norm1): ModuleList(
0:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        )
0:                                        (ffns): ModuleList(
0:                                          (0): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (1): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (2): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (3): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (4): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (5): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                        )
0:                                        (layer_norm2): ModuleList(
0:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        )
0:                                        (memories): ModuleDict()
0:                                        (pred_layer): PredLayer(
0:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
0:                                        )
0:                                        (img_pred_layer): ImgPredLayer(
0:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
0:                                        )
0:                                      )
0: INFO - 04/18/20 13:26:22 - 0:03:37 - Number of parameters (model): 92180120
1: INFO - 04/18/20 13:26:27 - 0:03:42 - Model: TransformerModel(
1:                                        (projector): Projector(
1:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
1:                                        )
1:                                        (regional_encodings): RegionalEncodings(
1:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
1:                                        )
1:                                        (position_embeddings): Embedding(512, 512)
1:                                        (lang_embeddings): Embedding(3, 512)
1:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
1:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        (attentions): ModuleList(
1:                                          (0): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (1): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (2): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (3): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (4): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (5): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                        )
1:                                        (layer_norm1): ModuleList(
1:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        )
1:                                        (ffns): ModuleList(
1:                                          (0): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (1): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (2): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (3): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (4): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (5): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                        )
1:                                        (layer_norm2): ModuleList(
1:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        )
1:                                        (memories): ModuleDict()
1:                                        (pred_layer): PredLayer(
1:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
1:                                        )
1:                                        (img_pred_layer): ImgPredLayer(
1:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
1:                                        )
1:                                      )
1: INFO - 04/18/20 13:26:27 - 0:03:42 - Number of parameters (model): 92180120
2: INFO - 04/18/20 13:26:30 - 0:03:44 - Model: TransformerModel(
2:                                        (projector): Projector(
2:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
2:                                        )
2:                                        (regional_encodings): RegionalEncodings(
2:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
2:                                        )
2:                                        (position_embeddings): Embedding(512, 512)
2:                                        (lang_embeddings): Embedding(3, 512)
2:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
2:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        (attentions): ModuleList(
2:                                          (0): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (1): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (2): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (3): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (4): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (5): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                        )
2:                                        (layer_norm1): ModuleList(
2:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        )
2:                                        (ffns): ModuleList(
2:                                          (0): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (1): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (2): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (3): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (4): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (5): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                        )
2:                                        (layer_norm2): ModuleList(
2:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        )
2:                                        (memories): ModuleDict()
2:                                        (pred_layer): PredLayer(
2:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
2:                                        )
2:                                        (img_pred_layer): ImgPredLayer(
2:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
2:                                        )
2:                                      )
2: INFO - 04/18/20 13:26:30 - 0:03:45 - Number of parameters (model): 92180120
3: INFO - 04/18/20 13:26:32 - 0:03:47 - Removed 0 empty sentences.
3: 
3: INFO - 04/18/20 13:26:32 - 0:03:47 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/18/20 13:26:33 - 0:03:47 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:26:33 - 0:03:47 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
3: INFO - 04/18/20 13:26:33 - 0:03:48 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
3: INFO - 04/18/20 13:26:34 - 0:03:49 - Model: TransformerModel(
3:                                        (projector): Projector(
3:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
3:                                        )
3:                                        (regional_encodings): RegionalEncodings(
3:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
3:                                        )
3:                                        (position_embeddings): Embedding(512, 512)
3:                                        (lang_embeddings): Embedding(3, 512)
3:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
3:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        (attentions): ModuleList(
3:                                          (0): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (1): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (2): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (3): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (4): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (5): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm1): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (ffns): ModuleList(
3:                                          (0): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (1): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (2): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (3): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (4): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (5): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm2): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (memories): ModuleDict()
3:                                        (pred_layer): PredLayer(
3:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
3:                                        )
3:                                        (img_pred_layer): ImgPredLayer(
3:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
3:                                        )
3:                                      )
3: INFO - 04/18/20 13:26:34 - 0:03:49 - Number of parameters (model): 92180120
1: INFO - 04/18/20 13:26:37 - 0:03:52 - Model: TransformerModel(
1:                                        (projector): Projector(
1:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
1:                                        )
1:                                        (regional_encodings): RegionalEncodings(
1:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
1:                                        )
1:                                        (position_embeddings): Embedding(512, 512)
1:                                        (lang_embeddings): Embedding(3, 512)
1:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
1:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        (attentions): ModuleList(
1:                                          (0): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (1): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (2): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (3): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (4): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (5): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                        )
1:                                        (layer_norm1): ModuleList(
1:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        )
1:                                        (ffns): ModuleList(
1:                                          (0): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (1): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (2): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (3): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (4): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (5): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                        )
1:                                        (layer_norm2): ModuleList(
1:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        )
1:                                        (memories): ModuleDict()
1:                                        (pred_layer): PredLayer(
1:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
1:                                        )
1:                                        (img_pred_layer): ImgPredLayer(
1:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
1:                                        )
1:                                      )
1: INFO - 04/18/20 13:26:37 - 0:03:52 - Number of parameters (model): 92180120
3: INFO - 04/18/20 13:26:37 - 0:03:52 - Removed 0 empty sentences.
3: 
3: 
3: INFO - 04/18/20 13:26:38 - 0:03:52 - ============ Data summary
3: INFO - 04/18/20 13:26:38 - 0:03:52 - Parallel data      - train -        de-en:   3308331
3: INFO - 04/18/20 13:26:38 - 0:03:52 - Parallel data      - valid -        de-en:      5000
3: INFO - 04/18/20 13:26:38 - 0:03:52 - Parallel data      -  test -        de-en:      5000
3: 
0: INFO - 04/18/20 13:26:39 - 0:03:54 - Model: TransformerModel(
0:                                        (projector): Projector(
0:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
0:                                        )
0:                                        (regional_encodings): RegionalEncodings(
0:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
0:                                        )
0:                                        (position_embeddings): Embedding(512, 512)
0:                                        (lang_embeddings): Embedding(3, 512)
0:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
0:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        (attentions): ModuleList(
0:                                          (0): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (1): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (2): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (3): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (4): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (5): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                        )
0:                                        (layer_norm1): ModuleList(
0:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        )
0:                                        (ffns): ModuleList(
0:                                          (0): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (1): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (2): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (3): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (4): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (5): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                        )
0:                                        (layer_norm2): ModuleList(
0:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        )
0:                                        (memories): ModuleDict()
0:                                        (pred_layer): PredLayer(
0:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
0:                                        )
0:                                        (img_pred_layer): ImgPredLayer(
0:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
0:                                        )
0:                                      )
0: INFO - 04/18/20 13:26:39 - 0:03:54 - Number of parameters (model): 92180120
3: INFO - 04/18/20 13:26:55 - 0:04:10 - Model: TransformerModel(
3:                                        (projector): Projector(
3:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
3:                                        )
3:                                        (regional_encodings): RegionalEncodings(
3:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
3:                                        )
3:                                        (position_embeddings): Embedding(512, 512)
3:                                        (lang_embeddings): Embedding(3, 512)
3:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
3:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        (attentions): ModuleList(
3:                                          (0): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (1): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (2): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (3): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (4): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (5): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm1): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (ffns): ModuleList(
3:                                          (0): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (1): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (2): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (3): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (4): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (5): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm2): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (memories): ModuleDict()
3:                                        (pred_layer): PredLayer(
3:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
3:                                        )
3:                                        (img_pred_layer): ImgPredLayer(
3:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
3:                                        )
3:                                      )
3: INFO - 04/18/20 13:26:55 - 0:04:10 - Number of parameters (model): 92180120
3: INFO - 04/18/20 13:27:46 - 0:05:00 - Found 0 memories.
3: INFO - 04/18/20 13:27:46 - 0:05:00 - Found 6 FFN.
3: INFO - 04/18/20 13:27:46 - 0:05:00 - Found 108 parameters in model.
3: INFO - 04/18/20 13:27:46 - 0:05:00 - Using nn.parallel.DistributedDataParallel ...
3: --- Logging error ---
3: Traceback (most recent call last):
3:   File "/usr/lib64/python3.6/logging/__init__.py", line 993, in emit
3:     msg = self.format(record)
3:   File "/usr/lib64/python3.6/logging/__init__.py", line 839, in format
3:     return fmt.format(record)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/logger.py", line 26, in format
3:     message = record.getMessage()
3:   File "/usr/lib64/python3.6/logging/__init__.py", line 338, in getMessage
3:     msg = msg % self.args
3: TypeError: not all arguments converted during string formatting
3: Call stack:
3:   File "train.py", line 348, in <module>
3:     main(params)
3:   File "train.py", line 251, in main
3:     trainer = SingleTrainer(model, data, params)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
3:     super().__init__(data, params)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 66, in __init__
3:     logger.info("name: ", name)
3: Message: 'name: '
3: Arguments: ('model',)
3: --- Logging error ---
3: Traceback (most recent call last):
3:   File "/usr/lib64/python3.6/logging/__init__.py", line 993, in emit
3:     msg = self.format(record)
3:   File "/usr/lib64/python3.6/logging/__init__.py", line 839, in format
3:     return fmt.format(record)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/logger.py", line 26, in format
3:     message = record.getMessage()
3:   File "/usr/lib64/python3.6/logging/__init__.py", line 338, in getMessage
3:     msg = msg % self.args
3: TypeError: not all arguments converted during string formatting
3: Call stack:
3:   File "train.py", line 348, in <module>
3:     main(params)
3:   File "train.py", line 251, in main
3:     trainer = SingleTrainer(model, data, params)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
3:     super().__init__(data, params)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 66, in __init__
3:     logger.info("name: ", name)
3: Message: 'name: '
3: Arguments: ('model',)
0: INFO - 04/18/20 13:27:54 - 0:05:09 - Found 0 memories.
0: INFO - 04/18/20 13:27:54 - 0:05:09 - Found 6 FFN.
0: INFO - 04/18/20 13:27:54 - 0:05:09 - Found 108 parameters in model.
0: INFO - 04/18/20 13:27:54 - 0:05:09 - Using nn.parallel.DistributedDataParallel ...
0: --- Logging error ---
0: Traceback (most recent call last):
0:   File "/usr/lib64/python3.6/logging/__init__.py", line 993, in emit
0:     msg = self.format(record)
0:   File "/usr/lib64/python3.6/logging/__init__.py", line 839, in format
0:     return fmt.format(record)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/logger.py", line 26, in format
0:     message = record.getMessage()
0:   File "/usr/lib64/python3.6/logging/__init__.py", line 338, in getMessage
0:     msg = msg % self.args
0: TypeError: not all arguments converted during string formatting
0: Call stack:
0:   File "train.py", line 348, in <module>
0:     main(params)
0:   File "train.py", line 251, in main
0:     trainer = SingleTrainer(model, data, params)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
0:     super().__init__(data, params)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 66, in __init__
0:     logger.info("name: ", name)
0: Message: 'name: '
0: Arguments: ('model',)
0: --- Logging error ---
0: Traceback (most recent call last):
0:   File "/usr/lib64/python3.6/logging/__init__.py", line 993, in emit
0:     msg = self.format(record)
0:   File "/usr/lib64/python3.6/logging/__init__.py", line 839, in format
0:     return fmt.format(record)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/logger.py", line 26, in format
0:     message = record.getMessage()
0:   File "/usr/lib64/python3.6/logging/__init__.py", line 338, in getMessage
0:     msg = msg % self.args
0: TypeError: not all arguments converted during string formatting
0: Call stack:
0:   File "train.py", line 348, in <module>
0:     main(params)
0:   File "train.py", line 251, in main
0:     trainer = SingleTrainer(model, data, params)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
0:     super().__init__(data, params)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 66, in __init__
0:     logger.info("name: ", name)
0: Message: 'name: '
0: Arguments: ('model',)
1: INFO - 04/18/20 13:27:58 - 0:05:12 - Found 0 memories.
1: INFO - 04/18/20 13:27:58 - 0:05:12 - Found 6 FFN.
1: INFO - 04/18/20 13:27:58 - 0:05:12 - Found 108 parameters in model.
1: INFO - 04/18/20 13:27:58 - 0:05:12 - Using nn.parallel.DistributedDataParallel ...
1: --- Logging error ---
1: Traceback (most recent call last):
1:   File "/usr/lib64/python3.6/logging/__init__.py", line 993, in emit
1:     msg = self.format(record)
1:   File "/usr/lib64/python3.6/logging/__init__.py", line 839, in format
1:     return fmt.format(record)
1:   File "/home/menekse/xlm/Animal/XLM-master/src/logger.py", line 26, in format
1:     message = record.getMessage()
1:   File "/usr/lib64/python3.6/logging/__init__.py", line 338, in getMessage
1:     msg = msg % self.args
1: TypeError: not all arguments converted during string formatting
1: Call stack:
1:   File "train.py", line 348, in <module>
1:     main(params)
1:   File "train.py", line 251, in main
1:     trainer = SingleTrainer(model, data, params)
1:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
1:     super().__init__(data, params)
1:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 66, in __init__
1:     logger.info("name: ", name)
1: Message: 'name: '
1: Arguments: ('model',)
1: --- Logging error ---
1: Traceback (most recent call last):
1:   File "/usr/lib64/python3.6/logging/__init__.py", line 993, in emit
1:     msg = self.format(record)
1:   File "/usr/lib64/python3.6/logging/__init__.py", line 839, in format
1:     return fmt.format(record)
1:   File "/home/menekse/xlm/Animal/XLM-master/src/logger.py", line 26, in format
1:     message = record.getMessage()
1:   File "/usr/lib64/python3.6/logging/__init__.py", line 338, in getMessage
1:     msg = msg % self.args
1: TypeError: not all arguments converted during string formatting
1: Call stack:
1:   File "train.py", line 348, in <module>
1:     main(params)
1:   File "train.py", line 251, in main
1:     trainer = SingleTrainer(model, data, params)
1:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
1:     super().__init__(data, params)
1:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 66, in __init__
1:     logger.info("name: ", name)
1: Message: 'name: '
1: Arguments: ('model',)
2: INFO - 04/18/20 13:28:00 - 0:05:14 - Found 0 memories.
2: INFO - 04/18/20 13:28:00 - 0:05:14 - Found 6 FFN.
2: INFO - 04/18/20 13:28:00 - 0:05:14 - Found 108 parameters in model.
2: INFO - 04/18/20 13:28:00 - 0:05:14 - Using nn.parallel.DistributedDataParallel ...
2: --- Logging error ---
2: Traceback (most recent call last):
2:   File "/usr/lib64/python3.6/logging/__init__.py", line 993, in emit
2:     msg = self.format(record)
2:   File "/usr/lib64/python3.6/logging/__init__.py", line 839, in format
2:     return fmt.format(record)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/logger.py", line 26, in format
2:     message = record.getMessage()
2:   File "/usr/lib64/python3.6/logging/__init__.py", line 338, in getMessage
2:     msg = msg % self.args
2: TypeError: not all arguments converted during string formatting
2: Call stack:
2:   File "train.py", line 348, in <module>
2:     main(params)
2:   File "train.py", line 251, in main
2:     trainer = SingleTrainer(model, data, params)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
2:     super().__init__(data, params)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 66, in __init__
2:     logger.info("name: ", name)
2: Message: 'name: '
2: Arguments: ('model',)
2: --- Logging error ---
2: Traceback (most recent call last):
2:   File "/usr/lib64/python3.6/logging/__init__.py", line 993, in emit
2:     msg = self.format(record)
2:   File "/usr/lib64/python3.6/logging/__init__.py", line 839, in format
2:     return fmt.format(record)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/logger.py", line 26, in format
2:     message = record.getMessage()
2:   File "/usr/lib64/python3.6/logging/__init__.py", line 338, in getMessage
2:     msg = msg % self.args
2: TypeError: not all arguments converted during string formatting
2: Call stack:
2:   File "train.py", line 348, in <module>
2:     main(params)
2:   File "train.py", line 251, in main
2:     trainer = SingleTrainer(model, data, params)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
2:     super().__init__(data, params)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 66, in __init__
2:     logger.info("name: ", name)
2: Message: 'name: '
2: Arguments: ('model',)
2: INFO - 04/18/20 13:28:03 - 0:05:18 - Found 0 memories.
2: INFO - 04/18/20 13:28:03 - 0:05:18 - Found 6 FFN.
2: INFO - 04/18/20 13:28:03 - 0:05:18 - Found 108 parameters in model.
2: INFO - 04/18/20 13:28:03 - 0:05:18 - Using nn.parallel.DistributedDataParallel ...
2: --- Logging error ---
2: Traceback (most recent call last):
2:   File "/usr/lib64/python3.6/logging/__init__.py", line 993, in emit
2:     msg = self.format(record)
2:   File "/usr/lib64/python3.6/logging/__init__.py", line 839, in format
2:     return fmt.format(record)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/logger.py", line 26, in format
2:     message = record.getMessage()
2:   File "/usr/lib64/python3.6/logging/__init__.py", line 338, in getMessage
2:     msg = msg % self.args
2: TypeError: not all arguments converted during string formatting
2: Call stack:
2:   File "train.py", line 348, in <module>
2:     main(params)
2:   File "train.py", line 251, in main
2:     trainer = SingleTrainer(model, data, params)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
2:     super().__init__(data, params)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 66, in __init__
2:     logger.info("name: ", name)
2: Message: 'name: '
2: Arguments: ('model',)
2: --- Logging error ---
2: Traceback (most recent call last):
2:   File "/usr/lib64/python3.6/logging/__init__.py", line 993, in emit
2:     msg = self.format(record)
2:   File "/usr/lib64/python3.6/logging/__init__.py", line 839, in format
2:     return fmt.format(record)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/logger.py", line 26, in format
2:     message = record.getMessage()
2:   File "/usr/lib64/python3.6/logging/__init__.py", line 338, in getMessage
2:     msg = msg % self.args
2: TypeError: not all arguments converted during string formatting
2: Call stack:
2:   File "train.py", line 348, in <module>
2:     main(params)
2:   File "train.py", line 251, in main
2:     trainer = SingleTrainer(model, data, params)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
2:     super().__init__(data, params)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 66, in __init__
2:     logger.info("name: ", name)
2: Message: 'name: '
2: Arguments: ('model',)
1: INFO - 04/18/20 13:28:05 - 0:05:20 - Found 0 memories.
1: INFO - 04/18/20 13:28:05 - 0:05:20 - Found 6 FFN.
1: INFO - 04/18/20 13:28:05 - 0:05:20 - Found 108 parameters in model.
1: INFO - 04/18/20 13:28:05 - 0:05:20 - Using nn.parallel.DistributedDataParallel ...
1: --- Logging error ---
1: Traceback (most recent call last):
1:   File "/usr/lib64/python3.6/logging/__init__.py", line 993, in emit
1:     msg = self.format(record)
1:   File "/usr/lib64/python3.6/logging/__init__.py", line 839, in format
1:     return fmt.format(record)
1:   File "/home/menekse/xlm/Animal/XLM-master/src/logger.py", line 26, in format
1:     message = record.getMessage()
1:   File "/usr/lib64/python3.6/logging/__init__.py", line 338, in getMessage
1:     msg = msg % self.args
1: TypeError: not all arguments converted during string formatting
1: Call stack:
1:   File "train.py", line 348, in <module>
1:     main(params)
1:   File "train.py", line 251, in main
1:     trainer = SingleTrainer(model, data, params)
1:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
1:     super().__init__(data, params)
1:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 66, in __init__
1:     logger.info("name: ", name)
1: Message: 'name: '
1: Arguments: ('model',)
1: --- Logging error ---
1: Traceback (most recent call last):
1:   File "/usr/lib64/python3.6/logging/__init__.py", line 993, in emit
1:     msg = self.format(record)
1:   File "/usr/lib64/python3.6/logging/__init__.py", line 839, in format
1:     return fmt.format(record)
1:   File "/home/menekse/xlm/Animal/XLM-master/src/logger.py", line 26, in format
1:     message = record.getMessage()
1:   File "/usr/lib64/python3.6/logging/__init__.py", line 338, in getMessage
1:     msg = msg % self.args
1: TypeError: not all arguments converted during string formatting
1: Call stack:
1:   File "train.py", line 348, in <module>
1:     main(params)
1:   File "train.py", line 251, in main
1:     trainer = SingleTrainer(model, data, params)
1:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
1:     super().__init__(data, params)
1:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 66, in __init__
1:     logger.info("name: ", name)
1: Message: 'name: '
1: Arguments: ('model',)
3: INFO - 04/18/20 13:28:07 - 0:05:21 - Found 0 memories.
3: INFO - 04/18/20 13:28:07 - 0:05:21 - Found 6 FFN.
3: INFO - 04/18/20 13:28:07 - 0:05:21 - Found 108 parameters in model.
3: INFO - 04/18/20 13:28:07 - 0:05:21 - Using nn.parallel.DistributedDataParallel ...
3: --- Logging error ---
3: Traceback (most recent call last):
3:   File "/usr/lib64/python3.6/logging/__init__.py", line 993, in emit
3:     msg = self.format(record)
3:   File "/usr/lib64/python3.6/logging/__init__.py", line 839, in format
3:     return fmt.format(record)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/logger.py", line 26, in format
3:     message = record.getMessage()
3:   File "/usr/lib64/python3.6/logging/__init__.py", line 338, in getMessage
3:     msg = msg % self.args
3: TypeError: not all arguments converted during string formatting
3: Call stack:
3:   File "train.py", line 348, in <module>
3:     main(params)
3:   File "train.py", line 251, in main
3:     trainer = SingleTrainer(model, data, params)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
3:     super().__init__(data, params)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 66, in __init__
3:     logger.info("name: ", name)
3: Message: 'name: '
3: Arguments: ('model',)
3: --- Logging error ---
3: Traceback (most recent call last):
3:   File "/usr/lib64/python3.6/logging/__init__.py", line 993, in emit
3:     msg = self.format(record)
3:   File "/usr/lib64/python3.6/logging/__init__.py", line 839, in format
3:     return fmt.format(record)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/logger.py", line 26, in format
3:     message = record.getMessage()
3:   File "/usr/lib64/python3.6/logging/__init__.py", line 338, in getMessage
3:     msg = msg % self.args
3: TypeError: not all arguments converted during string formatting
3: Call stack:
3:   File "train.py", line 348, in <module>
3:     main(params)
3:   File "train.py", line 251, in main
3:     trainer = SingleTrainer(model, data, params)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
3:     super().__init__(data, params)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 66, in __init__
3:     logger.info("name: ", name)
3: Message: 'name: '
3: Arguments: ('model',)
0: INFO - 04/18/20 13:28:11 - 0:05:26 - Found 0 memories.
0: INFO - 04/18/20 13:28:11 - 0:05:26 - Found 6 FFN.
0: INFO - 04/18/20 13:28:11 - 0:05:26 - Found 108 parameters in model.
0: INFO - 04/18/20 13:28:11 - 0:05:26 - Using nn.parallel.DistributedDataParallel ...
0: --- Logging error ---
0: Traceback (most recent call last):
0:   File "/usr/lib64/python3.6/logging/__init__.py", line 993, in emit
0:     msg = self.format(record)
0:   File "/usr/lib64/python3.6/logging/__init__.py", line 839, in format
0:     return fmt.format(record)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/logger.py", line 26, in format
0:     message = record.getMessage()
0:   File "/usr/lib64/python3.6/logging/__init__.py", line 338, in getMessage
0:     msg = msg % self.args
0: TypeError: not all arguments converted during string formatting
0: Call stack:
0:   File "train.py", line 348, in <module>
0:     main(params)
0:   File "train.py", line 251, in main
0:     trainer = SingleTrainer(model, data, params)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
0:     super().__init__(data, params)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 66, in __init__
0:     logger.info("name: ", name)
0: Message: 'name: '
0: Arguments: ('model',)
0: --- Logging error ---
0: Traceback (most recent call last):
0:   File "/usr/lib64/python3.6/logging/__init__.py", line 993, in emit
0:     msg = self.format(record)
0:   File "/usr/lib64/python3.6/logging/__init__.py", line 839, in format
0:     return fmt.format(record)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/logger.py", line 26, in format
0:     message = record.getMessage()
0:   File "/usr/lib64/python3.6/logging/__init__.py", line 338, in getMessage
0:     msg = msg % self.args
0: TypeError: not all arguments converted during string formatting
0: Call stack:
0:   File "train.py", line 348, in <module>
0:     main(params)
0:   File "train.py", line 251, in main
0:     trainer = SingleTrainer(model, data, params)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
0:     super().__init__(data, params)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 66, in __init__
0:     logger.info("name: ", name)
0: Message: 'name: '
0: Arguments: ('model',)
3: INFO - 04/18/20 13:28:22 - 0:05:37 - Found 0 memories.
3: INFO - 04/18/20 13:28:22 - 0:05:37 - Found 6 FFN.
3: INFO - 04/18/20 13:28:22 - 0:05:37 - Found 108 parameters in model.
3: INFO - 04/18/20 13:28:22 - 0:05:37 - Using nn.parallel.DistributedDataParallel ...
3: --- Logging error ---
3: Traceback (most recent call last):
3:   File "/usr/lib64/python3.6/logging/__init__.py", line 993, in emit
3:     msg = self.format(record)
3:   File "/usr/lib64/python3.6/logging/__init__.py", line 839, in format
3:     return fmt.format(record)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/logger.py", line 26, in format
3:     message = record.getMessage()
3:   File "/usr/lib64/python3.6/logging/__init__.py", line 338, in getMessage
3:     msg = msg % self.args
3: TypeError: not all arguments converted during string formatting
3: Call stack:
3:   File "train.py", line 348, in <module>
3:     main(params)
3:   File "train.py", line 251, in main
3:     trainer = SingleTrainer(model, data, params)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
3:     super().__init__(data, params)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 66, in __init__
3:     logger.info("name: ", name)
3: Message: 'name: '
3: Arguments: ('model',)
3: --- Logging error ---
3: Traceback (most recent call last):
3:   File "/usr/lib64/python3.6/logging/__init__.py", line 993, in emit
3:     msg = self.format(record)
3:   File "/usr/lib64/python3.6/logging/__init__.py", line 839, in format
3:     return fmt.format(record)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/logger.py", line 26, in format
3:     message = record.getMessage()
3:   File "/usr/lib64/python3.6/logging/__init__.py", line 338, in getMessage
3:     msg = msg % self.args
3: TypeError: not all arguments converted during string formatting
3: Call stack:
3:   File "train.py", line 348, in <module>
3:     main(params)
3:   File "train.py", line 251, in main
3:     trainer = SingleTrainer(model, data, params)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
3:     super().__init__(data, params)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 66, in __init__
3:     logger.info("name: ", name)
3: Message: 'name: '
3: Arguments: ('model',)
2: Traceback (most recent call last):
2:   File "train.py", line 348, in <module>
2:     main(params)
2:   File "train.py", line 251, in main
2:     trainer = SingleTrainer(model, data, params)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
2:     super().__init__(data, params)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 67, in __init__
2:     setattr(self, name, nn.parallel.DistributedDataParallel(getattr(self, name), device_ids=[params.local_rank], output_device=params.local_rank, broadcast_buffers=True))
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 303, in __init__
2:     self.broadcast_bucket_size)
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 485, in _distributed_broadcast_coalesced
2:     dist._broadcast_coalesced(self.process_group, tensors, buffer_size)
2: RuntimeError: NCCL error in: /pytorch/torch/lib/c10d/ProcessGroupNCCL.cpp:410, unhandled system error, NCCL version 2.4.8
3: Traceback (most recent call last):
3:   File "train.py", line 348, in <module>
3:     main(params)
3:   File "train.py", line 251, in main
3:     trainer = SingleTrainer(model, data, params)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
3:     super().__init__(data, params)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 67, in __init__
3:     setattr(self, name, nn.parallel.DistributedDataParallel(getattr(self, name), device_ids=[params.local_rank], output_device=params.local_rank, broadcast_buffers=True))
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 303, in __init__
3:     self.broadcast_bucket_size)
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 485, in _distributed_broadcast_coalesced
3:     dist._broadcast_coalesced(self.process_group, tensors, buffer_size)
3: RuntimeError: NCCL error in: /pytorch/torch/lib/c10d/ProcessGroupNCCL.cpp:410, unhandled system error, NCCL version 2.4.8
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 3081 ON hanabi CANCELLED AT 2020-04-18T13:30:31 ***
0: slurmstepd: error: *** STEP 3081.0 ON hanabi CANCELLED AT 2020-04-18T13:30:31 ***
