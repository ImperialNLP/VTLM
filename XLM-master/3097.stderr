/var/spool/slurm/d/job03097/slurm_script: line 15: {workdir}/3097.stdout: No such file or directory
/var/spool/slurm/d/job03097/slurm_script: line 16: {workdir}/3097.stdout: No such file or directory
/var/spool/slurm/d/job03097/slurm_script: line 17: {workdir}/3097.stdout: No such file or directory
/var/spool/slurm/d/job03097/slurm_script: line 18: {workdir}/3097.stdout: No such file or directory
/var/spool/slurm/d/job03097/slurm_script: line 19: {workdir}/3097.stdout: No such file or directory
/var/spool/slurm/d/job03097/slurm_script: line 20: {workdir}/3097.stdout: No such file or directory
5: FAISS library was not found.
5: FAISS not available. Switching to standard nearest neighbors search implementation.
1: FAISS library was not found.
1: FAISS not available. Switching to standard nearest neighbors search implementation.
3: FAISS library was not found.
3: FAISS not available. Switching to standard nearest neighbors search implementation.
2: FAISS library was not found.
2: FAISS not available. Switching to standard nearest neighbors search implementation.
5: FAISS library was not found.
5: FAISS not available. Switching to standard nearest neighbors search implementation.
4: FAISS library was not found.
4: FAISS not available. Switching to standard nearest neighbors search implementation.
1: FAISS library was not found.
1: FAISS not available. Switching to standard nearest neighbors search implementation.
5: FAISS library was not found.
5: FAISS not available. Switching to standard nearest neighbors search implementation.
1: FAISS library was not found.
1: FAISS not available. Switching to standard nearest neighbors search implementation.
0: FAISS library was not found.
0: FAISS not available. Switching to standard nearest neighbors search implementation.
0: FAISS library was not found.
0: FAISS not available. Switching to standard nearest neighbors search implementation.
4: FAISS library was not found.
4: FAISS not available. Switching to standard nearest neighbors search implementation.
2: FAISS library was not found.
2: FAISS not available. Switching to standard nearest neighbors search implementation.
0: FAISS library was not found.
0: FAISS not available. Switching to standard nearest neighbors search implementation.
3: FAISS library was not found.
3: FAISS not available. Switching to standard nearest neighbors search implementation.
2: FAISS library was not found.
2: FAISS not available. Switching to standard nearest neighbors search implementation.
3: FAISS library was not found.
3: FAISS not available. Switching to standard nearest neighbors search implementation.
4: FAISS library was not found.
4: FAISS not available. Switching to standard nearest neighbors search implementation.
3: Traceback (most recent call last):
3:   File "train.py", line 348, in <module>
3:     main(params)
3:   File "train.py", line 230, in main
3:     init_distributed_mode(params)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/slurm.py", line 171, in init_distributed_mode
5: Traceback (most recent call last):
5:   File "train.py", line 348, in <module>
3:     backend='nccl',
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py", line 397, in init_process_group
3:     store, rank, world_size = next(rendezvous_iterator)
5:     main(params)
5:   File "train.py", line 230, in main
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/rendezvous.py", line 168, in _env_rendezvous_handler
5:     init_distributed_mode(params)
5:   File "/home/menekse/xlm/Animal/XLM-master/src/slurm.py", line 171, in init_distributed_mode
3:     store = TCPStore(master_addr, master_port, world_size, start_daemon)
3: RuntimeError: Address already in use
5:     backend='nccl',
5:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py", line 397, in init_process_group
5:     store, rank, world_size = next(rendezvous_iterator)
5:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/rendezvous.py", line 168, in _env_rendezvous_handler
5:     store = TCPStore(master_addr, master_port, world_size, start_daemon)
5: RuntimeError: Address already in use
4: Traceback (most recent call last):
4:   File "train.py", line 348, in <module>
4:     main(params)
4:   File "train.py", line 230, in main
4:     init_distributed_mode(params)
4:   File "/home/menekse/xlm/Animal/XLM-master/src/slurm.py", line 171, in init_distributed_mode
4:     backend='nccl',
4:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py", line 397, in init_process_group
4:     store, rank, world_size = next(rendezvous_iterator)
4:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/rendezvous.py", line 168, in _env_rendezvous_handler
4:     store = TCPStore(master_addr, master_port, world_size, start_daemon)
4: RuntimeError: Address already in use
3: Traceback (most recent call last):
3:   File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
3:     "__main__", mod_spec)
3:   File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
3:     exec(code, run_globals)
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 263, in <module>
3:     main()
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 259, in main
3:     cmd=cmd)
3: subprocess.CalledProcessError: Command '['/home/menekse/virtualenvs/torch_env/bin/python', '-u', 'train.py', '--local_rank=2', '--exp_name', 'xlm_en_de_tlm', '--dump_path', '/data/menekse/dumped', '--data_path', '/data/shared/ConceptualCaptions/XLM_data/50k', '--lgs', 'en-de', '--clm_steps', '', '--mlm_steps', 'en-de', '--emb_dim', '512', '--n_layers', '6', '--n_heads', '8', '--dropout', '0.1', '--attention_dropout', '0.1', '--gelu_activation', 'true', '--batch_size', '32', '--bptt', '256', '--optimizer', 'adam,lr=0.0001', '--epoch_size', '300000', '--max_epoch', '100000', '--validation_metrics', 'valid_en_de_mlm_ppl', '--stopping_criterion', '_valid_mlm_ppl,25', '--fp16', 'false', '--image_names', '/data/shared/ConceptualCaptions/XLM_data/50k', '--reload_model', '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth', '--save_periodic', '2']' returned non-zero exit status 1.
5: Traceback (most recent call last):
5:   File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
5:     "__main__", mod_spec)
5:   File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
5:     exec(code, run_globals)
5:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 263, in <module>
5:     main()
5:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 259, in main
5:     cmd=cmd)
5: subprocess.CalledProcessError: Command '['/home/menekse/virtualenvs/torch_env/bin/python', '-u', 'train.py', '--local_rank=2', '--exp_name', 'xlm_en_de_tlm', '--dump_path', '/data/menekse/dumped', '--data_path', '/data/shared/ConceptualCaptions/XLM_data/50k', '--lgs', 'en-de', '--clm_steps', '', '--mlm_steps', 'en-de', '--emb_dim', '512', '--n_layers', '6', '--n_heads', '8', '--dropout', '0.1', '--attention_dropout', '0.1', '--gelu_activation', 'true', '--batch_size', '32', '--bptt', '256', '--optimizer', 'adam,lr=0.0001', '--epoch_size', '300000', '--max_epoch', '100000', '--validation_metrics', 'valid_en_de_mlm_ppl', '--stopping_criterion', '_valid_mlm_ppl,25', '--fp16', 'false', '--image_names', '/data/shared/ConceptualCaptions/XLM_data/50k', '--reload_model', '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth', '--save_periodic', '2']' returned non-zero exit status 1.
1: INFO - 04/21/20 23:10:38 - 0:00:00 - ============ Initialized logger ============
1: INFO - 04/21/20 23:10:38 - 0:00:00 - accumulate_gradients: 1
1:                                      ae_steps: []
1:                                      amp: -1
1:                                      asm: False
1:                                      attention_dropout: 0.1
1:                                      batch_size: 32
1:                                      beam_size: 1
1:                                      bptt: 256
1:                                      bt_src_langs: []
1:                                      bt_steps: []
1:                                      clip_grad_norm: 5
1:                                      clm_steps: []
1:                                      command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2 --exp_id "3097"
1:                                      context_size: 0
1:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
1:                                      debug: False
1:                                      debug_slurm: False
1:                                      debug_train: False
1:                                      dropout: 0.1
1:                                      dump_path: /data/menekse/dumped/xlm_en_de_tlm/3097
1:                                      early_stopping: False
1:                                      emb_dim: 512
1:                                      encoder_only: True
1:                                      epoch_size: 300000
1:                                      eval_bleu: False
1:                                      eval_only: False
1:                                      exp_id: 3097
1:                                      exp_name: xlm_en_de_tlm
1:                                      fp16: False
1:                                      gelu_activation: True
1:                                      global_rank: 1
1:                                      group_by_size: True
1:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
1:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
1:                                      is_master: False
1:                                      is_slurm_job: False
1:                                      lambda_ae: 1
1:                                      lambda_bt: 1
1:                                      lambda_clm: 1
1:                                      lambda_mlm: 1
1:                                      lambda_mt: 1
1:                                      lambda_pc: 1
1:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
1:                                      langs: ['en', 'de', 'img']
1:                                      length_penalty: 1
1:                                      lg_sampling_factor: -1
1:                                      lgs: en-de
1:                                      local_rank: 1
1:                                      master_port: -1
1:                                      max_batch_size: 0
1:                                      max_epoch: 100000
1:                                      max_len: 100
1:                                      max_vocab: -1
1:                                      min_count: 0
1:                                      mlm_steps: [('en', 'de')]
1:                                      mono_dataset: {}
1:                                      mt_steps: []
1:                                      multi_gpu: True
1:                                      multi_node: False
1:                                      n_gpu_per_node: 3
1:                                      n_heads: 8
1:                                      n_langs: 3
1:                                      n_layers: 6
1:                                      n_nodes: 1
1:                                      node_id: 0
1:                                      only_vlm: False
1:                                      optimizer: adam,lr=0.0001
1:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
1:                                      pc_steps: []
1:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
1:                                      reload_checkpoint: 
1:                                      reload_emb: 
1:                                      reload_model: /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth
1:                                      sample_alpha: 0
1:                                      save_periodic: 2
1:                                      share_inout_emb: True
1:                                      sinusoidal_embeddings: False
1:                                      split_data: False
1:                                      stopping_criterion: _valid_mlm_ppl,25
1:                                      tokens_per_batch: -1
1:                                      use_lang_emb: True
1:                                      use_memory: False
1:                                      validation_metrics: valid_en_de_mlm_ppl
1:                                      vlm_steps: [('en', 'de')]
1:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
1:                                      word_blank: 0
1:                                      word_dropout: 0
1:                                      word_keep: 0.1
1:                                      word_mask: 0.8
1:                                      word_mask_keep_rand: 0.8,0.1,0.1
1:                                      word_pred: 0.15
1:                                      word_rand: 0.1
1:                                      word_shuffle: 0
1:                                      world_size: 3
1: INFO - 04/21/20 23:10:38 - 0:00:00 - The experiment will be stored in /data/menekse/dumped/xlm_en_de_tlm/3097
1:                                      
1: INFO - 04/21/20 23:10:38 - 0:00:00 - Running command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2
1: 
1: WARNING - 04/21/20 23:10:38 - 0:00:00 - Signal handler installed.
1: 
1: INFO - 04/21/20 23:10:38 - 0:00:00 - ============ Parallel data (de-en)
1: INFO - 04/21/20 23:10:38 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
4: Traceback (most recent call last):
4:   File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
4:     "__main__", mod_spec)
4:   File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
4:     exec(code, run_globals)
4:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 263, in <module>
4:     main()
4:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 259, in main
4:     cmd=cmd)
4: subprocess.CalledProcessError: Command '['/home/menekse/virtualenvs/torch_env/bin/python', '-u', 'train.py', '--local_rank=2', '--exp_name', 'xlm_en_de_tlm', '--dump_path', '/data/menekse/dumped', '--data_path', '/data/shared/ConceptualCaptions/XLM_data/50k', '--lgs', 'en-de', '--clm_steps', '', '--mlm_steps', 'en-de', '--emb_dim', '512', '--n_layers', '6', '--n_heads', '8', '--dropout', '0.1', '--attention_dropout', '0.1', '--gelu_activation', 'true', '--batch_size', '32', '--bptt', '256', '--optimizer', 'adam,lr=0.0001', '--epoch_size', '300000', '--max_epoch', '100000', '--validation_metrics', 'valid_en_de_mlm_ppl', '--stopping_criterion', '_valid_mlm_ppl,25', '--fp16', 'false', '--image_names', '/data/shared/ConceptualCaptions/XLM_data/50k', '--reload_model', '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth', '--save_periodic', '2']' returned non-zero exit status 1.
5: INFO - 04/21/20 23:10:38 - 0:00:00 - ============ Initialized logger ============
5: INFO - 04/21/20 23:10:38 - 0:00:00 - accumulate_gradients: 1
5:                                      ae_steps: []
5:                                      amp: -1
5:                                      asm: False
5:                                      attention_dropout: 0.1
5:                                      batch_size: 32
5:                                      beam_size: 1
5:                                      bptt: 256
5:                                      bt_src_langs: []
5:                                      bt_steps: []
5:                                      clip_grad_norm: 5
5:                                      clm_steps: []
5:                                      command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2 --exp_id "3097"
5:                                      context_size: 0
5:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
5:                                      debug: False
5:                                      debug_slurm: False
5:                                      debug_train: False
5:                                      dropout: 0.1
5:                                      dump_path: /data/menekse/dumped/xlm_en_de_tlm/3097
5:                                      early_stopping: False
5:                                      emb_dim: 512
5:                                      encoder_only: True
5:                                      epoch_size: 300000
5:                                      eval_bleu: False
5:                                      eval_only: False
5:                                      exp_id: 3097
5:                                      exp_name: xlm_en_de_tlm
5:                                      fp16: False
5:                                      gelu_activation: True
5:                                      global_rank: 1
5:                                      group_by_size: True
5:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
5:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
5:                                      is_master: False
5:                                      is_slurm_job: False
5:                                      lambda_ae: 1
5:                                      lambda_bt: 1
5:                                      lambda_clm: 1
5:                                      lambda_mlm: 1
5:                                      lambda_mt: 1
5:                                      lambda_pc: 1
5:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
5:                                      langs: ['en', 'de', 'img']
5:                                      length_penalty: 1
5:                                      lg_sampling_factor: -1
5:                                      lgs: en-de
5:                                      local_rank: 1
5:                                      master_port: -1
5:                                      max_batch_size: 0
5:                                      max_epoch: 100000
5:                                      max_len: 100
5:                                      max_vocab: -1
5:                                      min_count: 0
5:                                      mlm_steps: [('en', 'de')]
5:                                      mono_dataset: {}
5:                                      mt_steps: []
5:                                      multi_gpu: True
5:                                      multi_node: False
5:                                      n_gpu_per_node: 3
5:                                      n_heads: 8
5:                                      n_langs: 3
5:                                      n_layers: 6
5:                                      n_nodes: 1
5:                                      node_id: 0
5:                                      only_vlm: False
5:                                      optimizer: adam,lr=0.0001
5:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
5:                                      pc_steps: []
5:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
5:                                      reload_checkpoint: 
5:                                      reload_emb: 
5:                                      reload_model: /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth
5:                                      sample_alpha: 0
5:                                      save_periodic: 2
5:                                      share_inout_emb: True
5:                                      sinusoidal_embeddings: False
5:                                      split_data: False
5:                                      stopping_criterion: _valid_mlm_ppl,25
5:                                      tokens_per_batch: -1
5:                                      use_lang_emb: True
5:                                      use_memory: False
5:                                      validation_metrics: valid_en_de_mlm_ppl
5:                                      vlm_steps: [('en', 'de')]
5:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
5:                                      word_blank: 0
5:                                      word_dropout: 0
5:                                      word_keep: 0.1
5:                                      word_mask: 0.8
5:                                      word_mask_keep_rand: 0.8,0.1,0.1
5:                                      word_pred: 0.15
5:                                      word_rand: 0.1
5:                                      word_shuffle: 0
5:                                      world_size: 3
5: INFO - 04/21/20 23:10:38 - 0:00:00 - The experiment will be stored in /data/menekse/dumped/xlm_en_de_tlm/3097
5:                                      
5: INFO - 04/21/20 23:10:38 - 0:00:00 - Running command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2
5: 
5: WARNING - 04/21/20 23:10:38 - 0:00:00 - Signal handler installed.
5: 
5: INFO - 04/21/20 23:10:38 - 0:00:00 - ============ Parallel data (de-en)
5: INFO - 04/21/20 23:10:38 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
1: INFO - 04/21/20 23:10:38 - 0:00:00 - ============ Initialized logger ============
1: INFO - 04/21/20 23:10:38 - 0:00:00 - accumulate_gradients: 1
1:                                      ae_steps: []
1:                                      amp: -1
1:                                      asm: False
1:                                      attention_dropout: 0.1
1:                                      batch_size: 32
1:                                      beam_size: 1
1:                                      bptt: 256
1:                                      bt_src_langs: []
1:                                      bt_steps: []
1:                                      clip_grad_norm: 5
1:                                      clm_steps: []
1:                                      command: python train.py --local_rank=0 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2 --exp_id "3097"
1:                                      context_size: 0
1:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
1:                                      debug: False
1:                                      debug_slurm: False
1:                                      debug_train: False
1:                                      dropout: 0.1
1:                                      dump_path: /data/menekse/dumped/xlm_en_de_tlm/3097
1:                                      early_stopping: False
1:                                      emb_dim: 512
1:                                      encoder_only: True
1:                                      epoch_size: 300000
1:                                      eval_bleu: False
1:                                      eval_only: False
1:                                      exp_id: 3097
1:                                      exp_name: xlm_en_de_tlm
1:                                      fp16: False
1:                                      gelu_activation: True
1:                                      global_rank: 0
1:                                      group_by_size: True
1:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
1:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
1:                                      is_master: True
1:                                      is_slurm_job: False
1:                                      lambda_ae: 1
1:                                      lambda_bt: 1
1:                                      lambda_clm: 1
1:                                      lambda_mlm: 1
1:                                      lambda_mt: 1
1:                                      lambda_pc: 1
1:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
1:                                      langs: ['en', 'de', 'img']
1:                                      length_penalty: 1
1:                                      lg_sampling_factor: -1
1:                                      lgs: en-de
1:                                      local_rank: 0
1:                                      master_port: -1
1:                                      max_batch_size: 0
1:                                      max_epoch: 100000
1:                                      max_len: 100
1:                                      max_vocab: -1
1:                                      min_count: 0
1:                                      mlm_steps: [('en', 'de')]
1:                                      mono_dataset: {}
1:                                      mt_steps: []
1:                                      multi_gpu: True
1:                                      multi_node: False
1:                                      n_gpu_per_node: 3
1:                                      n_heads: 8
1:                                      n_langs: 3
1:                                      n_layers: 6
1:                                      n_nodes: 1
1:                                      node_id: 0
1:                                      only_vlm: False
1:                                      optimizer: adam,lr=0.0001
1:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
1:                                      pc_steps: []
1:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
1:                                      reload_checkpoint: 
1:                                      reload_emb: 
1:                                      reload_model: /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth
1:                                      sample_alpha: 0
1:                                      save_periodic: 2
1:                                      share_inout_emb: True
1:                                      sinusoidal_embeddings: False
1:                                      split_data: False
1:                                      stopping_criterion: _valid_mlm_ppl,25
1:                                      tokens_per_batch: -1
1:                                      use_lang_emb: True
1:                                      use_memory: False
1:                                      validation_metrics: valid_en_de_mlm_ppl
1:                                      vlm_steps: [('en', 'de')]
1:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
1:                                      word_blank: 0
1:                                      word_dropout: 0
1:                                      word_keep: 0.1
1:                                      word_mask: 0.8
1:                                      word_mask_keep_rand: 0.8,0.1,0.1
1:                                      word_pred: 0.15
1:                                      word_rand: 0.1
1:                                      word_shuffle: 0
1:                                      world_size: 3
1: INFO - 04/21/20 23:10:38 - 0:00:00 - The experiment will be stored in /data/menekse/dumped/xlm_en_de_tlm/3097
1:                                      
1: INFO - 04/21/20 23:10:38 - 0:00:00 - Running command: python train.py --local_rank=0 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2
1: 
1: WARNING - 04/21/20 23:10:38 - 0:00:00 - Signal handler installed.
1: 
1: INFO - 04/21/20 23:10:38 - 0:00:00 - ============ Parallel data (de-en)
1: INFO - 04/21/20 23:10:38 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
srun: error: hanabi: task 3: Exited with exit code 1
3: INFO - 04/21/20 23:10:39 - 0:00:00 - ============ Initialized logger ============
3: INFO - 04/21/20 23:10:39 - 0:00:00 - accumulate_gradients: 1
3:                                      ae_steps: []
3:                                      amp: -1
3:                                      asm: False
3:                                      attention_dropout: 0.1
3:                                      batch_size: 32
3:                                      beam_size: 1
3:                                      bptt: 256
3:                                      bt_src_langs: []
3:                                      bt_steps: []
3:                                      clip_grad_norm: 5
3:                                      clm_steps: []
3:                                      command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2 --exp_id "3097"
3:                                      context_size: 0
3:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      debug: False
3:                                      debug_slurm: False
3:                                      debug_train: False
3:                                      dropout: 0.1
3:                                      dump_path: /data/menekse/dumped/xlm_en_de_tlm/3097
3:                                      early_stopping: False
3:                                      emb_dim: 512
3:                                      encoder_only: True
3:                                      epoch_size: 300000
3:                                      eval_bleu: False
3:                                      eval_only: False
3:                                      exp_id: 3097
3:                                      exp_name: xlm_en_de_tlm
3:                                      fp16: False
3:                                      gelu_activation: True
3:                                      global_rank: 2
3:                                      group_by_size: True
3:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
3:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      is_master: False
3:                                      is_slurm_job: False
3:                                      lambda_ae: 1
3:                                      lambda_bt: 1
3:                                      lambda_clm: 1
3:                                      lambda_mlm: 1
3:                                      lambda_mt: 1
3:                                      lambda_pc: 1
3:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
3:                                      langs: ['en', 'de', 'img']
3:                                      length_penalty: 1
3:                                      lg_sampling_factor: -1
3:                                      lgs: en-de
3:                                      local_rank: 2
3:                                      master_port: -1
3:                                      max_batch_size: 0
3:                                      max_epoch: 100000
3:                                      max_len: 100
3:                                      max_vocab: -1
3:                                      min_count: 0
3:                                      mlm_steps: [('en', 'de')]
3:                                      mono_dataset: {}
3:                                      mt_steps: []
3:                                      multi_gpu: True
3:                                      multi_node: False
3:                                      n_gpu_per_node: 3
3:                                      n_heads: 8
3:                                      n_langs: 3
3:                                      n_layers: 6
3:                                      n_nodes: 1
3:                                      node_id: 0
3:                                      only_vlm: False
3:                                      optimizer: adam,lr=0.0001
3:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      pc_steps: []
3:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
3:                                      reload_checkpoint: 
3:                                      reload_emb: 
3:                                      reload_model: /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth
3:                                      sample_alpha: 0
3:                                      save_periodic: 2
3:                                      share_inout_emb: True
3:                                      sinusoidal_embeddings: False
3:                                      split_data: False
3:                                      stopping_criterion: _valid_mlm_ppl,25
3:                                      tokens_per_batch: -1
3:                                      use_lang_emb: True
3:                                      use_memory: False
3:                                      validation_metrics: valid_en_de_mlm_ppl
3:                                      vlm_steps: [('en', 'de')]
3:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      word_blank: 0
3:                                      word_dropout: 0
3:                                      word_keep: 0.1
3:                                      word_mask: 0.8
3:                                      word_mask_keep_rand: 0.8,0.1,0.1
3:                                      word_pred: 0.15
3:                                      word_rand: 0.1
3:                                      word_shuffle: 0
3:                                      world_size: 3
3: INFO - 04/21/20 23:10:39 - 0:00:00 - The experiment will be stored in /data/menekse/dumped/xlm_en_de_tlm/3097
3:                                      
3: INFO - 04/21/20 23:10:39 - 0:00:00 - Running command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2
3: 
3: WARNING - 04/21/20 23:10:39 - 0:00:00 - Signal handler installed.
3: 
3: INFO - 04/21/20 23:10:39 - 0:00:00 - ============ Parallel data (de-en)
3: INFO - 04/21/20 23:10:39 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
2: Traceback (most recent call last):
2:   File "train.py", line 348, in <module>
2:     main(params)
2:   File "train.py", line 230, in main
2: INFO - 04/21/20 23:10:39 - 0:00:00 - ============ Initialized logger ============
2: INFO - 04/21/20 23:10:39 - 0:00:00 - accumulate_gradients: 1
2:                                      ae_steps: []
2:                                      amp: -1
2:                                      asm: False
2:                                      attention_dropout: 0.1
2:                                      batch_size: 32
2:                                      beam_size: 1
2:                                      bptt: 256
2:                                      bt_src_langs: []
2:                                      bt_steps: []
2:                                      clip_grad_norm: 5
2:                                      clm_steps: []
2:                                      command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2 --exp_id "3097"
2:                                      context_size: 0
2:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
2:                                      debug: False
2:                                      debug_slurm: False
2:                                      debug_train: False
2:                                      dropout: 0.1
2:                                      dump_path: /data/menekse/dumped/xlm_en_de_tlm/3097
2:                                      early_stopping: False
2:                                      emb_dim: 512
2:                                      encoder_only: True
2:                                      epoch_size: 300000
2:                                      eval_bleu: False
2:                                      eval_only: False
2:                                      exp_id: 3097
2:                                      exp_name: xlm_en_de_tlm
2:                                      fp16: False
2:                                      gelu_activation: True
2:                                      global_rank: 1
2:                                      group_by_size: True
2:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
2:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
2:                                      is_master: False
2:                                      is_slurm_job: False
2:                                      lambda_ae: 1
2:                                      lambda_bt: 1
2:                                      lambda_clm: 1
2:                                      lambda_mlm: 1
2:                                      lambda_mt: 1
2:                                      lambda_pc: 1
2:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
2:                                      langs: ['en', 'de', 'img']
2:                                      length_penalty: 1
2:                                      lg_sampling_factor: -1
2:                                      lgs: en-de
2:                                      local_rank: 1
2:                                      master_port: -1
2:                                      max_batch_size: 0
2:                                      max_epoch: 100000
2:                                      max_len: 100
2:                                      max_vocab: -1
2:                                      min_count: 0
2:                                      mlm_steps: [('en', 'de')]
2:                                      mono_dataset: {}
2:                                      mt_steps: []
2:                                      multi_gpu: True
2:                                      multi_node: False
2:                                      n_gpu_per_node: 3
2:                                      n_heads: 8
2:                                      n_langs: 3
2:                                      n_layers: 6
2:                                      n_nodes: 1
2:                                      node_id: 0
2:                                      only_vlm: False
2:                                      optimizer: adam,lr=0.0001
2:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
2:                                      pc_steps: []
2:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
2:                                      reload_checkpoint: 
2:                                      reload_emb: 
2:                                      reload_model: /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth
2:                                      sample_alpha: 0
2:                                      save_periodic: 2
2:                                      share_inout_emb: True
2:                                      sinusoidal_embeddings: False
2:                                      split_data: False
2:                                      stopping_criterion: _valid_mlm_ppl,25
2:                                      tokens_per_batch: -1
2:                                      use_lang_emb: True
2:                                      use_memory: False
2:                                      validation_metrics: valid_en_de_mlm_ppl
2:                                      vlm_steps: [('en', 'de')]
2:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
2:                                      word_blank: 0
2:                                      word_dropout: 0
2:                                      word_keep: 0.1
2:                                      word_mask: 0.8
2:                                      word_mask_keep_rand: 0.8,0.1,0.1
2:                                      word_pred: 0.15
2:                                      word_rand: 0.1
2:                                      word_shuffle: 0
2:                                      world_size: 3
2: INFO - 04/21/20 23:10:39 - 0:00:00 - The experiment will be stored in /data/menekse/dumped/xlm_en_de_tlm/3097
2:                                      
2: INFO - 04/21/20 23:10:39 - 0:00:00 - Running command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2
2: 
2: WARNING - 04/21/20 23:10:39 - 0:00:00 - Signal handler installed.
2: 
2: INFO - 04/21/20 23:10:39 - 0:00:00 - ============ Parallel data (de-en)
2: INFO - 04/21/20 23:10:39 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
0: Traceback (most recent call last):
0:   File "train.py", line 348, in <module>
0:     main(params)
0:   File "train.py", line 230, in main
0:     init_distributed_mode(params)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/slurm.py", line 171, in init_distributed_mode
0:     backend='nccl',
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py", line 397, in init_process_group
0:     store, rank, world_size = next(rendezvous_iterator)
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/rendezvous.py", line 168, in _env_rendezvous_handler
2:     init_distributed_mode(params)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/slurm.py", line 171, in init_distributed_mode
0:     store = TCPStore(master_addr, master_port, world_size, start_daemon)
0: RuntimeError: Address already in use
2:     backend='nccl',
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py", line 397, in init_process_group
2:     store, rank, world_size = next(rendezvous_iterator)
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/rendezvous.py", line 168, in _env_rendezvous_handler
2:     store = TCPStore(master_addr, master_port, world_size, start_daemon)
2: RuntimeError: Address already in use
1: INFO - 04/21/20 23:10:39 - 0:00:00 - ============ Initialized logger ============
1: INFO - 04/21/20 23:10:39 - 0:00:00 - accumulate_gradients: 1
1:                                      ae_steps: []
1:                                      amp: -1
1:                                      asm: False
1:                                      attention_dropout: 0.1
1:                                      batch_size: 32
1:                                      beam_size: 1
1:                                      bptt: 256
1:                                      bt_src_langs: []
1:                                      bt_steps: []
1:                                      clip_grad_norm: 5
1:                                      clm_steps: []
1:                                      command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2 --exp_id "3097"
1:                                      context_size: 0
1:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
1:                                      debug: False
1:                                      debug_slurm: False
1:                                      debug_train: False
1:                                      dropout: 0.1
1:                                      dump_path: /data/menekse/dumped/xlm_en_de_tlm/3097
1:                                      early_stopping: False
1:                                      emb_dim: 512
1:                                      encoder_only: True
1:                                      epoch_size: 300000
1:                                      eval_bleu: False
1:                                      eval_only: False
1:                                      exp_id: 3097
1:                                      exp_name: xlm_en_de_tlm
1:                                      fp16: False
1:                                      gelu_activation: True
1:                                      global_rank: 2
1:                                      group_by_size: True
1:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
1:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
1:                                      is_master: False
1:                                      is_slurm_job: False
1:                                      lambda_ae: 1
1:                                      lambda_bt: 1
1:                                      lambda_clm: 1
1:                                      lambda_mlm: 1
1:                                      lambda_mt: 1
1:                                      lambda_pc: 1
1:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
1:                                      langs: ['en', 'de', 'img']
1:                                      length_penalty: 1
1:                                      lg_sampling_factor: -1
1:                                      lgs: en-de
1:                                      local_rank: 2
1:                                      master_port: -1
1:                                      max_batch_size: 0
1:                                      max_epoch: 100000
1:                                      max_len: 100
1:                                      max_vocab: -1
1:                                      min_count: 0
1:                                      mlm_steps: [('en', 'de')]
1:                                      mono_dataset: {}
1:                                      mt_steps: []
1:                                      multi_gpu: True
1:                                      multi_node: False
1:                                      n_gpu_per_node: 3
1:                                      n_heads: 8
1:                                      n_langs: 3
1:                                      n_layers: 6
1:                                      n_nodes: 1
1:                                      node_id: 0
1:                                      only_vlm: False
1:                                      optimizer: adam,lr=0.0001
1:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
1:                                      pc_steps: []
1:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
1:                                      reload_checkpoint: 
1:                                      reload_emb: 
1:                                      reload_model: /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth
1:                                      sample_alpha: 0
1:                                      save_periodic: 2
1:                                      share_inout_emb: True
1:                                      sinusoidal_embeddings: False
1:                                      split_data: False
1:                                      stopping_criterion: _valid_mlm_ppl,25
1:                                      tokens_per_batch: -1
1:                                      use_lang_emb: True
1:                                      use_memory: False
1:                                      validation_metrics: valid_en_de_mlm_ppl
1:                                      vlm_steps: [('en', 'de')]
1:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
1:                                      word_blank: 0
1:                                      word_dropout: 0
1:                                      word_keep: 0.1
1:                                      word_mask: 0.8
1:                                      word_mask_keep_rand: 0.8,0.1,0.1
1:                                      word_pred: 0.15
1:                                      word_rand: 0.1
1:                                      word_shuffle: 0
1:                                      world_size: 3
1: INFO - 04/21/20 23:10:39 - 0:00:00 - The experiment will be stored in /data/menekse/dumped/xlm_en_de_tlm/3097
1:                                      
1: INFO - 04/21/20 23:10:39 - 0:00:00 - Running command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2
1: 
1: WARNING - 04/21/20 23:10:39 - 0:00:00 - Signal handler installed.
1: 
1: INFO - 04/21/20 23:10:39 - 0:00:00 - ============ Parallel data (de-en)
1: INFO - 04/21/20 23:10:39 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
5: INFO - 04/21/20 23:10:39 - 0:00:00 - ============ Initialized logger ============
5: INFO - 04/21/20 23:10:39 - 0:00:00 - accumulate_gradients: 1
5:                                      ae_steps: []
5:                                      amp: -1
5:                                      asm: False
5:                                      attention_dropout: 0.1
5:                                      batch_size: 32
5:                                      beam_size: 1
5:                                      bptt: 256
5:                                      bt_src_langs: []
5:                                      bt_steps: []
5:                                      clip_grad_norm: 5
5:                                      clm_steps: []
5:                                      command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2 --exp_id "3097"
5:                                      context_size: 0
5:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
5:                                      debug: False
5:                                      debug_slurm: False
5:                                      debug_train: False
5:                                      dropout: 0.1
5:                                      dump_path: /data/menekse/dumped/xlm_en_de_tlm/3097
5:                                      early_stopping: False
5:                                      emb_dim: 512
5:                                      encoder_only: True
5:                                      epoch_size: 300000
5:                                      eval_bleu: False
5:                                      eval_only: False
5:                                      exp_id: 3097
5:                                      exp_name: xlm_en_de_tlm
5:                                      fp16: False
5:                                      gelu_activation: True
5:                                      global_rank: 2
5:                                      group_by_size: True
5:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
5:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
5:                                      is_master: False
5:                                      is_slurm_job: False
5:                                      lambda_ae: 1
5:                                      lambda_bt: 1
5:                                      lambda_clm: 1
5:                                      lambda_mlm: 1
5:                                      lambda_mt: 1
5:                                      lambda_pc: 1
5:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
5:                                      langs: ['en', 'de', 'img']
5:                                      length_penalty: 1
5:                                      lg_sampling_factor: -1
5:                                      lgs: en-de
5:                                      local_rank: 2
5:                                      master_port: -1
5:                                      max_batch_size: 0
5:                                      max_epoch: 100000
5:                                      max_len: 100
5:                                      max_vocab: -1
5:                                      min_count: 0
5:                                      mlm_steps: [('en', 'de')]
5:                                      mono_dataset: {}
5:                                      mt_steps: []
5:                                      multi_gpu: True
5:                                      multi_node: False
5:                                      n_gpu_per_node: 3
5:                                      n_heads: 8
5:                                      n_langs: 3
5:                                      n_layers: 6
5:                                      n_nodes: 1
5:                                      node_id: 0
5:                                      only_vlm: False
5:                                      optimizer: adam,lr=0.0001
5:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
5:                                      pc_steps: []
5:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
5:                                      reload_checkpoint: 
5:                                      reload_emb: 
5:                                      reload_model: /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth
5:                                      sample_alpha: 0
5:                                      save_periodic: 2
5:                                      share_inout_emb: True
5:                                      sinusoidal_embeddings: False
5:                                      split_data: False
5:                                      stopping_criterion: _valid_mlm_ppl,25
5:                                      tokens_per_batch: -1
5:                                      use_lang_emb: True
5:                                      use_memory: False
5:                                      validation_metrics: valid_en_de_mlm_ppl
5:                                      vlm_steps: [('en', 'de')]
5:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
5:                                      word_blank: 0
5:                                      word_dropout: 0
5:                                      word_keep: 0.1
5:                                      word_mask: 0.8
5:                                      word_mask_keep_rand: 0.8,0.1,0.1
5:                                      word_pred: 0.15
5:                                      word_rand: 0.1
5:                                      word_shuffle: 0
5:                                      world_size: 3
5: INFO - 04/21/20 23:10:39 - 0:00:00 - The experiment will be stored in /data/menekse/dumped/xlm_en_de_tlm/3097
5:                                      
5: INFO - 04/21/20 23:10:39 - 0:00:00 - Running command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2
5: 
5: WARNING - 04/21/20 23:10:39 - 0:00:00 - Signal handler installed.
5: 
5: INFO - 04/21/20 23:10:39 - 0:00:00 - ============ Parallel data (de-en)
5: INFO - 04/21/20 23:10:39 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
0: INFO - 04/21/20 23:10:39 - 0:00:00 - ============ Initialized logger ============
0: INFO - 04/21/20 23:10:39 - 0:00:00 - accumulate_gradients: 1
0:                                      ae_steps: []
0:                                      amp: -1
0:                                      asm: False
0:                                      attention_dropout: 0.1
0:                                      batch_size: 32
0:                                      beam_size: 1
0:                                      bptt: 256
0:                                      bt_src_langs: []
0:                                      bt_steps: []
0:                                      clip_grad_norm: 5
0:                                      clm_steps: []
0:                                      command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2 --exp_id "3097"
0:                                      context_size: 0
0:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
0:                                      debug: False
0:                                      debug_slurm: False
0:                                      debug_train: False
0:                                      dropout: 0.1
0:                                      dump_path: /data/menekse/dumped/xlm_en_de_tlm/3097
0:                                      early_stopping: False
0:                                      emb_dim: 512
0:                                      encoder_only: True
0:                                      epoch_size: 300000
0:                                      eval_bleu: False
0:                                      eval_only: False
0:                                      exp_id: 3097
0:                                      exp_name: xlm_en_de_tlm
0:                                      fp16: False
0:                                      gelu_activation: True
0:                                      global_rank: 1
0:                                      group_by_size: True
0:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
0:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
0:                                      is_master: False
0:                                      is_slurm_job: False
0:                                      lambda_ae: 1
0:                                      lambda_bt: 1
0:                                      lambda_clm: 1
0:                                      lambda_mlm: 1
0:                                      lambda_mt: 1
0:                                      lambda_pc: 1
0:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
0:                                      langs: ['en', 'de', 'img']
0:                                      length_penalty: 1
0:                                      lg_sampling_factor: -1
0:                                      lgs: en-de
0:                                      local_rank: 1
0:                                      master_port: -1
0:                                      max_batch_size: 0
0:                                      max_epoch: 100000
0:                                      max_len: 100
0:                                      max_vocab: -1
0:                                      min_count: 0
0:                                      mlm_steps: [('en', 'de')]
0:                                      mono_dataset: {}
0:                                      mt_steps: []
0:                                      multi_gpu: True
0:                                      multi_node: False
0:                                      n_gpu_per_node: 3
0:                                      n_heads: 8
0:                                      n_langs: 3
0:                                      n_layers: 6
0:                                      n_nodes: 1
0:                                      node_id: 0
0:                                      only_vlm: False
0:                                      optimizer: adam,lr=0.0001
0:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
0:                                      pc_steps: []
0:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
0:                                      reload_checkpoint: 
0:                                      reload_emb: 
0:                                      reload_model: /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth
0:                                      sample_alpha: 0
0:                                      save_periodic: 2
0:                                      share_inout_emb: True
0:                                      sinusoidal_embeddings: False
0:                                      split_data: False
0:                                      stopping_criterion: _valid_mlm_ppl,25
0:                                      tokens_per_batch: -1
0:                                      use_lang_emb: True
0:                                      use_memory: False
0:                                      validation_metrics: valid_en_de_mlm_ppl
0:                                      vlm_steps: [('en', 'de')]
0:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
0:                                      word_blank: 0
0:                                      word_dropout: 0
0:                                      word_keep: 0.1
0:                                      word_mask: 0.8
0:                                      word_mask_keep_rand: 0.8,0.1,0.1
0:                                      word_pred: 0.15
0:                                      word_rand: 0.1
0:                                      word_shuffle: 0
0:                                      world_size: 3
0: INFO - 04/21/20 23:10:39 - 0:00:00 - The experiment will be stored in /data/menekse/dumped/xlm_en_de_tlm/3097
4: INFO - 04/21/20 23:10:39 - 0:00:00 - ============ Initialized logger ============
0:                                      
0: INFO - 04/21/20 23:10:39 - 0:00:00 - Running command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2
4: INFO - 04/21/20 23:10:39 - 0:00:00 - accumulate_gradients: 1
4:                                      ae_steps: []
4:                                      amp: -1
4:                                      asm: False
4:                                      attention_dropout: 0.1
4:                                      batch_size: 32
4:                                      beam_size: 1
4:                                      bptt: 256
4:                                      bt_src_langs: []
4:                                      bt_steps: []
4:                                      clip_grad_norm: 5
4:                                      clm_steps: []
4:                                      command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2 --exp_id "3097"
4:                                      context_size: 0
4:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
4:                                      debug: False
4:                                      debug_slurm: False
4:                                      debug_train: False
4:                                      dropout: 0.1
4:                                      dump_path: /data/menekse/dumped/xlm_en_de_tlm/3097
4:                                      early_stopping: False
4:                                      emb_dim: 512
4:                                      encoder_only: True
4:                                      epoch_size: 300000
4:                                      eval_bleu: False
4:                                      eval_only: False
4:                                      exp_id: 3097
4:                                      exp_name: xlm_en_de_tlm
4:                                      fp16: False
4:                                      gelu_activation: True
4:                                      global_rank: 2
4:                                      group_by_size: True
4:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
4:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
4:                                      is_master: False
4:                                      is_slurm_job: False
4:                                      lambda_ae: 1
4:                                      lambda_bt: 1
4:                                      lambda_clm: 1
4:                                      lambda_mlm: 1
4:                                      lambda_mt: 1
4:                                      lambda_pc: 1
4:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
4:                                      langs: ['en', 'de', 'img']
4:                                      length_penalty: 1
4:                                      lg_sampling_factor: -1
4:                                      lgs: en-de
4:                                      local_rank: 2
4:                                      master_port: -1
4:                                      max_batch_size: 0
4:                                      max_epoch: 100000
4:                                      max_len: 100
4:                                      max_vocab: -1
4:                                      min_count: 0
4:                                      mlm_steps: [('en', 'de')]
4:                                      mono_dataset: {}
4:                                      mt_steps: []
4:                                      multi_gpu: True
4:                                      multi_node: False
4:                                      n_gpu_per_node: 3
4:                                      n_heads: 8
0: 
4:                                      n_langs: 3
4:                                      n_layers: 6
4:                                      n_nodes: 1
4:                                      node_id: 0
4:                                      only_vlm: False
4:                                      optimizer: adam,lr=0.0001
4:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
4:                                      pc_steps: []
4:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
4:                                      reload_checkpoint: 
4:                                      reload_emb: 
4:                                      reload_model: /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth
4:                                      sample_alpha: 0
4:                                      save_periodic: 2
4:                                      share_inout_emb: True
4:                                      sinusoidal_embeddings: False
4:                                      split_data: False
4:                                      stopping_criterion: _valid_mlm_ppl,25
4:                                      tokens_per_batch: -1
4:                                      use_lang_emb: True
4:                                      use_memory: False
4:                                      validation_metrics: valid_en_de_mlm_ppl
4:                                      vlm_steps: [('en', 'de')]
4:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
4:                                      word_blank: 0
4:                                      word_dropout: 0
4:                                      word_keep: 0.1
4:                                      word_mask: 0.8
4:                                      word_mask_keep_rand: 0.8,0.1,0.1
4:                                      word_pred: 0.15
4:                                      word_rand: 0.1
4:                                      word_shuffle: 0
4:                                      world_size: 3
4: INFO - 04/21/20 23:10:39 - 0:00:00 - The experiment will be stored in /data/menekse/dumped/xlm_en_de_tlm/3097
4:                                      
0: INFO - 04/21/20 23:10:39 - 0:00:00 - ============ Initialized logger ============
4: INFO - 04/21/20 23:10:39 - 0:00:00 - Running command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2
4: INFO - 04/21/20 23:10:39 - 0:00:00 - ============ Initialized logger ============
4: 
0: WARNING - 04/21/20 23:10:39 - 0:00:00 - Signal handler installed.
3: INFO - 04/21/20 23:10:39 - 0:00:00 - ============ Initialized logger ============
2: INFO - 04/21/20 23:10:39 - 0:00:00 - ============ Initialized logger ============
0: 
4: WARNING - 04/21/20 23:10:39 - 0:00:00 - Signal handler installed.
4: 
0: INFO - 04/21/20 23:10:39 - 0:00:00 - ============ Parallel data (de-en)
4: INFO - 04/21/20 23:10:39 - 0:00:00 - ============ Parallel data (de-en)
0: INFO - 04/21/20 23:10:39 - 0:00:00 - accumulate_gradients: 1
0:                                      ae_steps: []
0:                                      amp: -1
0:                                      asm: False
0:                                      attention_dropout: 0.1
0:                                      batch_size: 32
0:                                      beam_size: 1
0:                                      bptt: 256
0:                                      bt_src_langs: []
0:                                      bt_steps: []
0:                                      clip_grad_norm: 5
0:                                      clm_steps: []
0:                                      command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2 --exp_id "3097"
0:                                      context_size: 0
0:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
0:                                      debug: False
0:                                      debug_slurm: False
0:                                      debug_train: False
0:                                      dropout: 0.1
0:                                      dump_path: /data/menekse/dumped/xlm_en_de_tlm/3097
0:                                      early_stopping: False
0:                                      emb_dim: 512
0:                                      encoder_only: True
0:                                      epoch_size: 300000
0:                                      eval_bleu: False
0:                                      eval_only: False
0:                                      exp_id: 3097
0:                                      exp_name: xlm_en_de_tlm
0:                                      fp16: False
0:                                      gelu_activation: True
0:                                      global_rank: 2
0:                                      group_by_size: True
0:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
0:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
0:                                      is_master: False
0:                                      is_slurm_job: False
0:                                      lambda_ae: 1
0:                                      lambda_bt: 1
0:                                      lambda_clm: 1
0:                                      lambda_mlm: 1
0:                                      lambda_mt: 1
0:                                      lambda_pc: 1
0:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
0:                                      langs: ['en', 'de', 'img']
0:                                      length_penalty: 1
0:                                      lg_sampling_factor: -1
0:                                      lgs: en-de
0:                                      local_rank: 2
0:                                      master_port: -1
0:                                      max_batch_size: 0
0:                                      max_epoch: 100000
0:                                      max_len: 100
0:                                      max_vocab: -1
0:                                      min_count: 0
0:                                      mlm_steps: [('en', 'de')]
0:                                      mono_dataset: {}
0:                                      mt_steps: []
0:                                      multi_gpu: True
0:                                      multi_node: False
0:                                      n_gpu_per_node: 3
0:                                      n_heads: 8
0:                                      n_langs: 3
0:                                      n_layers: 6
0:                                      n_nodes: 1
0:                                      node_id: 0
0:                                      only_vlm: False
0:                                      optimizer: adam,lr=0.0001
0:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
0:                                      pc_steps: []
0:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
0:                                      reload_checkpoint: 
0:                                      reload_emb: 
0:                                      reload_model: /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth
0:                                      sample_alpha: 0
0:                                      save_periodic: 2
0:                                      share_inout_emb: True
0:                                      sinusoidal_embeddings: False
0:                                      split_data: False
0:                                      stopping_criterion: _valid_mlm_ppl,25
0:                                      tokens_per_batch: -1
0:                                      use_lang_emb: True
0:                                      use_memory: False
0:                                      validation_metrics: valid_en_de_mlm_ppl
0:                                      vlm_steps: [('en', 'de')]
0:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
0:                                      word_blank: 0
0:                                      word_dropout: 0
0:                                      word_keep: 0.1
0:                                      word_mask: 0.8
0:                                      word_mask_keep_rand: 0.8,0.1,0.1
0:                                      word_pred: 0.15
0:                                      word_rand: 0.1
0:                                      word_shuffle: 0
0:                                      world_size: 3
0: INFO - 04/21/20 23:10:39 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
4: INFO - 04/21/20 23:10:39 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
4: INFO - 04/21/20 23:10:39 - 0:00:00 - accumulate_gradients: 1
4:                                      ae_steps: []
4:                                      amp: -1
4:                                      asm: False
4:                                      attention_dropout: 0.1
4:                                      batch_size: 32
4:                                      beam_size: 1
4:                                      bptt: 256
4:                                      bt_src_langs: []
4:                                      bt_steps: []
4:                                      clip_grad_norm: 5
4:                                      clm_steps: []
4:                                      command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2 --exp_id "3097"
4:                                      context_size: 0
4:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
4:                                      debug: False
4:                                      debug_slurm: False
4:                                      debug_train: False
4:                                      dropout: 0.1
4:                                      dump_path: /data/menekse/dumped/xlm_en_de_tlm/3097
4:                                      early_stopping: False
4:                                      emb_dim: 512
4:                                      encoder_only: True
4:                                      epoch_size: 300000
4:                                      eval_bleu: False
4:                                      eval_only: False
4:                                      exp_id: 3097
4:                                      exp_name: xlm_en_de_tlm
4:                                      fp16: False
4:                                      gelu_activation: True
4:                                      global_rank: 1
4:                                      group_by_size: True
4:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
4:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
4:                                      is_master: False
4:                                      is_slurm_job: False
4:                                      lambda_ae: 1
4:                                      lambda_bt: 1
4:                                      lambda_clm: 1
4:                                      lambda_mlm: 1
4:                                      lambda_mt: 1
4:                                      lambda_pc: 1
4:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
4:                                      langs: ['en', 'de', 'img']
4:                                      length_penalty: 1
4:                                      lg_sampling_factor: -1
4:                                      lgs: en-de
4:                                      local_rank: 1
4:                                      master_port: -1
4:                                      max_batch_size: 0
4:                                      max_epoch: 100000
4:                                      max_len: 100
4:                                      max_vocab: -1
4:                                      min_count: 0
4:                                      mlm_steps: [('en', 'de')]
4:                                      mono_dataset: {}
4:                                      mt_steps: []
4:                                      multi_gpu: True
4:                                      multi_node: False
0: INFO - 04/21/20 23:10:39 - 0:00:00 - The experiment will be stored in /data/menekse/dumped/xlm_en_de_tlm/3097
0:                                      
4:                                      n_gpu_per_node: 3
4:                                      n_heads: 8
4:                                      n_langs: 3
4:                                      n_layers: 6
4:                                      n_nodes: 1
4:                                      node_id: 0
4:                                      only_vlm: False
4:                                      optimizer: adam,lr=0.0001
4:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
4:                                      pc_steps: []
4:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
4:                                      reload_checkpoint: 
4:                                      reload_emb: 
4:                                      reload_model: /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth
4:                                      sample_alpha: 0
4:                                      save_periodic: 2
4:                                      share_inout_emb: True
4:                                      sinusoidal_embeddings: False
4:                                      split_data: False
4:                                      stopping_criterion: _valid_mlm_ppl,25
4:                                      tokens_per_batch: -1
4:                                      use_lang_emb: True
4:                                      use_memory: False
4:                                      validation_metrics: valid_en_de_mlm_ppl
4:                                      vlm_steps: [('en', 'de')]
4:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
4:                                      word_blank: 0
4:                                      word_dropout: 0
4:                                      word_keep: 0.1
4:                                      word_mask: 0.8
4:                                      word_mask_keep_rand: 0.8,0.1,0.1
4:                                      word_pred: 0.15
4:                                      word_rand: 0.1
4:                                      word_shuffle: 0
4:                                      world_size: 3
4: INFO - 04/21/20 23:10:39 - 0:00:00 - The experiment will be stored in /data/menekse/dumped/xlm_en_de_tlm/3097
4:                                      
3: INFO - 04/21/20 23:10:39 - 0:00:00 - accumulate_gradients: 1
3:                                      ae_steps: []
3:                                      amp: -1
3:                                      asm: False
3:                                      attention_dropout: 0.1
3:                                      batch_size: 32
3:                                      beam_size: 1
3:                                      bptt: 256
3:                                      bt_src_langs: []
3:                                      bt_steps: []
3:                                      clip_grad_norm: 5
3:                                      clm_steps: []
3:                                      command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2 --exp_id "3097"
3:                                      context_size: 0
3:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      debug: False
3:                                      debug_slurm: False
3:                                      debug_train: False
3:                                      dropout: 0.1
3:                                      dump_path: /data/menekse/dumped/xlm_en_de_tlm/3097
3:                                      early_stopping: False
3:                                      emb_dim: 512
3:                                      encoder_only: True
3:                                      epoch_size: 300000
3:                                      eval_bleu: False
3:                                      eval_only: False
3:                                      exp_id: 3097
3:                                      exp_name: xlm_en_de_tlm
3:                                      fp16: False
3:                                      gelu_activation: True
3:                                      global_rank: 1
3:                                      group_by_size: True
3:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
3:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      is_master: False
3:                                      is_slurm_job: False
3:                                      lambda_ae: 1
3:                                      lambda_bt: 1
3:                                      lambda_clm: 1
3:                                      lambda_mlm: 1
3:                                      lambda_mt: 1
3:                                      lambda_pc: 1
3:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
3:                                      langs: ['en', 'de', 'img']
3:                                      length_penalty: 1
3:                                      lg_sampling_factor: -1
3:                                      lgs: en-de
3:                                      local_rank: 1
3:                                      master_port: -1
3:                                      max_batch_size: 0
3:                                      max_epoch: 100000
3:                                      max_len: 100
3:                                      max_vocab: -1
3:                                      min_count: 0
3:                                      mlm_steps: [('en', 'de')]
3:                                      mono_dataset: {}
3:                                      mt_steps: []
3:                                      multi_gpu: True
3:                                      multi_node: False
3:                                      n_gpu_per_node: 3
3:                                      n_heads: 8
0: INFO - 04/21/20 23:10:39 - 0:00:00 - Running command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2
2: INFO - 04/21/20 23:10:39 - 0:00:00 - accumulate_gradients: 1
2:                                      ae_steps: []
2:                                      amp: -1
2:                                      asm: False
2:                                      attention_dropout: 0.1
2:                                      batch_size: 32
2:                                      beam_size: 1
2:                                      bptt: 256
2:                                      bt_src_langs: []
2:                                      bt_steps: []
2:                                      clip_grad_norm: 5
2:                                      clm_steps: []
2:                                      command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2 --exp_id "3097"
2:                                      context_size: 0
2:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
2:                                      debug: False
2:                                      debug_slurm: False
2:                                      debug_train: False
2:                                      dropout: 0.1
2:                                      dump_path: /data/menekse/dumped/xlm_en_de_tlm/3097
2:                                      early_stopping: False
2:                                      emb_dim: 512
2:                                      encoder_only: True
2:                                      epoch_size: 300000
2:                                      eval_bleu: False
2:                                      eval_only: False
2:                                      exp_id: 3097
2:                                      exp_name: xlm_en_de_tlm
2:                                      fp16: False
2:                                      gelu_activation: True
2:                                      global_rank: 2
2:                                      group_by_size: True
2:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
2:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
2:                                      is_master: False
2:                                      is_slurm_job: False
2:                                      lambda_ae: 1
2:                                      lambda_bt: 1
2:                                      lambda_clm: 1
2:                                      lambda_mlm: 1
2:                                      lambda_mt: 1
2:                                      lambda_pc: 1
2:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
2:                                      langs: ['en', 'de', 'img']
2:                                      length_penalty: 1
2:                                      lg_sampling_factor: -1
2:                                      lgs: en-de
2:                                      local_rank: 2
2:                                      master_port: -1
2:                                      max_batch_size: 0
2:                                      max_epoch: 100000
2:                                      max_len: 100
2:                                      max_vocab: -1
2:                                      min_count: 0
2:                                      mlm_steps: [('en', 'de')]
2:                                      mono_dataset: {}
2:                                      mt_steps: []
2:                                      multi_gpu: True
2:                                      multi_node: False
2:                                      n_gpu_per_node: 3
2:                                      n_heads: 8
3:                                      n_langs: 3
3:                                      n_layers: 6
3:                                      n_nodes: 1
3:                                      node_id: 0
3:                                      only_vlm: False
3:                                      optimizer: adam,lr=0.0001
3:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      pc_steps: []
3:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
3:                                      reload_checkpoint: 
3:                                      reload_emb: 
3:                                      reload_model: /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth
3:                                      sample_alpha: 0
3:                                      save_periodic: 2
3:                                      share_inout_emb: True
3:                                      sinusoidal_embeddings: False
3:                                      split_data: False
3:                                      stopping_criterion: _valid_mlm_ppl,25
3:                                      tokens_per_batch: -1
3:                                      use_lang_emb: True
3:                                      use_memory: False
3:                                      validation_metrics: valid_en_de_mlm_ppl
3:                                      vlm_steps: [('en', 'de')]
3:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      word_blank: 0
3:                                      word_dropout: 0
3:                                      word_keep: 0.1
3:                                      word_mask: 0.8
3:                                      word_mask_keep_rand: 0.8,0.1,0.1
3:                                      word_pred: 0.15
3:                                      word_rand: 0.1
3:                                      word_shuffle: 0
3:                                      world_size: 3
3: INFO - 04/21/20 23:10:39 - 0:00:00 - The experiment will be stored in /data/menekse/dumped/xlm_en_de_tlm/3097
3:                                      
4: INFO - 04/21/20 23:10:39 - 0:00:00 - Running command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2
4: 
0: 
2:                                      n_langs: 3
2:                                      n_layers: 6
2:                                      n_nodes: 1
2:                                      node_id: 0
2:                                      only_vlm: False
2:                                      optimizer: adam,lr=0.0001
2:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
2:                                      pc_steps: []
2:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
2:                                      reload_checkpoint: 
2:                                      reload_emb: 
2:                                      reload_model: /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth
2:                                      sample_alpha: 0
2:                                      save_periodic: 2
2:                                      share_inout_emb: True
2:                                      sinusoidal_embeddings: False
2:                                      split_data: False
2:                                      stopping_criterion: _valid_mlm_ppl,25
2:                                      tokens_per_batch: -1
2:                                      use_lang_emb: True
2:                                      use_memory: False
2:                                      validation_metrics: valid_en_de_mlm_ppl
2:                                      vlm_steps: [('en', 'de')]
2:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
2:                                      word_blank: 0
2:                                      word_dropout: 0
2:                                      word_keep: 0.1
2:                                      word_mask: 0.8
2:                                      word_mask_keep_rand: 0.8,0.1,0.1
2:                                      word_pred: 0.15
2:                                      word_rand: 0.1
2:                                      word_shuffle: 0
2:                                      world_size: 3
2: INFO - 04/21/20 23:10:39 - 0:00:00 - The experiment will be stored in /data/menekse/dumped/xlm_en_de_tlm/3097
2:                                      
3: INFO - 04/21/20 23:10:39 - 0:00:00 - Running command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2
2: INFO - 04/21/20 23:10:39 - 0:00:00 - Running command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --reload_model '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth' --save_periodic 2
0: WARNING - 04/21/20 23:10:39 - 0:00:00 - Signal handler installed.
3: 
4: WARNING - 04/21/20 23:10:39 - 0:00:00 - Signal handler installed.
2: 
0: 
4: 
3: WARNING - 04/21/20 23:10:39 - 0:00:00 - Signal handler installed.
0: INFO - 04/21/20 23:10:39 - 0:00:00 - ============ Parallel data (de-en)
2: WARNING - 04/21/20 23:10:39 - 0:00:00 - Signal handler installed.
4: INFO - 04/21/20 23:10:39 - 0:00:00 - ============ Parallel data (de-en)
3: 
2: 
0: INFO - 04/21/20 23:10:39 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: INFO - 04/21/20 23:10:39 - 0:00:00 - ============ Parallel data (de-en)
4: INFO - 04/21/20 23:10:39 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
2: INFO - 04/21/20 23:10:39 - 0:00:00 - ============ Parallel data (de-en)
3: INFO - 04/21/20 23:10:39 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
2: INFO - 04/21/20 23:10:39 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
srun: error: hanabi: task 5: Exited with exit code 1
1: INFO - 04/21/20 23:10:42 - 0:00:04 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
1: INFO - 04/21/20 23:10:42 - 0:00:04 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
1: INFO - 04/21/20 23:10:44 - 0:00:06 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
1: INFO - 04/21/20 23:10:44 - 0:00:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
5: INFO - 04/21/20 23:10:46 - 0:00:08 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
5: INFO - 04/21/20 23:10:46 - 0:00:08 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
srun: error: hanabi: task 4: Exited with exit code 1
1: INFO - 04/21/20 23:10:47 - 0:00:09 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/21/20 23:10:48 - 0:00:09 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/21/20 23:10:48 - 0:00:09 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
4: INFO - 04/21/20 23:10:49 - 0:00:10 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
4: INFO - 04/21/20 23:10:49 - 0:00:10 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
4: INFO - 04/21/20 23:10:49 - 0:00:10 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
4: INFO - 04/21/20 23:10:49 - 0:00:10 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
0: INFO - 04/21/20 23:10:50 - 0:00:11 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
0: INFO - 04/21/20 23:10:50 - 0:00:11 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
2: INFO - 04/21/20 23:10:50 - 0:00:11 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
2: INFO - 04/21/20 23:10:50 - 0:00:11 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
5: INFO - 04/21/20 23:10:50 - 0:00:11 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
5: INFO - 04/21/20 23:10:50 - 0:00:11 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
1: INFO - 04/21/20 23:10:50 - 0:00:11 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
1: INFO - 04/21/20 23:10:50 - 0:00:11 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
3: INFO - 04/21/20 23:10:50 - 0:00:12 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/21/20 23:10:50 - 0:00:12 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
0: INFO - 04/21/20 23:10:50 - 0:00:11 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
0: INFO - 04/21/20 23:10:50 - 0:00:11 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
1: INFO - 04/21/20 23:10:50 - 0:00:12 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
2: INFO - 04/21/20 23:10:50 - 0:00:12 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
2: INFO - 04/21/20 23:10:50 - 0:00:12 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
0: Traceback (most recent call last):
0:   File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
0:     "__main__", mod_spec)
0:   File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
0:     exec(code, run_globals)
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 263, in <module>
0:     main()
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 259, in main
0:     cmd=cmd)
0: subprocess.CalledProcessError: Command '['/home/menekse/virtualenvs/torch_env/bin/python', '-u', 'train.py', '--local_rank=2', '--exp_name', 'xlm_en_de_tlm', '--dump_path', '/data/menekse/dumped', '--data_path', '/data/shared/ConceptualCaptions/XLM_data/50k', '--lgs', 'en-de', '--clm_steps', '', '--mlm_steps', 'en-de', '--emb_dim', '512', '--n_layers', '6', '--n_heads', '8', '--dropout', '0.1', '--attention_dropout', '0.1', '--gelu_activation', 'true', '--batch_size', '32', '--bptt', '256', '--optimizer', 'adam,lr=0.0001', '--epoch_size', '300000', '--max_epoch', '100000', '--validation_metrics', 'valid_en_de_mlm_ppl', '--stopping_criterion', '_valid_mlm_ppl,25', '--fp16', 'false', '--image_names', '/data/shared/ConceptualCaptions/XLM_data/50k', '--reload_model', '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth', '--save_periodic', '2']' returned non-zero exit status 1.
2: Traceback (most recent call last):
2:   File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
2:     "__main__", mod_spec)
2:   File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
2:     exec(code, run_globals)
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 263, in <module>
2:     main()
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 259, in main
2:     cmd=cmd)
2: subprocess.CalledProcessError: Command '['/home/menekse/virtualenvs/torch_env/bin/python', '-u', 'train.py', '--local_rank=2', '--exp_name', 'xlm_en_de_tlm', '--dump_path', '/data/menekse/dumped', '--data_path', '/data/shared/ConceptualCaptions/XLM_data/50k', '--lgs', 'en-de', '--clm_steps', '', '--mlm_steps', 'en-de', '--emb_dim', '512', '--n_layers', '6', '--n_heads', '8', '--dropout', '0.1', '--attention_dropout', '0.1', '--gelu_activation', 'true', '--batch_size', '32', '--bptt', '256', '--optimizer', 'adam,lr=0.0001', '--epoch_size', '300000', '--max_epoch', '100000', '--validation_metrics', 'valid_en_de_mlm_ppl', '--stopping_criterion', '_valid_mlm_ppl,25', '--fp16', 'false', '--image_names', '/data/shared/ConceptualCaptions/XLM_data/50k', '--reload_model', '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth', '--save_periodic', '2']' returned non-zero exit status 1.
5: INFO - 04/21/20 23:10:52 - 0:00:14 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/21/20 23:10:54 - 0:00:15 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
1: INFO - 04/21/20 23:10:58 - 0:00:19 - Removed 0 empty sentences.
srun: error: hanabi: task 2: Exited with exit code 1
4: INFO - 04/21/20 23:10:59 - 0:00:20 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
srun: error: hanabi: task 0: Exited with exit code 1
0: INFO - 04/21/20 23:11:00 - 0:00:21 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
4: INFO - 04/21/20 23:11:00 - 0:00:21 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
2: INFO - 04/21/20 23:11:00 - 0:00:21 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
1: INFO - 04/21/20 23:11:00 - 0:00:21 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
0: INFO - 04/21/20 23:11:00 - 0:00:21 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
5: INFO - 04/21/20 23:11:00 - 0:00:21 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
2: INFO - 04/21/20 23:11:00 - 0:00:22 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/21/20 23:11:00 - 0:00:22 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/21/20 23:11:05 - 0:00:26 - Removed 0 empty sentences.
5: INFO - 04/21/20 23:11:05 - 0:00:27 - Removed 0 empty sentences.
1: INFO - 04/21/20 23:11:10 - 0:00:32 - Removed 0 empty sentences.
1: INFO - 04/21/20 23:11:13 - 0:00:35 - Removed 0 empty sentences.
2: INFO - 04/21/20 23:11:19 - 0:00:40 - Removed 0 empty sentences.
2: INFO - 04/21/20 23:11:19 - 0:00:41 - Removed 0 empty sentences.
4: INFO - 04/21/20 23:11:19 - 0:00:40 - Removed 0 empty sentences.
4: INFO - 04/21/20 23:11:19 - 0:00:40 - Removed 0 empty sentences.
5: INFO - 04/21/20 23:11:19 - 0:00:41 - Removed 0 empty sentences.
0: INFO - 04/21/20 23:11:20 - 0:00:41 - Removed 0 empty sentences.
0: INFO - 04/21/20 23:11:20 - 0:00:41 - Removed 0 empty sentences.
3: INFO - 04/21/20 23:11:20 - 0:00:41 - Removed 0 empty sentences.
1: INFO - 04/21/20 23:11:20 - 0:00:41 - Removed 0 empty sentences.
5: INFO - 04/21/20 23:11:24 - 0:00:46 - Removed 0 empty sentences.
3: INFO - 04/21/20 23:11:26 - 0:00:47 - Removed 0 empty sentences.
1: INFO - 04/21/20 23:11:26 - 0:00:48 - Removed 2 too long sentences.
1: 
1: INFO - 04/21/20 23:11:32 - 0:00:53 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
1: INFO - 04/21/20 23:11:32 - 0:00:54 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/21/20 23:11:32 - 0:00:54 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: INFO - 04/21/20 23:11:33 - 0:00:54 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/21/20 23:11:37 - 0:00:59 - Removed 0 empty sentences.
5: INFO - 04/21/20 23:11:37 - 0:00:58 - Removed 2 too long sentences.
1: INFO - 04/21/20 23:11:37 - 0:00:59 - Removed 0 empty sentences.
1: 
1: INFO - 04/21/20 23:11:37 - 0:00:59 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/21/20 23:11:38 - 0:00:59 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/21/20 23:11:38 - 0:01:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/21/20 23:11:38 - 0:01:00 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
3: INFO - 04/21/20 23:11:40 - 0:01:01 - Removed 2 too long sentences.
5: 
5: INFO - 04/21/20 23:11:43 - 0:01:05 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
5: INFO - 04/21/20 23:11:44 - 0:01:05 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
5: INFO - 04/21/20 23:11:44 - 0:01:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: INFO - 04/21/20 23:11:44 - 0:01:06 - Removed 0 empty sentences.
1: 
1: 
1: INFO - 04/21/20 23:11:44 - 0:01:06 - ============ Parallel data with image regions (de-en)
1: INFO - 04/21/20 23:11:44 - 0:01:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
5: INFO - 04/21/20 23:11:44 - 0:01:06 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
3: 
3: INFO - 04/21/20 23:11:46 - 0:01:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
3: INFO - 04/21/20 23:11:46 - 0:01:08 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/21/20 23:11:47 - 0:01:08 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
2: INFO - 04/21/20 23:11:47 - 0:01:08 - Removed 0 empty sentences.
2: INFO - 04/21/20 23:11:47 - 0:01:08 - Removed 0 empty sentences.
3: INFO - 04/21/20 23:11:47 - 0:01:08 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
5: INFO - 04/21/20 23:11:48 - 0:01:09 - Removed 0 empty sentences.
1: INFO - 04/21/20 23:11:50 - 0:01:11 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
1: INFO - 04/21/20 23:11:50 - 0:01:11 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
0: INFO - 04/21/20 23:11:50 - 0:01:11 - Removed 0 empty sentences.
0: INFO - 04/21/20 23:11:50 - 0:01:11 - Removed 0 empty sentences.
5: INFO - 04/21/20 23:11:50 - 0:01:12 - Removed 0 empty sentences.
5: 
5: INFO - 04/21/20 23:11:50 - 0:01:12 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
4: INFO - 04/21/20 23:11:50 - 0:01:12 - Removed 0 empty sentences.
5: INFO - 04/21/20 23:11:51 - 0:01:12 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
4: INFO - 04/21/20 23:11:51 - 0:01:12 - Removed 0 empty sentences.
5: INFO - 04/21/20 23:11:51 - 0:01:12 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
5: INFO - 04/21/20 23:11:51 - 0:01:13 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
3: INFO - 04/21/20 23:11:51 - 0:01:13 - Removed 0 empty sentences.
3: INFO - 04/21/20 23:11:52 - 0:01:13 - Removed 0 empty sentences.
3: 
3: INFO - 04/21/20 23:11:52 - 0:01:13 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/21/20 23:11:52 - 0:01:13 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/21/20 23:11:52 - 0:01:13 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/21/20 23:11:52 - 0:01:14 - Removed 2 too long sentences.
3: INFO - 04/21/20 23:11:53 - 0:01:14 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: INFO - 04/21/20 23:11:54 - 0:01:15 - Removed 0 empty sentences.
1: INFO - 04/21/20 23:11:55 - 0:01:17 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
5: INFO - 04/21/20 23:11:56 - 0:01:18 - Removed 0 empty sentences.
5: 
5: 
5: INFO - 04/21/20 23:11:56 - 0:01:18 - ============ Parallel data with image regions (de-en)
5: INFO - 04/21/20 23:11:56 - 0:01:18 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: INFO - 04/21/20 23:11:57 - 0:01:18 - Removed 0 empty sentences.
3: 
3: 
3: INFO - 04/21/20 23:11:57 - 0:01:18 - ============ Parallel data with image regions (de-en)
3: INFO - 04/21/20 23:11:57 - 0:01:18 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
1: 
1: INFO - 04/21/20 23:11:59 - 0:01:21 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
1: INFO - 04/21/20 23:11:59 - 0:01:21 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/21/20 23:12:00 - 0:01:22 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: INFO - 04/21/20 23:12:00 - 0:01:22 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
5: INFO - 04/21/20 23:12:02 - 0:01:23 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
5: INFO - 04/21/20 23:12:02 - 0:01:23 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
3: INFO - 04/21/20 23:12:03 - 0:01:24 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/21/20 23:12:03 - 0:01:24 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
2: INFO - 04/21/20 23:12:04 - 0:01:25 - Removed 2 too long sentences.
2: INFO - 04/21/20 23:12:05 - 0:01:26 - Removed 2 too long sentences.
5: INFO - 04/21/20 23:12:06 - 0:01:27 - Removed 2 too long sentences.
1: INFO - 04/21/20 23:12:06 - 0:01:28 - Removed 0 empty sentences.
1: 
1: INFO - 04/21/20 23:12:06 - 0:01:28 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/21/20 23:12:07 - 0:01:29 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/21/20 23:12:07 - 0:01:29 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/21/20 23:12:08 - 0:01:30 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
0: INFO - 04/21/20 23:12:08 - 0:01:29 - Removed 2 too long sentences.
4: INFO - 04/21/20 23:12:08 - 0:01:30 - Removed 2 too long sentences.
4: INFO - 04/21/20 23:12:10 - 0:01:31 - Removed 2 too long sentences.
5: INFO - 04/21/20 23:12:10 - 0:01:32 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/21/20 23:12:10 - 0:01:32 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
0: INFO - 04/21/20 23:12:11 - 0:01:32 - Removed 2 too long sentences.
3: INFO - 04/21/20 23:12:11 - 0:01:33 - Removed 2 too long sentences.
2: 
2: INFO - 04/21/20 23:12:12 - 0:01:33 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
2: 
2: INFO - 04/21/20 23:12:12 - 0:01:33 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
2: INFO - 04/21/20 23:12:12 - 0:01:33 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/21/20 23:12:12 - 0:01:33 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/21/20 23:12:12 - 0:01:34 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
2: INFO - 04/21/20 23:12:12 - 0:01:34 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: INFO - 04/21/20 23:12:13 - 0:01:35 - Removed 0 empty sentences.
1: 
1: 
2: INFO - 04/21/20 23:12:13 - 0:01:34 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/21/20 23:12:13 - 0:01:35 - ============ Parallel data with image regions (de-en)
1: INFO - 04/21/20 23:12:13 - 0:01:35 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
2: INFO - 04/21/20 23:12:13 - 0:01:34 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
5: 
5: INFO - 04/21/20 23:12:13 - 0:01:34 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
5: INFO - 04/21/20 23:12:14 - 0:01:35 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
5: INFO - 04/21/20 23:12:14 - 0:01:35 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
5: INFO - 04/21/20 23:12:14 - 0:01:35 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/21/20 23:12:14 - 0:01:36 - Removed 2 too long sentences.
0: 
0: INFO - 04/21/20 23:12:15 - 0:01:36 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
4: 
4: INFO - 04/21/20 23:12:15 - 0:01:37 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
0: INFO - 04/21/20 23:12:15 - 0:01:37 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/21/20 23:12:16 - 0:01:37 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
4: INFO - 04/21/20 23:12:16 - 0:01:37 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
4: INFO - 04/21/20 23:12:16 - 0:01:37 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
0: INFO - 04/21/20 23:12:16 - 0:01:37 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
4: 
4: INFO - 04/21/20 23:12:16 - 0:01:37 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
4: INFO - 04/21/20 23:12:16 - 0:01:38 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
4: INFO - 04/21/20 23:12:17 - 0:01:38 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
4: INFO - 04/21/20 23:12:17 - 0:01:38 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
2: INFO - 04/21/20 23:12:17 - 0:01:39 - Removed 0 empty sentences.
2: 
2: INFO - 04/21/20 23:12:17 - 0:01:39 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/21/20 23:12:17 - 0:01:39 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
1: INFO - 04/21/20 23:12:17 - 0:01:39 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
4: INFO - 04/21/20 23:12:17 - 0:01:39 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
2: INFO - 04/21/20 23:12:18 - 0:01:39 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: 
3: INFO - 04/21/20 23:12:18 - 0:01:39 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
2: INFO - 04/21/20 23:12:18 - 0:01:39 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
0: 
0: INFO - 04/21/20 23:12:18 - 0:01:39 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
3: INFO - 04/21/20 23:12:18 - 0:01:40 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/21/20 23:12:18 - 0:01:40 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
2: INFO - 04/21/20 23:12:18 - 0:01:39 - Removed 0 empty sentences.
2: 
2: INFO - 04/21/20 23:12:18 - 0:01:39 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/21/20 23:12:18 - 0:01:40 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
2: INFO - 04/21/20 23:12:19 - 0:01:40 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/21/20 23:12:19 - 0:01:40 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/21/20 23:12:19 - 0:01:40 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
3: INFO - 04/21/20 23:12:19 - 0:01:40 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
0: INFO - 04/21/20 23:12:19 - 0:01:40 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
5: INFO - 04/21/20 23:12:19 - 0:01:40 - Removed 0 empty sentences.
5: 
5: INFO - 04/21/20 23:12:19 - 0:01:40 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
2: INFO - 04/21/20 23:12:19 - 0:01:40 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
0: INFO - 04/21/20 23:12:19 - 0:01:40 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
5: INFO - 04/21/20 23:12:20 - 0:01:41 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
5: INFO - 04/21/20 23:12:20 - 0:01:41 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
5: INFO - 04/21/20 23:12:20 - 0:01:41 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: 
1: INFO - 04/21/20 23:12:21 - 0:01:42 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
4: INFO - 04/21/20 23:12:21 - 0:01:42 - Removed 0 empty sentences.
4: 
4: INFO - 04/21/20 23:12:21 - 0:01:42 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/21/20 23:12:21 - 0:01:42 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/21/20 23:12:21 - 0:01:42 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
0: INFO - 04/21/20 23:12:21 - 0:01:42 - Removed 0 empty sentences.
0: 
0: INFO - 04/21/20 23:12:21 - 0:01:42 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
4: INFO - 04/21/20 23:12:21 - 0:01:42 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
4: INFO - 04/21/20 23:12:21 - 0:01:42 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/21/20 23:12:21 - 0:01:43 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
1: INFO - 04/21/20 23:12:21 - 0:01:43 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
4: INFO - 04/21/20 23:12:21 - 0:01:43 - Removed 0 empty sentences.
4: 
4: INFO - 04/21/20 23:12:21 - 0:01:43 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
0: INFO - 04/21/20 23:12:22 - 0:01:43 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
4: INFO - 04/21/20 23:12:22 - 0:01:43 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
0: INFO - 04/21/20 23:12:22 - 0:01:43 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
2: INFO - 04/21/20 23:12:22 - 0:01:43 - Removed 0 empty sentences.
2: 
2: 
4: INFO - 04/21/20 23:12:22 - 0:01:43 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/21/20 23:12:22 - 0:01:43 - ============ Parallel data with image regions (de-en)
2: INFO - 04/21/20 23:12:22 - 0:01:43 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
4: INFO - 04/21/20 23:12:22 - 0:01:43 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
0: INFO - 04/21/20 23:12:22 - 0:01:43 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
4: INFO - 04/21/20 23:12:22 - 0:01:44 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
3: INFO - 04/21/20 23:12:23 - 0:01:44 - Removed 0 empty sentences.
3: 
3: INFO - 04/21/20 23:12:23 - 0:01:44 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
2: INFO - 04/21/20 23:12:23 - 0:01:44 - Removed 0 empty sentences.
2: 
2: 
2: INFO - 04/21/20 23:12:23 - 0:01:44 - ============ Parallel data with image regions (de-en)
2: INFO - 04/21/20 23:12:23 - 0:01:44 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: INFO - 04/21/20 23:12:23 - 0:01:45 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/21/20 23:12:24 - 0:01:45 - Removed 0 empty sentences.
0: 
0: INFO - 04/21/20 23:12:24 - 0:01:45 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/21/20 23:12:24 - 0:01:45 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
5: INFO - 04/21/20 23:12:24 - 0:01:45 - Removed 0 empty sentences.
5: 
5: 
5: INFO - 04/21/20 23:12:24 - 0:01:45 - ============ Parallel data with image regions (de-en)
5: INFO - 04/21/20 23:12:24 - 0:01:45 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: INFO - 04/21/20 23:12:24 - 0:01:45 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
0: INFO - 04/21/20 23:12:24 - 0:01:45 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/21/20 23:12:24 - 0:01:45 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
0: INFO - 04/21/20 23:12:25 - 0:01:46 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
4: INFO - 04/21/20 23:12:26 - 0:01:47 - Removed 0 empty sentences.
4: 
4: 
4: INFO - 04/21/20 23:12:26 - 0:01:47 - ============ Parallel data with image regions (de-en)
4: INFO - 04/21/20 23:12:26 - 0:01:47 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
1: INFO - 04/21/20 23:12:26 - 0:01:47 - Removed 0 empty sentences.
1: 
1: INFO - 04/21/20 23:12:26 - 0:01:47 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
2: INFO - 04/21/20 23:12:26 - 0:01:48 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
2: INFO - 04/21/20 23:12:26 - 0:01:48 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
1: INFO - 04/21/20 23:12:27 - 0:01:48 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/21/20 23:12:27 - 0:01:48 - Removed 0 empty sentences.
0: 
0: 
1: INFO - 04/21/20 23:12:27 - 0:01:48 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
4: INFO - 04/21/20 23:12:27 - 0:01:48 - Removed 0 empty sentences.
4: 
4: 
0: INFO - 04/21/20 23:12:27 - 0:01:48 - ============ Parallel data with image regions (de-en)
0: INFO - 04/21/20 23:12:27 - 0:01:48 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
4: INFO - 04/21/20 23:12:27 - 0:01:48 - ============ Parallel data with image regions (de-en)
4: INFO - 04/21/20 23:12:27 - 0:01:48 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
1: INFO - 04/21/20 23:12:27 - 0:01:49 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
2: INFO - 04/21/20 23:12:28 - 0:01:49 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
2: INFO - 04/21/20 23:12:28 - 0:01:49 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
3: INFO - 04/21/20 23:12:28 - 0:01:50 - Removed 0 empty sentences.
3: 
3: 
3: INFO - 04/21/20 23:12:29 - 0:01:50 - ============ Parallel data with image regions (de-en)
3: INFO - 04/21/20 23:12:29 - 0:01:50 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
5: INFO - 04/21/20 23:12:29 - 0:01:50 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
5: INFO - 04/21/20 23:12:29 - 0:01:50 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
0: INFO - 04/21/20 23:12:29 - 0:01:50 - Removed 0 empty sentences.
0: 
0: 
0: INFO - 04/21/20 23:12:29 - 0:01:51 - ============ Parallel data with image regions (de-en)
0: INFO - 04/21/20 23:12:29 - 0:01:51 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
1: INFO - 04/21/20 23:12:32 - 0:01:53 - Removed 0 empty sentences.
1: 
1: 
4: INFO - 04/21/20 23:12:32 - 0:01:53 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
4: INFO - 04/21/20 23:12:32 - 0:01:53 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
1: INFO - 04/21/20 23:12:32 - 0:01:53 - ============ Parallel data with image regions (de-en)
1: INFO - 04/21/20 23:12:32 - 0:01:53 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
0: INFO - 04/21/20 23:12:32 - 0:01:53 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
0: INFO - 04/21/20 23:12:32 - 0:01:53 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
4: INFO - 04/21/20 23:12:33 - 0:01:54 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
4: INFO - 04/21/20 23:12:33 - 0:01:54 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
2: INFO - 04/21/20 23:12:33 - 0:01:54 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
2: INFO - 04/21/20 23:12:34 - 0:01:55 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
5: INFO - 04/21/20 23:12:35 - 0:01:56 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/21/20 23:12:36 - 0:01:58 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/21/20 23:12:36 - 0:01:58 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
0: INFO - 04/21/20 23:12:37 - 0:01:58 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
0: INFO - 04/21/20 23:12:37 - 0:01:58 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
4: INFO - 04/21/20 23:12:38 - 0:01:59 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
0: INFO - 04/21/20 23:12:38 - 0:01:59 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
1: INFO - 04/21/20 23:12:38 - 0:02:00 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
1: INFO - 04/21/20 23:12:38 - 0:02:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
4: INFO - 04/21/20 23:12:38 - 0:02:00 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/21/20 23:12:42 - 0:02:03 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
1: INFO - 04/21/20 23:12:42 - 0:02:04 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
0: INFO - 04/21/20 23:12:42 - 0:02:04 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
1: INFO - 04/21/20 23:13:09 - 0:02:30 - Removed 0 empty sentences.
3: INFO - 04/21/20 23:13:35 - 0:02:56 - Removed 0 empty sentences.
5: INFO - 04/21/20 23:13:39 - 0:03:00 - Removed 0 empty sentences.
1: INFO - 04/21/20 23:13:43 - 0:03:05 - Removed 0 empty sentences.
2: INFO - 04/21/20 23:13:47 - 0:03:08 - Removed 0 empty sentences.
5: INFO - 04/21/20 23:13:48 - 0:03:09 - Removed 0 empty sentences.
4: INFO - 04/21/20 23:13:53 - 0:03:14 - Removed 0 empty sentences.
1: INFO - 04/21/20 23:13:54 - 0:03:16 - Removed 0 empty sentences.
4: INFO - 04/21/20 23:13:58 - 0:03:20 - Removed 0 empty sentences.
0: INFO - 04/21/20 23:14:03 - 0:03:24 - Removed 0 empty sentences.
2: INFO - 04/21/20 23:14:10 - 0:03:31 - Removed 0 empty sentences.
5: INFO - 04/21/20 23:14:12 - 0:03:33 - Removed 0 empty sentences.
1: INFO - 04/21/20 23:14:13 - 0:03:34 - Removed 2 too long sentences.
2: INFO - 04/21/20 23:14:15 - 0:03:37 - Removed 0 empty sentences.
4: INFO - 04/21/20 23:14:16 - 0:03:37 - Removed 0 empty sentences.
3: INFO - 04/21/20 23:14:18 - 0:03:39 - Removed 0 empty sentences.
5: INFO - 04/21/20 23:14:20 - 0:03:42 - Removed 0 empty sentences.
1: 
1: INFO - 04/21/20 23:14:23 - 0:03:44 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
1: INFO - 04/21/20 23:14:23 - 0:03:45 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/21/20 23:14:24 - 0:03:45 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: INFO - 04/21/20 23:14:24 - 0:03:46 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
4: INFO - 04/21/20 23:14:27 - 0:03:48 - Removed 0 empty sentences.
2: INFO - 04/21/20 23:14:28 - 0:03:49 - Removed 2 too long sentences.
0: INFO - 04/21/20 23:14:29 - 0:03:50 - Removed 0 empty sentences.
5: INFO - 04/21/20 23:14:30 - 0:03:51 - Removed 2 too long sentences.
3: INFO - 04/21/20 23:14:32 - 0:03:53 - Removed 0 empty sentences.
2: 
2: INFO - 04/21/20 23:14:33 - 0:03:54 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
1: INFO - 04/21/20 23:14:33 - 0:03:55 - Removed 0 empty sentences.
1: INFO - 04/21/20 23:14:33 - 0:03:55 - Removed 0 empty sentences.
2: INFO - 04/21/20 23:14:34 - 0:03:55 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/21/20 23:14:34 - 0:03:55 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
2: INFO - 04/21/20 23:14:34 - 0:03:55 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
4: INFO - 04/21/20 23:14:35 - 0:03:56 - Removed 2 too long sentences.
5: 
5: INFO - 04/21/20 23:14:36 - 0:03:57 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
5: INFO - 04/21/20 23:14:36 - 0:03:58 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
5: INFO - 04/21/20 23:14:37 - 0:03:58 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
5: INFO - 04/21/20 23:14:38 - 0:03:59 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
0: INFO - 04/21/20 23:14:40 - 0:04:01 - Removed 0 empty sentences.
4: 
4: INFO - 04/21/20 23:14:41 - 0:04:02 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
4: INFO - 04/21/20 23:14:41 - 0:04:02 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
4: INFO - 04/21/20 23:14:42 - 0:04:03 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
4: INFO - 04/21/20 23:14:42 - 0:04:03 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
4: INFO - 04/21/20 23:14:43 - 0:04:05 - Removed 2 too long sentences.
3: INFO - 04/21/20 23:14:45 - 0:04:06 - Removed 2 too long sentences.
5: INFO - 04/21/20 23:14:45 - 0:04:07 - Removed 2 too long sentences.
0: INFO - 04/21/20 23:14:45 - 0:04:07 - Removed 2 too long sentences.
1: INFO - 04/21/20 23:14:47 - 0:04:09 - Removed 0 empty sentences.
1: 
1: INFO - 04/21/20 23:14:47 - 0:04:09 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/21/20 23:14:48 - 0:04:09 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/21/20 23:14:48 - 0:04:09 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/21/20 23:14:48 - 0:04:10 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
2: INFO - 04/21/20 23:14:48 - 0:04:09 - Removed 0 empty sentences.
2: 
2: INFO - 04/21/20 23:14:48 - 0:04:09 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
2: INFO - 04/21/20 23:14:49 - 0:04:10 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/21/20 23:14:49 - 0:04:10 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
4: 
4: INFO - 04/21/20 23:14:49 - 0:04:10 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
2: INFO - 04/21/20 23:14:49 - 0:04:10 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
4: INFO - 04/21/20 23:14:49 - 0:04:11 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
4: INFO - 04/21/20 23:14:50 - 0:04:11 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
4: INFO - 04/21/20 23:14:50 - 0:04:11 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
0: 
0: INFO - 04/21/20 23:14:51 - 0:04:12 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
0: INFO - 04/21/20 23:14:51 - 0:04:12 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
5: INFO - 04/21/20 23:14:51 - 0:04:13 - Removed 0 empty sentences.
5: 
5: INFO - 04/21/20 23:14:51 - 0:04:13 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
0: INFO - 04/21/20 23:14:51 - 0:04:12 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
5: INFO - 04/21/20 23:14:52 - 0:04:13 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/21/20 23:14:52 - 0:04:13 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
5: INFO - 04/21/20 23:14:52 - 0:04:13 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
5: INFO - 04/21/20 23:14:52 - 0:04:14 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
2: INFO - 04/21/20 23:14:53 - 0:04:14 - Removed 0 empty sentences.
2: 
2: 
5: 
5: INFO - 04/21/20 23:14:53 - 0:04:15 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
2: INFO - 04/21/20 23:14:54 - 0:04:15 - ============ Data summary
2: INFO - 04/21/20 23:14:54 - 0:04:15 - Parallel data      - train -        de-en:   3308331
2: INFO - 04/21/20 23:14:54 - 0:04:15 - Parallel data      - valid -        de-en:      5000
2: INFO - 04/21/20 23:14:54 - 0:04:15 - Parallel data      -  test -        de-en:      5000
2: 
3: 
3: INFO - 04/21/20 23:14:54 - 0:04:15 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
2: INFO - 04/21/20 23:14:54 - 0:04:15 - Removed 0 empty sentences.
5: INFO - 04/21/20 23:14:54 - 0:04:16 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/21/20 23:14:55 - 0:04:16 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
5: INFO - 04/21/20 23:14:55 - 0:04:17 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
4: INFO - 04/21/20 23:14:55 - 0:04:16 - Removed 0 empty sentences.
4: 
4: INFO - 04/21/20 23:14:55 - 0:04:16 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/21/20 23:14:55 - 0:04:16 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
4: INFO - 04/21/20 23:14:55 - 0:04:17 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
4: INFO - 04/21/20 23:14:56 - 0:04:17 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
5: INFO - 04/21/20 23:14:56 - 0:04:17 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
3: INFO - 04/21/20 23:14:56 - 0:04:17 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
4: INFO - 04/21/20 23:14:56 - 0:04:17 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: INFO - 04/21/20 23:14:56 - 0:04:18 - Removed 0 empty sentences.
1: 
1: 
1: INFO - 04/21/20 23:14:56 - 0:04:18 - ============ Data summary
1: INFO - 04/21/20 23:14:56 - 0:04:18 - Parallel data      - train -        de-en:   3308331
1: INFO - 04/21/20 23:14:56 - 0:04:18 - Parallel data      - valid -        de-en:      5000
1: INFO - 04/21/20 23:14:56 - 0:04:18 - Parallel data      -  test -        de-en:      5000
1: 
5: INFO - 04/21/20 23:14:57 - 0:04:18 - Removed 0 empty sentences.
5: 
5: 
5: INFO - 04/21/20 23:14:57 - 0:04:18 - ============ Data summary
5: INFO - 04/21/20 23:14:57 - 0:04:18 - Parallel data      - train -        de-en:   3308331
5: INFO - 04/21/20 23:14:57 - 0:04:18 - Parallel data      - valid -        de-en:      5000
5: INFO - 04/21/20 23:14:57 - 0:04:18 - Parallel data      -  test -        de-en:      5000
5: 
1: INFO - 04/21/20 23:14:57 - 0:04:19 - Removed 2 too long sentences.
4: INFO - 04/21/20 23:15:00 - 0:04:21 - Removed 0 empty sentences.
4: 
4: 
4: INFO - 04/21/20 23:15:01 - 0:04:22 - ============ Data summary
4: INFO - 04/21/20 23:15:01 - 0:04:22 - Parallel data      - train -        de-en:   3308331
4: INFO - 04/21/20 23:15:01 - 0:04:22 - Parallel data      - valid -        de-en:      5000
4: INFO - 04/21/20 23:15:01 - 0:04:22 - Parallel data      -  test -        de-en:      5000
4: 
4: INFO - 04/21/20 23:15:02 - 0:04:23 - Removed 0 empty sentences.
4: 
4: INFO - 04/21/20 23:15:02 - 0:04:23 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
4: INFO - 04/21/20 23:15:02 - 0:04:23 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
4: INFO - 04/21/20 23:15:02 - 0:04:23 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
4: INFO - 04/21/20 23:15:03 - 0:04:24 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
2: INFO - 04/21/20 23:15:04 - 0:04:25 - Reloading model from /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth ...
0: INFO - 04/21/20 23:15:04 - 0:04:25 - Removed 0 empty sentences.
0: 
0: INFO - 04/21/20 23:15:04 - 0:04:25 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
0: INFO - 04/21/20 23:15:05 - 0:04:26 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/21/20 23:15:05 - 0:04:26 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
0: INFO - 04/21/20 23:15:05 - 0:04:26 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
4: INFO - 04/21/20 23:15:07 - 0:04:28 - Removed 0 empty sentences.
4: 
4: 
1: 
1: INFO - 04/21/20 23:15:07 - 0:04:29 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
4: INFO - 04/21/20 23:15:07 - 0:04:28 - ============ Data summary
4: INFO - 04/21/20 23:15:07 - 0:04:28 - Parallel data      - train -        de-en:   3308331
4: INFO - 04/21/20 23:15:07 - 0:04:28 - Parallel data      - valid -        de-en:      5000
4: INFO - 04/21/20 23:15:07 - 0:04:28 - Parallel data      -  test -        de-en:      5000
4: 
5: INFO - 04/21/20 23:15:07 - 0:04:28 - Reloading model from /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth ...
1: INFO - 04/21/20 23:15:07 - 0:04:29 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/21/20 23:15:08 - 0:04:30 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
0: INFO - 04/21/20 23:15:09 - 0:04:30 - Removed 0 empty sentences.
0: 
0: 
1: INFO - 04/21/20 23:15:09 - 0:04:30 - Removed 0 empty sentences.
1: INFO - 04/21/20 23:15:09 - 0:04:31 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
0: INFO - 04/21/20 23:15:09 - 0:04:30 - ============ Data summary
0: INFO - 04/21/20 23:15:09 - 0:04:30 - Parallel data      - train -        de-en:   3308331
0: INFO - 04/21/20 23:15:09 - 0:04:30 - Parallel data      - valid -        de-en:      5000
0: INFO - 04/21/20 23:15:09 - 0:04:30 - Parallel data      -  test -        de-en:      5000
0: 
3: INFO - 04/21/20 23:15:10 - 0:04:31 - Removed 0 empty sentences.
4: INFO - 04/21/20 23:15:11 - 0:04:32 - Reloading model from /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth ...
1: INFO - 04/21/20 23:15:13 - 0:04:34 - Reloading model from /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth ...
5: INFO - 04/21/20 23:15:18 - 0:04:39 - Removed 0 empty sentences.
5: 
5: INFO - 04/21/20 23:15:18 - 0:04:39 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/21/20 23:15:18 - 0:04:39 - Removed 0 empty sentences.
3: 
3: INFO - 04/21/20 23:15:18 - 0:04:39 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
5: INFO - 04/21/20 23:15:18 - 0:04:40 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
5: INFO - 04/21/20 23:15:18 - 0:04:40 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
0: INFO - 04/21/20 23:15:18 - 0:04:40 - Removed 0 empty sentences.
2: INFO - 04/21/20 23:15:18 - 0:04:40 - Removed 2 too long sentences.
3: INFO - 04/21/20 23:15:19 - 0:04:40 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
4: INFO - 04/21/20 23:15:19 - 0:04:40 - Reloading model from /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth ...
3: INFO - 04/21/20 23:15:19 - 0:04:40 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
5: INFO - 04/21/20 23:15:19 - 0:04:41 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
3: INFO - 04/21/20 23:15:20 - 0:04:41 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
0: INFO - 04/21/20 23:15:20 - 0:04:41 - Reloading model from /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth ...
5: INFO - 04/21/20 23:15:26 - 0:04:47 - Removed 0 empty sentences.
5: 
5: 
5: INFO - 04/21/20 23:15:26 - 0:04:48 - ============ Data summary
5: INFO - 04/21/20 23:15:26 - 0:04:48 - Parallel data      - train -        de-en:   3308331
5: INFO - 04/21/20 23:15:26 - 0:04:48 - Parallel data      - valid -        de-en:      5000
5: INFO - 04/21/20 23:15:26 - 0:04:48 - Parallel data      -  test -        de-en:      5000
5: 
2: 
2: INFO - 04/21/20 23:15:26 - 0:04:48 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
3: INFO - 04/21/20 23:15:27 - 0:04:48 - Removed 0 empty sentences.
3: 
3: 
2: INFO - 04/21/20 23:15:27 - 0:04:48 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/21/20 23:15:27 - 0:04:49 - ============ Data summary
3: INFO - 04/21/20 23:15:27 - 0:04:49 - Parallel data      - train -        de-en:   3308331
3: INFO - 04/21/20 23:15:27 - 0:04:49 - Parallel data      - valid -        de-en:      5000
3: INFO - 04/21/20 23:15:27 - 0:04:49 - Parallel data      -  test -        de-en:      5000
3: 
2: INFO - 04/21/20 23:15:28 - 0:04:49 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: INFO - 04/21/20 23:15:28 - 0:04:50 - Removed 0 empty sentences.
1: 
1: INFO - 04/21/20 23:15:28 - 0:04:50 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
2: INFO - 04/21/20 23:15:28 - 0:04:50 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/21/20 23:15:29 - 0:04:51 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/21/20 23:15:29 - 0:04:51 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/21/20 23:15:29 - 0:04:51 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: INFO - 04/21/20 23:15:35 - 0:04:56 - Removed 2 too long sentences.
3: INFO - 04/21/20 23:15:36 - 0:04:57 - Removed 2 too long sentences.
1: INFO - 04/21/20 23:15:37 - 0:04:59 - Removed 0 empty sentences.
1: 
1: 
1: INFO - 04/21/20 23:15:38 - 0:05:00 - ============ Data summary
1: INFO - 04/21/20 23:15:38 - 0:05:00 - Parallel data      - train -        de-en:   3308331
1: INFO - 04/21/20 23:15:38 - 0:05:00 - Parallel data      - valid -        de-en:      5000
1: INFO - 04/21/20 23:15:38 - 0:05:00 - Parallel data      -  test -        de-en:      5000
1: 
0: INFO - 04/21/20 23:15:42 - 0:05:03 - Removed 2 too long sentences.
5: INFO - 04/21/20 23:15:42 - 0:05:04 - Reloading model from /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth ...
3: INFO - 04/21/20 23:15:43 - 0:05:04 - Reloading model from /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth ...
3: 
3: INFO - 04/21/20 23:15:44 - 0:05:05 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
1: 
1: INFO - 04/21/20 23:15:44 - 0:05:05 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
1: INFO - 04/21/20 23:15:44 - 0:05:06 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/21/20 23:15:45 - 0:05:06 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/21/20 23:15:45 - 0:05:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
3: INFO - 04/21/20 23:15:45 - 0:05:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: INFO - 04/21/20 23:15:45 - 0:05:07 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
3: INFO - 04/21/20 23:15:46 - 0:05:07 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
2: INFO - 04/21/20 23:15:49 - 0:05:10 - Removed 0 empty sentences.
2: 
2: INFO - 04/21/20 23:15:49 - 0:05:10 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
2: INFO - 04/21/20 23:15:49 - 0:05:11 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/21/20 23:15:49 - 0:05:11 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
2: INFO - 04/21/20 23:15:50 - 0:05:12 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
0: 
0: INFO - 04/21/20 23:15:51 - 0:05:12 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
0: INFO - 04/21/20 23:15:52 - 0:05:13 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/21/20 23:15:52 - 0:05:13 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
0: INFO - 04/21/20 23:15:53 - 0:05:14 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/21/20 23:15:53 - 0:05:15 - Reloading model from /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth ...
2: INFO - 04/21/20 23:15:57 - 0:05:19 - Removed 0 empty sentences.
2: 
2: 
2: INFO - 04/21/20 23:15:58 - 0:05:19 - ============ Data summary
2: INFO - 04/21/20 23:15:58 - 0:05:19 - Parallel data      - train -        de-en:   3308331
2: INFO - 04/21/20 23:15:58 - 0:05:19 - Parallel data      - valid -        de-en:      5000
2: INFO - 04/21/20 23:15:58 - 0:05:19 - Parallel data      -  test -        de-en:      5000
2: 
1: INFO - 04/21/20 23:16:05 - 0:05:26 - Removed 0 empty sentences.
1: 
1: INFO - 04/21/20 23:16:05 - 0:05:26 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/21/20 23:16:05 - 0:05:27 - Removed 0 empty sentences.
3: 
3: INFO - 04/21/20 23:16:05 - 0:05:27 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/21/20 23:16:06 - 0:05:27 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/21/20 23:16:06 - 0:05:27 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/21/20 23:16:06 - 0:05:27 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/21/20 23:16:06 - 0:05:28 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
3: INFO - 04/21/20 23:16:07 - 0:05:28 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: INFO - 04/21/20 23:16:07 - 0:05:28 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
0: INFO - 04/21/20 23:16:10 - 0:05:31 - Removed 0 empty sentences.
0: 
0: INFO - 04/21/20 23:16:10 - 0:05:31 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
0: INFO - 04/21/20 23:16:11 - 0:05:32 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/21/20 23:16:11 - 0:05:32 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
0: INFO - 04/21/20 23:16:11 - 0:05:32 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: INFO - 04/21/20 23:16:13 - 0:05:34 - Removed 0 empty sentences.
1: 
1: 
3: INFO - 04/21/20 23:16:13 - 0:05:34 - Removed 0 empty sentences.
3: 
3: 
1: INFO - 04/21/20 23:16:13 - 0:05:34 - ============ Data summary
1: INFO - 04/21/20 23:16:13 - 0:05:34 - Parallel data      - train -        de-en:   3308331
1: INFO - 04/21/20 23:16:13 - 0:05:34 - Parallel data      - valid -        de-en:      5000
1: INFO - 04/21/20 23:16:13 - 0:05:34 - Parallel data      -  test -        de-en:      5000
1: 
3: INFO - 04/21/20 23:16:13 - 0:05:35 - ============ Data summary
3: INFO - 04/21/20 23:16:13 - 0:05:35 - Parallel data      - train -        de-en:   3308331
3: INFO - 04/21/20 23:16:13 - 0:05:35 - Parallel data      - valid -        de-en:      5000
3: INFO - 04/21/20 23:16:13 - 0:05:35 - Parallel data      -  test -        de-en:      5000
3: 
2: INFO - 04/21/20 23:16:14 - 0:05:35 - Reloading model from /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth ...
0: INFO - 04/21/20 23:16:18 - 0:05:40 - Removed 0 empty sentences.
0: 
0: 
0: INFO - 04/21/20 23:16:19 - 0:05:40 - ============ Data summary
0: INFO - 04/21/20 23:16:19 - 0:05:40 - Parallel data      - train -        de-en:   3308331
0: INFO - 04/21/20 23:16:19 - 0:05:40 - Parallel data      - valid -        de-en:      5000
0: INFO - 04/21/20 23:16:19 - 0:05:40 - Parallel data      -  test -        de-en:      5000
0: 
1: INFO - 04/21/20 23:16:30 - 0:05:51 - Reloading model from /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth ...
3: INFO - 04/21/20 23:16:30 - 0:05:51 - Reloading model from /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth ...
0: INFO - 04/21/20 23:16:35 - 0:05:56 - Reloading model from /data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth ...
5: INFO - 04/21/20 23:16:56 - 0:06:17 - Model: TransformerModel(
5:                                        (projector): Projector(
5:                                          (linear): Linear(in_features=1536, out_features=512, bias=True)
5:                                        )
5:                                        (regional_encodings): RegionalEncodings(
5:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
5:                                        )
5:                                        (position_embeddings): Embedding(512, 512)
5:                                        (lang_embeddings): Embedding(3, 512)
5:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
5:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                        (attentions): ModuleList(
5:                                          (0): MultiHeadAttention(
5:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                          )
5:                                          (1): MultiHeadAttention(
5:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                          )
5:                                          (2): MultiHeadAttention(
5:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                          )
5:                                          (3): MultiHeadAttention(
5:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                          )
5:                                          (4): MultiHeadAttention(
5:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                          )
5:                                          (5): MultiHeadAttention(
5:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                          )
5:                                        )
5:                                        (layer_norm1): ModuleList(
5:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                        )
5:                                        (ffns): ModuleList(
5:                                          (0): TransformerFFN(
5:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
5:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
5:                                          )
5:                                          (1): TransformerFFN(
5:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
5:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
5:                                          )
5:                                          (2): TransformerFFN(
5:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
5:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
5:                                          )
5:                                          (3): TransformerFFN(
5:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
5:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
5:                                          )
5:                                          (4): TransformerFFN(
5:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
5:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
5:                                          )
5:                                          (5): TransformerFFN(
5:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
5:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
5:                                          )
5:                                        )
5:                                        (layer_norm2): ModuleList(
5:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                        )
5:                                        (memories): ModuleDict()
5:                                        (pred_layer): PredLayer(
5:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
5:                                        )
5:                                        (img_pred_layer): ImgPredLayer(
5:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
5:                                        )
5:                                      )
5: INFO - 04/21/20 23:16:56 - 0:06:17 - Number of parameters (model): 42634904
2: INFO - 04/21/20 23:16:58 - 0:06:19 - Model: TransformerModel(
2:                                        (projector): Projector(
2:                                          (linear): Linear(in_features=1536, out_features=512, bias=True)
2:                                        )
2:                                        (regional_encodings): RegionalEncodings(
2:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
2:                                        )
2:                                        (position_embeddings): Embedding(512, 512)
2:                                        (lang_embeddings): Embedding(3, 512)
2:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
2:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        (attentions): ModuleList(
2:                                          (0): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (1): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (2): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (3): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (4): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (5): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                        )
2:                                        (layer_norm1): ModuleList(
2:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        )
2:                                        (ffns): ModuleList(
2:                                          (0): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (1): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (2): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (3): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (4): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (5): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                        )
2:                                        (layer_norm2): ModuleList(
2:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        )
2:                                        (memories): ModuleDict()
2:                                        (pred_layer): PredLayer(
2:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
2:                                        )
2:                                        (img_pred_layer): ImgPredLayer(
2:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
2:                                        )
2:                                      )
2: INFO - 04/21/20 23:16:58 - 0:06:19 - Number of parameters (model): 42634904
5: INFO - 04/21/20 23:17:00 - 0:06:22 - Found 0 memories.
5: INFO - 04/21/20 23:17:00 - 0:06:22 - Found 6 FFN.
5: INFO - 04/21/20 23:17:00 - 0:06:22 - Found 108 parameters in model.
5: INFO - 04/21/20 23:17:00 - 0:06:22 - Using nn.parallel.DistributedDataParallel ...
2: INFO - 04/21/20 23:17:01 - 0:06:22 - Found 0 memories.
2: INFO - 04/21/20 23:17:01 - 0:06:22 - Found 6 FFN.
2: INFO - 04/21/20 23:17:01 - 0:06:22 - Found 108 parameters in model.
2: INFO - 04/21/20 23:17:01 - 0:06:22 - Using nn.parallel.DistributedDataParallel ...
4: INFO - 04/21/20 23:17:03 - 0:06:24 - Model: TransformerModel(
4:                                        (projector): Projector(
4:                                          (linear): Linear(in_features=1536, out_features=512, bias=True)
4:                                        )
4:                                        (regional_encodings): RegionalEncodings(
4:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
4:                                        )
4:                                        (position_embeddings): Embedding(512, 512)
4:                                        (lang_embeddings): Embedding(3, 512)
4:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
4:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                        (attentions): ModuleList(
4:                                          (0): MultiHeadAttention(
4:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                          )
4:                                          (1): MultiHeadAttention(
4:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                          )
4:                                          (2): MultiHeadAttention(
4:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                          )
4:                                          (3): MultiHeadAttention(
4:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                          )
4:                                          (4): MultiHeadAttention(
4:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                          )
4:                                          (5): MultiHeadAttention(
4:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                          )
4:                                        )
4:                                        (layer_norm1): ModuleList(
4:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                        )
4:                                        (ffns): ModuleList(
4:                                          (0): TransformerFFN(
4:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
4:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
4:                                          )
4:                                          (1): TransformerFFN(
4:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
4:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
4:                                          )
4:                                          (2): TransformerFFN(
4:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
4:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
4:                                          )
4:                                          (3): TransformerFFN(
4:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
4:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
4:                                          )
4:                                          (4): TransformerFFN(
4:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
4:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
4:                                          )
4:                                          (5): TransformerFFN(
4:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
4:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
4:                                          )
4:                                        )
4:                                        (layer_norm2): ModuleList(
4:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                        )
4:                                        (memories): ModuleDict()
4:                                        (pred_layer): PredLayer(
4:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
4:                                        )
4:                                        (img_pred_layer): ImgPredLayer(
4:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
4:                                        )
4:                                      )
4: INFO - 04/21/20 23:17:03 - 0:06:24 - Number of parameters (model): 42634904
4: INFO - 04/21/20 23:17:07 - 0:06:28 - Found 0 memories.
4: INFO - 04/21/20 23:17:07 - 0:06:28 - Found 6 FFN.
4: INFO - 04/21/20 23:17:07 - 0:06:28 - Found 108 parameters in model.
4: INFO - 04/21/20 23:17:07 - 0:06:28 - Using nn.parallel.DistributedDataParallel ...
4: INFO - 04/21/20 23:17:12 - 0:06:33 - Model: TransformerModel(
4:                                        (projector): Projector(
4:                                          (linear): Linear(in_features=1536, out_features=512, bias=True)
4:                                        )
4:                                        (regional_encodings): RegionalEncodings(
4:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
4:                                        )
4:                                        (position_embeddings): Embedding(512, 512)
4:                                        (lang_embeddings): Embedding(3, 512)
4:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
4:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                        (attentions): ModuleList(
4:                                          (0): MultiHeadAttention(
4:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                          )
4:                                          (1): MultiHeadAttention(
4:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                          )
4:                                          (2): MultiHeadAttention(
4:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                          )
4:                                          (3): MultiHeadAttention(
4:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                          )
4:                                          (4): MultiHeadAttention(
4:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                          )
4:                                          (5): MultiHeadAttention(
4:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
4:                                          )
4:                                        )
4:                                        (layer_norm1): ModuleList(
4:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                        )
4:                                        (ffns): ModuleList(
4:                                          (0): TransformerFFN(
4:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
4:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
4:                                          )
4:                                          (1): TransformerFFN(
4:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
4:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
4:                                          )
4:                                          (2): TransformerFFN(
4:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
4:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
4:                                          )
4:                                          (3): TransformerFFN(
4:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
4:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
4:                                          )
4:                                          (4): TransformerFFN(
4:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
4:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
4:                                          )
4:                                          (5): TransformerFFN(
4:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
4:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
4:                                          )
4:                                        )
4:                                        (layer_norm2): ModuleList(
4:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
4:                                        )
4:                                        (memories): ModuleDict()
4:                                        (pred_layer): PredLayer(
4:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
4:                                        )
4:                                        (img_pred_layer): ImgPredLayer(
4:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
4:                                        )
4:                                      )
4: INFO - 04/21/20 23:17:12 - 0:06:33 - Number of parameters (model): 42634904
0: INFO - 04/21/20 23:17:12 - 0:06:34 - Model: TransformerModel(
0:                                        (projector): Projector(
0:                                          (linear): Linear(in_features=1536, out_features=512, bias=True)
0:                                        )
0:                                        (regional_encodings): RegionalEncodings(
0:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
0:                                        )
0:                                        (position_embeddings): Embedding(512, 512)
0:                                        (lang_embeddings): Embedding(3, 512)
0:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
0:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        (attentions): ModuleList(
0:                                          (0): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (1): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (2): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (3): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (4): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (5): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                        )
0:                                        (layer_norm1): ModuleList(
0:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        )
0:                                        (ffns): ModuleList(
0:                                          (0): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (1): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (2): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (3): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (4): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (5): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                        )
0:                                        (layer_norm2): ModuleList(
0:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        )
0:                                        (memories): ModuleDict()
0:                                        (pred_layer): PredLayer(
0:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
0:                                        )
0:                                        (img_pred_layer): ImgPredLayer(
0:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
0:                                        )
0:                                      )
0: INFO - 04/21/20 23:17:12 - 0:06:34 - Number of parameters (model): 42634904
4: INFO - 04/21/20 23:17:15 - 0:06:36 - Found 0 memories.
4: INFO - 04/21/20 23:17:15 - 0:06:36 - Found 6 FFN.
4: INFO - 04/21/20 23:17:15 - 0:06:36 - Found 108 parameters in model.
4: INFO - 04/21/20 23:17:15 - 0:06:36 - Using nn.parallel.DistributedDataParallel ...
0: INFO - 04/21/20 23:17:15 - 0:06:36 - Found 0 memories.
0: INFO - 04/21/20 23:17:15 - 0:06:36 - Found 6 FFN.
0: INFO - 04/21/20 23:17:15 - 0:06:36 - Found 108 parameters in model.
0: INFO - 04/21/20 23:17:15 - 0:06:36 - Using nn.parallel.DistributedDataParallel ...
1: INFO - 04/21/20 23:17:27 - 0:06:49 - Model: TransformerModel(
1:                                        (projector): Projector(
1:                                          (linear): Linear(in_features=1536, out_features=512, bias=True)
1:                                        )
1:                                        (regional_encodings): RegionalEncodings(
1:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
1:                                        )
1:                                        (position_embeddings): Embedding(512, 512)
1:                                        (lang_embeddings): Embedding(3, 512)
1:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
1:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        (attentions): ModuleList(
1:                                          (0): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (1): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (2): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (3): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (4): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (5): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                        )
1:                                        (layer_norm1): ModuleList(
1:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        )
1:                                        (ffns): ModuleList(
1:                                          (0): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (1): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (2): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (3): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (4): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (5): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                        )
1:                                        (layer_norm2): ModuleList(
1:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        )
1:                                        (memories): ModuleDict()
1:                                        (pred_layer): PredLayer(
1:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
1:                                        )
1:                                        (img_pred_layer): ImgPredLayer(
1:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
1:                                        )
1:                                      )
1: INFO - 04/21/20 23:17:27 - 0:06:49 - Number of parameters (model): 42634904
1: INFO - 04/21/20 23:17:30 - 0:06:51 - Found 0 memories.
1: INFO - 04/21/20 23:17:30 - 0:06:51 - Found 6 FFN.
1: INFO - 04/21/20 23:17:30 - 0:06:51 - Found 108 parameters in model.
1: INFO - 04/21/20 23:17:30 - 0:06:51 - Using nn.parallel.DistributedDataParallel ...
0: INFO - 04/21/20 23:17:30 - 0:06:52 - Using nn.parallel.DistributedDataParallel ...
4: INFO - 04/21/20 23:17:30 - 0:06:52 - Using nn.parallel.DistributedDataParallel ...
1: INFO - 04/21/20 23:17:31 - 0:06:52 - Using nn.parallel.DistributedDataParallel ...
0: INFO - 04/21/20 23:17:31 - 0:06:52 - Optimizers: model
4: INFO - 04/21/20 23:17:31 - 0:06:52 - Optimizers: model
1: INFO - 04/21/20 23:17:31 - 0:06:53 - Optimizers: model
0: INFO - 04/21/20 23:17:31 - 0:06:52 - ============ Starting epoch 0 ... ============
0: INFO - 04/21/20 23:17:31 - 0:06:52 - Creating new training data iterator (pred,en,de) ...
4: INFO - 04/21/20 23:17:31 - 0:06:52 - ============ Starting epoch 0 ... ============
4: INFO - 04/21/20 23:17:31 - 0:06:52 - Creating new training data iterator (pred,en,de) ...
3: INFO - 04/21/20 23:17:54 - 0:07:15 - Model: TransformerModel(
3:                                        (projector): Projector(
3:                                          (linear): Linear(in_features=1536, out_features=512, bias=True)
3:                                        )
3:                                        (regional_encodings): RegionalEncodings(
3:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
3:                                        )
3:                                        (position_embeddings): Embedding(512, 512)
3:                                        (lang_embeddings): Embedding(3, 512)
3:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
3:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        (attentions): ModuleList(
3:                                          (0): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (1): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (2): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (3): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (4): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (5): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm1): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (ffns): ModuleList(
3:                                          (0): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (1): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (2): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (3): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (4): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (5): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm2): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (memories): ModuleDict()
3:                                        (pred_layer): PredLayer(
3:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
3:                                        )
3:                                        (img_pred_layer): ImgPredLayer(
3:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
3:                                        )
3:                                      )
3: INFO - 04/21/20 23:17:54 - 0:07:15 - Number of parameters (model): 42634904
5: INFO - 04/21/20 23:17:55 - 0:07:17 - Model: TransformerModel(
5:                                        (projector): Projector(
5:                                          (linear): Linear(in_features=1536, out_features=512, bias=True)
5:                                        )
5:                                        (regional_encodings): RegionalEncodings(
5:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
5:                                        )
5:                                        (position_embeddings): Embedding(512, 512)
5:                                        (lang_embeddings): Embedding(3, 512)
5:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
5:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                        (attentions): ModuleList(
5:                                          (0): MultiHeadAttention(
5:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                          )
5:                                          (1): MultiHeadAttention(
5:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                          )
5:                                          (2): MultiHeadAttention(
5:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                          )
5:                                          (3): MultiHeadAttention(
5:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                          )
5:                                          (4): MultiHeadAttention(
5:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                          )
5:                                          (5): MultiHeadAttention(
5:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
5:                                          )
5:                                        )
5:                                        (layer_norm1): ModuleList(
5:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                        )
5:                                        (ffns): ModuleList(
5:                                          (0): TransformerFFN(
5:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
5:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
5:                                          )
5:                                          (1): TransformerFFN(
5:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
5:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
5:                                          )
5:                                          (2): TransformerFFN(
5:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
5:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
5:                                          )
5:                                          (3): TransformerFFN(
5:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
5:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
5:                                          )
5:                                          (4): TransformerFFN(
5:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
5:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
5:                                          )
5:                                          (5): TransformerFFN(
5:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
5:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
5:                                          )
5:                                        )
5:                                        (layer_norm2): ModuleList(
5:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
5:                                        )
5:                                        (memories): ModuleDict()
5:                                        (pred_layer): PredLayer(
5:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
5:                                        )
5:                                        (img_pred_layer): ImgPredLayer(
5:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
5:                                        )
5:                                      )
5: INFO - 04/21/20 23:17:55 - 0:07:17 - Number of parameters (model): 42634904
5: INFO - 04/21/20 23:17:58 - 0:07:20 - Found 0 memories.
5: INFO - 04/21/20 23:17:58 - 0:07:20 - Found 6 FFN.
5: INFO - 04/21/20 23:17:58 - 0:07:20 - Found 108 parameters in model.
5: INFO - 04/21/20 23:17:58 - 0:07:20 - Using nn.parallel.DistributedDataParallel ...
3: INFO - 04/21/20 23:17:59 - 0:07:20 - Found 0 memories.
3: INFO - 04/21/20 23:17:59 - 0:07:20 - Found 6 FFN.
3: INFO - 04/21/20 23:17:59 - 0:07:20 - Found 108 parameters in model.
3: INFO - 04/21/20 23:17:59 - 0:07:20 - Using nn.parallel.DistributedDataParallel ...
4: Traceback (most recent call last):
4:   File "train.py", line 348, in <module>
4:     main(params)
4:   File "train.py", line 289, in main
4:     trainer.mlm_step(lang1, lang2, params.lambda_mlm, iter)
4:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 840, in mlm_step
4:     tensor = model('fwd', x=x, lengths=lengths, positions=positions, langs=langs, causal=False)
4:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
4:     result = self.forward(*input, **kwargs)
4:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 464, in forward
4:     self.reducer.prepare_for_backward([])
4: RuntimeError: Expected to have finished reduction in the prior iteration before starting a new one. This error indicates that your module has parameters that were not used in producing loss. You can enable unused parameter detection by (1) passing the keyword argument `find_unused_parameters=True` to `torch.nn.parallel.DistributedDataParallel`; (2) making sure all `forward` function outputs participate in calculating loss. If you already have done the above two steps, then the distributed data parallel module wasn't able to locate the output tensors in the return value of your module's `forward` function. Please include the loss function and the structure of the return value of `forward` of your module when reporting this issue (e.g. list, dict, iterable). (prepare_for_backward at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:514)
4: frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x33 (0x7fbd77086193 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libc10.so)
4: frame #1: c10d::Reducer::prepare_for_backward(std::vector<at::Tensor, std::allocator<at::Tensor> > const&) + 0x731 (0x7fbdb9656471 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
4: frame #2: <unknown function> + 0xa0e63a (0x7fbdb964263a in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
4: frame #3: <unknown function> + 0x2956c4 (0x7fbdb8ec96c4 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
4: <omitting python frames>
4: frame #35: main + 0x119 (0x400a99 in /home/menekse/virtualenvs/torch_env/bin/python)
4: frame #36: __libc_start_main + 0xf5 (0x7fbdca0193d5 in /lib64/libc.so.6)
4: frame #37: /home/menekse/virtualenvs/torch_env/bin/python() [0x400c20]
4: 
0: Traceback (most recent call last):
0:   File "train.py", line 348, in <module>
0:     main(params)
0:   File "train.py", line 289, in main
0:     trainer.mlm_step(lang1, lang2, params.lambda_mlm, iter)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 840, in mlm_step
0:     tensor = model('fwd', x=x, lengths=lengths, positions=positions, langs=langs, causal=False)
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
0:     result = self.forward(*input, **kwargs)
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 464, in forward
0:     self.reducer.prepare_for_backward([])
0: RuntimeError: Expected to have finished reduction in the prior iteration before starting a new one. This error indicates that your module has parameters that were not used in producing loss. You can enable unused parameter detection by (1) passing the keyword argument `find_unused_parameters=True` to `torch.nn.parallel.DistributedDataParallel`; (2) making sure all `forward` function outputs participate in calculating loss. If you already have done the above two steps, then the distributed data parallel module wasn't able to locate the output tensors in the return value of your module's `forward` function. Please include the loss function and the structure of the return value of `forward` of your module when reporting this issue (e.g. list, dict, iterable). (prepare_for_backward at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:514)
0: frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x33 (0x7f3cbe516193 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libc10.so)
0: frame #1: c10d::Reducer::prepare_for_backward(std::vector<at::Tensor, std::allocator<at::Tensor> > const&) + 0x731 (0x7f3d00ae6471 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
0: frame #2: <unknown function> + 0xa0e63a (0x7f3d00ad263a in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
0: frame #3: <unknown function> + 0x2956c4 (0x7f3d003596c4 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
0: <omitting python frames>
0: frame #35: main + 0x119 (0x400a99 in /home/menekse/virtualenvs/torch_env/bin/python)
0: frame #36: __libc_start_main + 0xf5 (0x7f3d114a93d5 in /lib64/libc.so.6)
0: frame #37: /home/menekse/virtualenvs/torch_env/bin/python() [0x400c20]
0: 
1: INFO - 04/21/20 23:18:06 - 0:07:28 - Model: TransformerModel(
1:                                        (projector): Projector(
1:                                          (linear): Linear(in_features=1536, out_features=512, bias=True)
1:                                        )
1:                                        (regional_encodings): RegionalEncodings(
1:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
1:                                        )
1:                                        (position_embeddings): Embedding(512, 512)
1:                                        (lang_embeddings): Embedding(3, 512)
1:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
1:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        (attentions): ModuleList(
1:                                          (0): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (1): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (2): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (3): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (4): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (5): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                        )
1:                                        (layer_norm1): ModuleList(
1:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        )
1:                                        (ffns): ModuleList(
1:                                          (0): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (1): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (2): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (3): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (4): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (5): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                        )
1:                                        (layer_norm2): ModuleList(
1:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        )
1:                                        (memories): ModuleDict()
1:                                        (pred_layer): PredLayer(
1:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
1:                                        )
1:                                        (img_pred_layer): ImgPredLayer(
1:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
1:                                        )
1:                                      )
1: INFO - 04/21/20 23:18:06 - 0:07:28 - Number of parameters (model): 42634904
1: INFO - 04/21/20 23:18:10 - 0:07:32 - Found 0 memories.
1: INFO - 04/21/20 23:18:10 - 0:07:32 - Found 6 FFN.
1: INFO - 04/21/20 23:18:10 - 0:07:32 - Found 108 parameters in model.
1: INFO - 04/21/20 23:18:10 - 0:07:32 - Using nn.parallel.DistributedDataParallel ...
1: INFO - 04/21/20 23:18:18 - 0:07:39 - Model: TransformerModel(
1:                                        (projector): Projector(
1:                                          (linear): Linear(in_features=1536, out_features=512, bias=True)
1:                                        )
1:                                        (regional_encodings): RegionalEncodings(
1:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
1:                                        )
1:                                        (position_embeddings): Embedding(512, 512)
1:                                        (lang_embeddings): Embedding(3, 512)
1:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
1:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        (attentions): ModuleList(
1:                                          (0): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (1): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (2): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (3): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (4): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (5): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                        )
1:                                        (layer_norm1): ModuleList(
1:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        )
1:                                        (ffns): ModuleList(
1:                                          (0): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (1): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (2): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (3): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (4): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (5): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                        )
1:                                        (layer_norm2): ModuleList(
1:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        )
1:                                        (memories): ModuleDict()
1:                                        (pred_layer): PredLayer(
1:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
1:                                        )
1:                                        (img_pred_layer): ImgPredLayer(
1:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
1:                                        )
1:                                      )
1: INFO - 04/21/20 23:18:18 - 0:07:39 - Number of parameters (model): 42634904
1: INFO - 04/21/20 23:18:20 - 0:07:42 - Found 0 memories.
1: INFO - 04/21/20 23:18:20 - 0:07:42 - Found 6 FFN.
1: INFO - 04/21/20 23:18:20 - 0:07:42 - Found 108 parameters in model.
1: INFO - 04/21/20 23:18:20 - 0:07:42 - Using nn.parallel.DistributedDataParallel ...
2: INFO - 04/21/20 23:18:22 - 0:07:43 - Model: TransformerModel(
2:                                        (projector): Projector(
2:                                          (linear): Linear(in_features=1536, out_features=512, bias=True)
2:                                        )
2:                                        (regional_encodings): RegionalEncodings(
2:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
2:                                        )
2:                                        (position_embeddings): Embedding(512, 512)
2:                                        (lang_embeddings): Embedding(3, 512)
2:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
2:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        (attentions): ModuleList(
2:                                          (0): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (1): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (2): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (3): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (4): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (5): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                        )
2:                                        (layer_norm1): ModuleList(
2:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        )
2:                                        (ffns): ModuleList(
2:                                          (0): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (1): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (2): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (3): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (4): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (5): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                        )
2:                                        (layer_norm2): ModuleList(
2:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        )
2:                                        (memories): ModuleDict()
2:                                        (pred_layer): PredLayer(
2:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
2:                                        )
2:                                        (img_pred_layer): ImgPredLayer(
2:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
2:                                        )
2:                                      )
2: INFO - 04/21/20 23:18:22 - 0:07:43 - Number of parameters (model): 42634904
2: INFO - 04/21/20 23:18:23 - 0:07:45 - Found 0 memories.
2: INFO - 04/21/20 23:18:23 - 0:07:45 - Found 6 FFN.
2: INFO - 04/21/20 23:18:23 - 0:07:45 - Found 108 parameters in model.
2: INFO - 04/21/20 23:18:23 - 0:07:45 - Using nn.parallel.DistributedDataParallel ...
3: INFO - 04/21/20 23:18:31 - 0:07:52 - Model: TransformerModel(
3:                                        (projector): Projector(
3:                                          (linear): Linear(in_features=1536, out_features=512, bias=True)
3:                                        )
3:                                        (regional_encodings): RegionalEncodings(
3:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
3:                                        )
3:                                        (position_embeddings): Embedding(512, 512)
3:                                        (lang_embeddings): Embedding(3, 512)
3:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
3:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        (attentions): ModuleList(
3:                                          (0): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (1): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (2): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (3): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (4): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (5): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm1): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (ffns): ModuleList(
3:                                          (0): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (1): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (2): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (3): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (4): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (5): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm2): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (memories): ModuleDict()
3:                                        (pred_layer): PredLayer(
3:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
3:                                        )
3:                                        (img_pred_layer): ImgPredLayer(
3:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
3:                                        )
3:                                      )
3: INFO - 04/21/20 23:18:31 - 0:07:52 - Number of parameters (model): 42634904
0: INFO - 04/21/20 23:18:32 - 0:07:53 - Model: TransformerModel(
0:                                        (projector): Projector(
0:                                          (linear): Linear(in_features=1536, out_features=512, bias=True)
0:                                        )
0:                                        (regional_encodings): RegionalEncodings(
0:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
0:                                        )
0:                                        (position_embeddings): Embedding(512, 512)
0:                                        (lang_embeddings): Embedding(3, 512)
0:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
0:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        (attentions): ModuleList(
0:                                          (0): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (1): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (2): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (3): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (4): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (5): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                        )
0:                                        (layer_norm1): ModuleList(
0:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        )
0:                                        (ffns): ModuleList(
0:                                          (0): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (1): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (2): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (3): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (4): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (5): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                        )
0:                                        (layer_norm2): ModuleList(
0:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        )
0:                                        (memories): ModuleDict()
0:                                        (pred_layer): PredLayer(
0:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
0:                                        )
0:                                        (img_pred_layer): ImgPredLayer(
0:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
0:                                        )
0:                                      )
0: INFO - 04/21/20 23:18:32 - 0:07:53 - Number of parameters (model): 42634904
3: INFO - 04/21/20 23:18:33 - 0:07:54 - Found 0 memories.
3: INFO - 04/21/20 23:18:33 - 0:07:54 - Found 6 FFN.
3: INFO - 04/21/20 23:18:33 - 0:07:54 - Found 108 parameters in model.
3: INFO - 04/21/20 23:18:33 - 0:07:54 - Using nn.parallel.DistributedDataParallel ...
0: INFO - 04/21/20 23:18:34 - 0:07:55 - Found 0 memories.
0: INFO - 04/21/20 23:18:34 - 0:07:55 - Found 6 FFN.
0: INFO - 04/21/20 23:18:34 - 0:07:55 - Found 108 parameters in model.
0: INFO - 04/21/20 23:18:34 - 0:07:55 - Using nn.parallel.DistributedDataParallel ...
1: INFO - 04/21/20 23:18:35 - 0:07:56 - ============ Starting epoch 0 ... ============
1: INFO - 04/21/20 23:18:35 - 0:07:56 - Creating new training data iterator (pred,en,de) ...
1: Traceback (most recent call last):
1:   File "train.py", line 348, in <module>
1:     main(params)
1:   File "train.py", line 251, in main
1:     trainer = SingleTrainer(model, data, params)
1:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
1:     super().__init__(data, params)
1:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 67, in __init__
1:     setattr(self, name, nn.parallel.DistributedDataParallel(getattr(self, name), find_unused_parameters=False, device_ids=[params.local_rank], output_device=params.local_rank, broadcast_buffers=True))
1:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 303, in __init__
1:     self.broadcast_bucket_size)
1:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 485, in _distributed_broadcast_coalesced
1:     dist._broadcast_coalesced(self.process_group, tensors, buffer_size)
1: RuntimeError: NCCL error in: /pytorch/torch/lib/c10d/ProcessGroupNCCL.cpp:410, unhandled system error, NCCL version 2.4.8
1: Traceback (most recent call last):
1:   File "train.py", line 348, in <module>
1:     main(params)
1:   File "train.py", line 289, in main
1:     trainer.mlm_step(lang1, lang2, params.lambda_mlm, iter)
1:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 840, in mlm_step
1:     tensor = model('fwd', x=x, lengths=lengths, positions=positions, langs=langs, causal=False)
1:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
1:     result = self.forward(*input, **kwargs)
1:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 464, in forward
1:     self.reducer.prepare_for_backward([])
1: RuntimeError: Expected to have finished reduction in the prior iteration before starting a new one. This error indicates that your module has parameters that were not used in producing loss. You can enable unused parameter detection by (1) passing the keyword argument `find_unused_parameters=True` to `torch.nn.parallel.DistributedDataParallel`; (2) making sure all `forward` function outputs participate in calculating loss. If you already have done the above two steps, then the distributed data parallel module wasn't able to locate the output tensors in the return value of your module's `forward` function. Please include the loss function and the structure of the return value of `forward` of your module when reporting this issue (e.g. list, dict, iterable). (prepare_for_backward at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:514)
1: frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x33 (0x7f3e70322193 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libc10.so)
1: frame #1: c10d::Reducer::prepare_for_backward(std::vector<at::Tensor, std::allocator<at::Tensor> > const&) + 0x731 (0x7f3eb28f2471 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
1: frame #2: <unknown function> + 0xa0e63a (0x7f3eb28de63a in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
1: frame #3: <unknown function> + 0x2956c4 (0x7f3eb21656c4 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
1: <omitting python frames>
1: frame #35: main + 0x119 (0x400a99 in /home/menekse/virtualenvs/torch_env/bin/python)
1: frame #36: __libc_start_main + 0xf5 (0x7f3ec32b53d5 in /lib64/libc.so.6)
1: frame #37: /home/menekse/virtualenvs/torch_env/bin/python() [0x400c20]
1: 
1: Traceback (most recent call last):
1:   File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
1:     "__main__", mod_spec)
1:   File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
1:     exec(code, run_globals)
1:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 263, in <module>
1:     main()
1:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 259, in main
1:     cmd=cmd)
1: subprocess.CalledProcessError: Command '['/home/menekse/virtualenvs/torch_env/bin/python', '-u', 'train.py', '--local_rank=2', '--exp_name', 'xlm_en_de_tlm', '--dump_path', '/data/menekse/dumped', '--data_path', '/data/shared/ConceptualCaptions/XLM_data/50k', '--lgs', 'en-de', '--clm_steps', '', '--mlm_steps', 'en-de', '--emb_dim', '512', '--n_layers', '6', '--n_heads', '8', '--dropout', '0.1', '--attention_dropout', '0.1', '--gelu_activation', 'true', '--batch_size', '32', '--bptt', '256', '--optimizer', 'adam,lr=0.0001', '--epoch_size', '300000', '--max_epoch', '100000', '--validation_metrics', 'valid_en_de_mlm_ppl', '--stopping_criterion', '_valid_mlm_ppl,25', '--fp16', 'false', '--image_names', '/data/shared/ConceptualCaptions/XLM_data/50k', '--reload_model', '/data/menekse/dumped/xlm_en_de_tlm/3094/best-valid_en_de_mlm_ppl.pth', '--save_periodic', '2']' returned non-zero exit status 1.
srun: error: hanabi: task 1: Exited with exit code 1
