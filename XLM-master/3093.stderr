/var/spool/slurm/d/job03093/slurm_script: line 15: {workdir}/3093.stdout: No such file or directory
/var/spool/slurm/d/job03093/slurm_script: line 16: {workdir}/3093.stdout: No such file or directory
/var/spool/slurm/d/job03093/slurm_script: line 17: {workdir}/3093.stdout: No such file or directory
/var/spool/slurm/d/job03093/slurm_script: line 18: {workdir}/3093.stdout: No such file or directory
/var/spool/slurm/d/job03093/slurm_script: line 19: {workdir}/3093.stdout: No such file or directory
/var/spool/slurm/d/job03093/slurm_script: line 20: {workdir}/3093.stdout: No such file or directory
3: FAISS library was not found.
3: FAISS not available. Switching to standard nearest neighbors search implementation.
3: FAISS library was not found.
3: FAISS not available. Switching to standard nearest neighbors search implementation.
1: FAISS library was not found.
1: FAISS not available. Switching to standard nearest neighbors search implementation.
1: FAISS library was not found.
1: FAISS not available. Switching to standard nearest neighbors search implementation.
2: FAISS library was not found.
2: FAISS not available. Switching to standard nearest neighbors search implementation.
2: FAISS library was not found.
2: FAISS not available. Switching to standard nearest neighbors search implementation.
0: FAISS library was not found.
0: FAISS not available. Switching to standard nearest neighbors search implementation.
0: FAISS library was not found.
0: FAISS not available. Switching to standard nearest neighbors search implementation.
1: Traceback (most recent call last):
1:   File "train.py", line 348, in <module>
1:     main(params)
1:   File "train.py", line 230, in main
1:     init_distributed_mode(params)
1:   File "/home/menekse/xlm/Animal/XLM-master/src/slurm.py", line 171, in init_distributed_mode
1:     backend='nccl',
1:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py", line 397, in init_process_group
1:     store, rank, world_size = next(rendezvous_iterator)
1:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/rendezvous.py", line 168, in _env_rendezvous_handler
1:     store = TCPStore(master_addr, master_port, world_size, start_daemon)
1: RuntimeError: Address already in use
3: INFO - 04/19/20 17:16:00 - 0:00:00 - ============ Initialized logger ============
3: INFO - 04/19/20 17:16:00 - 0:00:00 - accumulate_gradients: 1
3:                                      ae_steps: []
3:                                      amp: -1
3:                                      asm: False
3:                                      attention_dropout: 0.1
3:                                      batch_size: 32
3:                                      beam_size: 1
3:                                      bptt: 256
3:                                      bt_src_langs: []
3:                                      bt_steps: []
3:                                      clip_grad_norm: 5
3:                                      clm_steps: []
3:                                      command: python train.py --local_rank=0 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3093"
3:                                      context_size: 0
3:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      debug: False
3:                                      debug_slurm: False
3:                                      debug_train: False
3:                                      dropout: 0.1
3:                                      dump_path: /data/menekse/dumped/xlm_en_de_tlm/3093
3:                                      early_stopping: False
3:                                      emb_dim: 512
3:                                      encoder_only: True
3:                                      epoch_size: 300000
3:                                      eval_bleu: False
3:                                      eval_only: False
3:                                      exp_id: 3093
3:                                      exp_name: xlm_en_de_tlm
3:                                      fp16: False
3:                                      gelu_activation: True
3:                                      global_rank: 0
3:                                      group_by_size: True
3:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
3:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      is_master: True
3:                                      is_slurm_job: False
3:                                      lambda_ae: 1
3:                                      lambda_bt: 1
3:                                      lambda_clm: 1
3:                                      lambda_mlm: 1
3:                                      lambda_mt: 1
3:                                      lambda_pc: 1
3:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
3:                                      langs: ['en', 'de', 'img']
3:                                      length_penalty: 1
3:                                      lg_sampling_factor: -1
3:                                      lgs: en-de
3:                                      local_rank: 0
3:                                      master_port: -1
3:                                      max_batch_size: 0
3:                                      max_epoch: 100000
3:                                      max_len: 100
3:                                      max_vocab: -1
3:                                      min_count: 0
3:                                      mlm_steps: [('en', 'de')]
3:                                      mono_dataset: {}
3:                                      mt_steps: []
3:                                      multi_gpu: True
3:                                      multi_node: False
3:                                      n_gpu_per_node: 2
3:                                      n_heads: 8
3:                                      n_langs: 3
3:                                      n_layers: 6
3:                                      n_nodes: 1
3:                                      node_id: 0
3:                                      only_vlm: False
3:                                      optimizer: adam,lr=0.0001
3:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      pc_steps: []
3:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
3:                                      reload_checkpoint: 
3:                                      reload_emb: 
3:                                      reload_model: 
3:                                      sample_alpha: 0
3:                                      save_periodic: 0
3:                                      share_inout_emb: True
3:                                      sinusoidal_embeddings: False
3:                                      split_data: False
3:                                      stopping_criterion: _valid_mlm_ppl,25
3:                                      tokens_per_batch: -1
3:                                      use_lang_emb: True
3:                                      use_memory: False
3:                                      validation_metrics: valid_en_de_mlm_ppl
3:                                      vlm_steps: [('en', 'de')]
3:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      word_blank: 0
3:                                      word_dropout: 0
3:                                      word_keep: 0.1
3:                                      word_mask: 0.8
3:                                      word_mask_keep_rand: 0.8,0.1,0.1
3:                                      word_pred: 0.15
3:                                      word_rand: 0.1
3:                                      word_shuffle: 0
3:                                      world_size: 2
3: INFO - 04/19/20 17:16:00 - 0:00:00 - The experiment will be stored in /data/menekse/dumped/xlm_en_de_tlm/3093
3:                                      
3: INFO - 04/19/20 17:16:00 - 0:00:00 - Running command: python train.py --local_rank=0 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
3: 
3: WARNING - 04/19/20 17:16:00 - 0:00:00 - Signal handler installed.
3: 
3: INFO - 04/19/20 17:16:00 - 0:00:00 - ============ Parallel data (de-en)
3: INFO - 04/19/20 17:16:00 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
0: INFO - 04/19/20 17:16:00 - 0:00:00 - ============ Initialized logger ============
0: INFO - 04/19/20 17:16:00 - 0:00:00 - accumulate_gradients: 1
0:                                      ae_steps: []
0:                                      amp: -1
0:                                      asm: False
0:                                      attention_dropout: 0.1
0:                                      batch_size: 32
0:                                      beam_size: 1
0:                                      bptt: 256
0:                                      bt_src_langs: []
0:                                      bt_steps: []
0:                                      clip_grad_norm: 5
0:                                      clm_steps: []
0:                                      command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3093"
0:                                      context_size: 0
0:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
0:                                      debug: False
0:                                      debug_slurm: False
0:                                      debug_train: False
0:                                      dropout: 0.1
0:                                      dump_path: /data/menekse/dumped/xlm_en_de_tlm/3093
0:                                      early_stopping: False
0:                                      emb_dim: 512
0:                                      encoder_only: True
0:                                      epoch_size: 300000
0:                                      eval_bleu: False
0:                                      eval_only: False
0:                                      exp_id: 3093
0:                                      exp_name: xlm_en_de_tlm
0:                                      fp16: False
0:                                      gelu_activation: True
0:                                      global_rank: 1
0:                                      group_by_size: True
0:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
0:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
0:                                      is_master: False
0:                                      is_slurm_job: False
0:                                      lambda_ae: 1
0:                                      lambda_bt: 1
0:                                      lambda_clm: 1
0:                                      lambda_mlm: 1
0:                                      lambda_mt: 1
0:                                      lambda_pc: 1
0:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
0:                                      langs: ['en', 'de', 'img']
0:                                      length_penalty: 1
0:                                      lg_sampling_factor: -1
0:                                      lgs: en-de
0:                                      local_rank: 1
0:                                      master_port: -1
0:                                      max_batch_size: 0
0:                                      max_epoch: 100000
0:                                      max_len: 100
0:                                      max_vocab: -1
0:                                      min_count: 0
0:                                      mlm_steps: [('en', 'de')]
0:                                      mono_dataset: {}
0:                                      mt_steps: []
0:                                      multi_gpu: True
0:                                      multi_node: False
0:                                      n_gpu_per_node: 2
0:                                      n_heads: 8
0:                                      n_langs: 3
0:                                      n_layers: 6
0:                                      n_nodes: 1
0:                                      node_id: 0
0:                                      only_vlm: False
0:                                      optimizer: adam,lr=0.0001
0:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
0:                                      pc_steps: []
0:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
0:                                      reload_checkpoint: 
0:                                      reload_emb: 
0:                                      reload_model: 
0:                                      sample_alpha: 0
0:                                      save_periodic: 0
0:                                      share_inout_emb: True
0:                                      sinusoidal_embeddings: False
0:                                      split_data: False
0:                                      stopping_criterion: _valid_mlm_ppl,25
0:                                      tokens_per_batch: -1
0:                                      use_lang_emb: True
0:                                      use_memory: False
0:                                      validation_metrics: valid_en_de_mlm_ppl
0:                                      vlm_steps: [('en', 'de')]
0:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
0:                                      word_blank: 0
0:                                      word_dropout: 0
0:                                      word_keep: 0.1
0:                                      word_mask: 0.8
0:                                      word_mask_keep_rand: 0.8,0.1,0.1
0:                                      word_pred: 0.15
0:                                      word_rand: 0.1
0:                                      word_shuffle: 0
0:                                      world_size: 2
0: INFO - 04/19/20 17:16:00 - 0:00:00 - The experiment will be stored in /data/menekse/dumped/xlm_en_de_tlm/3093
0:                                      
0: INFO - 04/19/20 17:16:00 - 0:00:00 - Running command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
0: 
0: WARNING - 04/19/20 17:16:00 - 0:00:00 - Signal handler installed.
0: 
0: INFO - 04/19/20 17:16:00 - 0:00:00 - ============ Parallel data (de-en)
0: INFO - 04/19/20 17:16:00 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: INFO - 04/19/20 17:16:01 - 0:00:00 - ============ Initialized logger ============
3: INFO - 04/19/20 17:16:01 - 0:00:00 - accumulate_gradients: 1
3:                                      ae_steps: []
3:                                      amp: -1
3:                                      asm: False
3:                                      attention_dropout: 0.1
3:                                      batch_size: 32
3:                                      beam_size: 1
3:                                      bptt: 256
3:                                      bt_src_langs: []
3:                                      bt_steps: []
3:                                      clip_grad_norm: 5
3:                                      clm_steps: []
3:                                      command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3093"
3:                                      context_size: 0
3:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      debug: False
3:                                      debug_slurm: False
3:                                      debug_train: False
3:                                      dropout: 0.1
3:                                      dump_path: /data/menekse/dumped/xlm_en_de_tlm/3093
3:                                      early_stopping: False
3:                                      emb_dim: 512
3:                                      encoder_only: True
3:                                      epoch_size: 300000
3:                                      eval_bleu: False
3:                                      eval_only: False
3:                                      exp_id: 3093
3:                                      exp_name: xlm_en_de_tlm
3:                                      fp16: False
3:                                      gelu_activation: True
3:                                      global_rank: 1
3:                                      group_by_size: True
3:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
3:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      is_master: False
3:                                      is_slurm_job: False
3:                                      lambda_ae: 1
3:                                      lambda_bt: 1
3:                                      lambda_clm: 1
3:                                      lambda_mlm: 1
3:                                      lambda_mt: 1
3:                                      lambda_pc: 1
3:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
3:                                      langs: ['en', 'de', 'img']
3:                                      length_penalty: 1
3:                                      lg_sampling_factor: -1
3:                                      lgs: en-de
3:                                      local_rank: 1
3:                                      master_port: -1
3:                                      max_batch_size: 0
3:                                      max_epoch: 100000
3:                                      max_len: 100
3:                                      max_vocab: -1
3:                                      min_count: 0
3:                                      mlm_steps: [('en', 'de')]
3:                                      mono_dataset: {}
3:                                      mt_steps: []
3:                                      multi_gpu: True
3:                                      multi_node: False
3:                                      n_gpu_per_node: 2
3:                                      n_heads: 8
3:                                      n_langs: 3
3:                                      n_layers: 6
3:                                      n_nodes: 1
3:                                      node_id: 0
3:                                      only_vlm: False
3:                                      optimizer: adam,lr=0.0001
3:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      pc_steps: []
3:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
3:                                      reload_checkpoint: 
3:                                      reload_emb: 
3:                                      reload_model: 
3:                                      sample_alpha: 0
3:                                      save_periodic: 0
3:                                      share_inout_emb: True
3:                                      sinusoidal_embeddings: False
3:                                      split_data: False
3:                                      stopping_criterion: _valid_mlm_ppl,25
3:                                      tokens_per_batch: -1
3:                                      use_lang_emb: True
3:                                      use_memory: False
3:                                      validation_metrics: valid_en_de_mlm_ppl
3:                                      vlm_steps: [('en', 'de')]
3:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      word_blank: 0
3:                                      word_dropout: 0
3:                                      word_keep: 0.1
3:                                      word_mask: 0.8
3:                                      word_mask_keep_rand: 0.8,0.1,0.1
3:                                      word_pred: 0.15
3:                                      word_rand: 0.1
3:                                      word_shuffle: 0
3:                                      world_size: 2
3: INFO - 04/19/20 17:16:01 - 0:00:00 - The experiment will be stored in /data/menekse/dumped/xlm_en_de_tlm/3093
3:                                      
3: INFO - 04/19/20 17:16:01 - 0:00:00 - Running command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
3: 
3: WARNING - 04/19/20 17:16:01 - 0:00:00 - Signal handler installed.
3: 
3: INFO - 04/19/20 17:16:01 - 0:00:00 - ============ Parallel data (de-en)
3: INFO - 04/19/20 17:16:01 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
1: INFO - 04/19/20 17:16:01 - 0:00:00 - ============ Initialized logger ============
2: Traceback (most recent call last):
2:   File "train.py", line 348, in <module>
1: INFO - 04/19/20 17:16:01 - 0:00:00 - accumulate_gradients: 1
1:                                      ae_steps: []
1:                                      amp: -1
1:                                      asm: False
1:                                      attention_dropout: 0.1
1:                                      batch_size: 32
1:                                      beam_size: 1
1:                                      bptt: 256
1:                                      bt_src_langs: []
1:                                      bt_steps: []
1:                                      clip_grad_norm: 5
1:                                      clm_steps: []
1:                                      command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3093"
1:                                      context_size: 0
1:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
1:                                      debug: False
1:                                      debug_slurm: False
1:                                      debug_train: False
1:                                      dropout: 0.1
1:                                      dump_path: /data/menekse/dumped/xlm_en_de_tlm/3093
1:                                      early_stopping: False
1:                                      emb_dim: 512
1:                                      encoder_only: True
1:                                      epoch_size: 300000
1:                                      eval_bleu: False
1:                                      eval_only: False
1:                                      exp_id: 3093
1:                                      exp_name: xlm_en_de_tlm
1:                                      fp16: False
1:                                      gelu_activation: True
1:                                      global_rank: 1
1:                                      group_by_size: True
1:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
1:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
1:                                      is_master: False
1:                                      is_slurm_job: False
1:                                      lambda_ae: 1
1:                                      lambda_bt: 1
1:                                      lambda_clm: 1
1:                                      lambda_mlm: 1
1:                                      lambda_mt: 1
1:                                      lambda_pc: 1
1:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
1:                                      langs: ['en', 'de', 'img']
1:                                      length_penalty: 1
1:                                      lg_sampling_factor: -1
1:                                      lgs: en-de
1:                                      local_rank: 1
1:                                      master_port: -1
1:                                      max_batch_size: 0
1:                                      max_epoch: 100000
1:                                      max_len: 100
1:                                      max_vocab: -1
1:                                      min_count: 0
1:                                      mlm_steps: [('en', 'de')]
1:                                      mono_dataset: {}
1:                                      mt_steps: []
1:                                      multi_gpu: True
1:                                      multi_node: False
1:                                      n_gpu_per_node: 2
1:                                      n_heads: 8
1:                                      n_langs: 3
1:                                      n_layers: 6
1:                                      n_nodes: 1
1:                                      node_id: 0
1:                                      only_vlm: False
1:                                      optimizer: adam,lr=0.0001
1:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
1:                                      pc_steps: []
1:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
1:                                      reload_checkpoint: 
1:                                      reload_emb: 
1:                                      reload_model: 
1:                                      sample_alpha: 0
1:                                      save_periodic: 0
1:                                      share_inout_emb: True
1:                                      sinusoidal_embeddings: False
1:                                      split_data: False
1:                                      stopping_criterion: _valid_mlm_ppl,25
1:                                      tokens_per_batch: -1
1:                                      use_lang_emb: True
1:                                      use_memory: False
1:                                      validation_metrics: valid_en_de_mlm_ppl
1:                                      vlm_steps: [('en', 'de')]
1:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
1:                                      word_blank: 0
1:                                      word_dropout: 0
1:                                      word_keep: 0.1
1:                                      word_mask: 0.8
1:                                      word_mask_keep_rand: 0.8,0.1,0.1
1:                                      word_pred: 0.15
1:                                      word_rand: 0.1
1:                                      word_shuffle: 0
1:                                      world_size: 2
1: INFO - 04/19/20 17:16:01 - 0:00:00 - The experiment will be stored in /data/menekse/dumped/xlm_en_de_tlm/3093
1:                                      
1: INFO - 04/19/20 17:16:01 - 0:00:00 - Running command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
1: 
1: WARNING - 04/19/20 17:16:01 - 0:00:00 - Signal handler installed.
1: 
1: INFO - 04/19/20 17:16:01 - 0:00:00 - ============ Parallel data (de-en)
1: INFO - 04/19/20 17:16:01 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
0: Traceback (most recent call last):
0:   File "train.py", line 348, in <module>
2:     main(params)
2:   File "train.py", line 230, in main
0:     main(params)
0:   File "train.py", line 230, in main
0:     init_distributed_mode(params)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/slurm.py", line 171, in init_distributed_mode
2:     init_distributed_mode(params)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/slurm.py", line 171, in init_distributed_mode
0:     backend='nccl',
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py", line 397, in init_process_group
2:     backend='nccl',
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py", line 397, in init_process_group
2: INFO - 04/19/20 17:16:01 - 0:00:00 - ============ Initialized logger ============
2: INFO - 04/19/20 17:16:01 - 0:00:00 - accumulate_gradients: 1
2:                                      ae_steps: []
2:                                      amp: -1
2:                                      asm: False
2:                                      attention_dropout: 0.1
2:                                      batch_size: 32
2:                                      beam_size: 1
2:                                      bptt: 256
2:                                      bt_src_langs: []
2:                                      bt_steps: []
2:                                      clip_grad_norm: 5
2:                                      clm_steps: []
2:                                      command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3093"
2:                                      context_size: 0
2:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
2:                                      debug: False
2:                                      debug_slurm: False
2:                                      debug_train: False
2:                                      dropout: 0.1
2:                                      dump_path: /data/menekse/dumped/xlm_en_de_tlm/3093
2:                                      early_stopping: False
2:                                      emb_dim: 512
2:                                      encoder_only: True
2:                                      epoch_size: 300000
2:                                      eval_bleu: False
2:                                      eval_only: False
2:                                      exp_id: 3093
2:                                      exp_name: xlm_en_de_tlm
2:                                      fp16: False
2:                                      gelu_activation: True
2:                                      global_rank: 1
2:                                      group_by_size: True
2:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
2:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
2:                                      is_master: False
2:                                      is_slurm_job: False
2:                                      lambda_ae: 1
2:                                      lambda_bt: 1
2:                                      lambda_clm: 1
2:                                      lambda_mlm: 1
2:                                      lambda_mt: 1
2:                                      lambda_pc: 1
2:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
2:                                      langs: ['en', 'de', 'img']
2:                                      length_penalty: 1
2:                                      lg_sampling_factor: -1
2:                                      lgs: en-de
2:                                      local_rank: 1
2:                                      master_port: -1
2:                                      max_batch_size: 0
2:                                      max_epoch: 100000
2:                                      max_len: 100
2:                                      max_vocab: -1
2:                                      min_count: 0
2:                                      mlm_steps: [('en', 'de')]
2:                                      mono_dataset: {}
2:                                      mt_steps: []
2:                                      multi_gpu: True
2:                                      multi_node: False
2:                                      n_gpu_per_node: 2
2:                                      n_heads: 8
2:                                      n_langs: 3
2:                                      n_layers: 6
2:                                      n_nodes: 1
2:                                      node_id: 0
2:                                      only_vlm: False
2:                                      optimizer: adam,lr=0.0001
2:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
2:                                      pc_steps: []
2:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
2:                                      reload_checkpoint: 
2:                                      reload_emb: 
2:                                      reload_model: 
2:                                      sample_alpha: 0
2:                                      save_periodic: 0
2:                                      share_inout_emb: True
2:                                      sinusoidal_embeddings: False
2:                                      split_data: False
2:                                      stopping_criterion: _valid_mlm_ppl,25
2:                                      tokens_per_batch: -1
2:                                      use_lang_emb: True
2:                                      use_memory: False
2:                                      validation_metrics: valid_en_de_mlm_ppl
2:                                      vlm_steps: [('en', 'de')]
2:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
2:                                      word_blank: 0
2:                                      word_dropout: 0
2:                                      word_keep: 0.1
2:                                      word_mask: 0.8
2:                                      word_mask_keep_rand: 0.8,0.1,0.1
2:                                      word_pred: 0.15
2:                                      word_rand: 0.1
2:                                      word_shuffle: 0
2:                                      world_size: 2
2: INFO - 04/19/20 17:16:01 - 0:00:00 - The experiment will be stored in /data/menekse/dumped/xlm_en_de_tlm/3093
2:                                      
2: INFO - 04/19/20 17:16:01 - 0:00:00 - Running command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path '/data/menekse/dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
2: 
2: WARNING - 04/19/20 17:16:01 - 0:00:00 - Signal handler installed.
2: 
2: INFO - 04/19/20 17:16:01 - 0:00:00 - ============ Parallel data (de-en)
2: INFO - 04/19/20 17:16:01 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
0:     store, rank, world_size = next(rendezvous_iterator)
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/rendezvous.py", line 168, in _env_rendezvous_handler
2:     store, rank, world_size = next(rendezvous_iterator)
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/rendezvous.py", line 168, in _env_rendezvous_handler
0:     store = TCPStore(master_addr, master_port, world_size, start_daemon)
0: RuntimeError: Address already in use
2:     store = TCPStore(master_addr, master_port, world_size, start_daemon)
2: RuntimeError: Address already in use
1: Traceback (most recent call last):
1:   File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
1:     "__main__", mod_spec)
1:   File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
1:     exec(code, run_globals)
1:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 263, in <module>
1:     main()
1:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 259, in main
1:     cmd=cmd)
1: subprocess.CalledProcessError: Command '['/home/menekse/virtualenvs/torch_env/bin/python', '-u', 'train.py', '--local_rank=1', '--exp_name', 'xlm_en_de_tlm', '--dump_path', '/data/menekse/dumped', '--data_path', '/data/shared/ConceptualCaptions/XLM_data/50k', '--lgs', 'en-de', '--clm_steps', '', '--mlm_steps', 'en-de', '--emb_dim', '512', '--n_layers', '6', '--n_heads', '8', '--dropout', '0.1', '--attention_dropout', '0.1', '--gelu_activation', 'true', '--batch_size', '32', '--bptt', '256', '--optimizer', 'adam,lr=0.0001', '--epoch_size', '300000', '--max_epoch', '100000', '--validation_metrics', 'valid_en_de_mlm_ppl', '--stopping_criterion', '_valid_mlm_ppl,25', '--fp16', 'false', '--image_names', '/data/shared/ConceptualCaptions/XLM_data/50k']' returned non-zero exit status 1.
0: INFO - 04/19/20 17:16:04 - 0:00:04 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
0: INFO - 04/19/20 17:16:04 - 0:00:04 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
srun: error: hanabi: task 1: Exited with exit code 1
3: INFO - 04/19/20 17:16:06 - 0:00:05 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/19/20 17:16:06 - 0:00:05 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
3: INFO - 04/19/20 17:16:07 - 0:00:06 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
1: INFO - 04/19/20 17:16:07 - 0:00:06 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/19/20 17:16:07 - 0:00:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
1: INFO - 04/19/20 17:16:07 - 0:00:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
2: INFO - 04/19/20 17:16:07 - 0:00:06 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
2: INFO - 04/19/20 17:16:07 - 0:00:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
0: Traceback (most recent call last):
0:   File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
0:     "__main__", mod_spec)
0:   File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
0:     exec(code, run_globals)
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 263, in <module>
0:     main()
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 259, in main
0:     cmd=cmd)
0: subprocess.CalledProcessError: Command '['/home/menekse/virtualenvs/torch_env/bin/python', '-u', 'train.py', '--local_rank=1', '--exp_name', 'xlm_en_de_tlm', '--dump_path', '/data/menekse/dumped', '--data_path', '/data/shared/ConceptualCaptions/XLM_data/50k', '--lgs', 'en-de', '--clm_steps', '', '--mlm_steps', 'en-de', '--emb_dim', '512', '--n_layers', '6', '--n_heads', '8', '--dropout', '0.1', '--attention_dropout', '0.1', '--gelu_activation', 'true', '--batch_size', '32', '--bptt', '256', '--optimizer', 'adam,lr=0.0001', '--epoch_size', '300000', '--max_epoch', '100000', '--validation_metrics', 'valid_en_de_mlm_ppl', '--stopping_criterion', '_valid_mlm_ppl,25', '--fp16', 'false', '--image_names', '/data/shared/ConceptualCaptions/XLM_data/50k']' returned non-zero exit status 1.
2: Traceback (most recent call last):
2:   File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
2:     "__main__", mod_spec)
2:   File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
2:     exec(code, run_globals)
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 263, in <module>
2:     main()
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 259, in main
2:     cmd=cmd)
2: subprocess.CalledProcessError: Command '['/home/menekse/virtualenvs/torch_env/bin/python', '-u', 'train.py', '--local_rank=1', '--exp_name', 'xlm_en_de_tlm', '--dump_path', '/data/menekse/dumped', '--data_path', '/data/shared/ConceptualCaptions/XLM_data/50k', '--lgs', 'en-de', '--clm_steps', '', '--mlm_steps', 'en-de', '--emb_dim', '512', '--n_layers', '6', '--n_heads', '8', '--dropout', '0.1', '--attention_dropout', '0.1', '--gelu_activation', 'true', '--batch_size', '32', '--bptt', '256', '--optimizer', 'adam,lr=0.0001', '--epoch_size', '300000', '--max_epoch', '100000', '--validation_metrics', 'valid_en_de_mlm_ppl', '--stopping_criterion', '_valid_mlm_ppl,25', '--fp16', 'false', '--image_names', '/data/shared/ConceptualCaptions/XLM_data/50k']' returned non-zero exit status 1.
0: INFO - 04/19/20 17:16:08 - 0:00:08 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
srun: error: hanabi: task 2: Exited with exit code 1
3: INFO - 04/19/20 17:16:11 - 0:00:11 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
1: INFO - 04/19/20 17:16:11 - 0:00:10 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
2: INFO - 04/19/20 17:16:12 - 0:00:10 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
srun: error: hanabi: task 0: Exited with exit code 1
3: INFO - 04/19/20 17:16:12 - 0:00:11 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
0: INFO - 04/19/20 17:16:15 - 0:00:15 - Removed 0 empty sentences.
3: INFO - 04/19/20 17:16:21 - 0:00:21 - Removed 0 empty sentences.
2: INFO - 04/19/20 17:16:21 - 0:00:20 - Removed 0 empty sentences.
1: INFO - 04/19/20 17:16:21 - 0:00:20 - Removed 0 empty sentences.
3: INFO - 04/19/20 17:16:22 - 0:00:21 - Removed 0 empty sentences.
0: INFO - 04/19/20 17:16:26 - 0:00:26 - Removed 0 empty sentences.
0: INFO - 04/19/20 17:16:34 - 0:00:34 - Removed 2 too long sentences.
0: 
0: INFO - 04/19/20 17:16:38 - 0:00:37 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
0: INFO - 04/19/20 17:16:38 - 0:00:38 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/19/20 17:16:38 - 0:00:38 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
0: INFO - 04/19/20 17:16:39 - 0:00:38 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
2: INFO - 04/19/20 17:16:39 - 0:00:38 - Removed 0 empty sentences.
1: INFO - 04/19/20 17:16:40 - 0:00:39 - Removed 0 empty sentences.
3: INFO - 04/19/20 17:16:40 - 0:00:40 - Removed 0 empty sentences.
3: INFO - 04/19/20 17:16:41 - 0:00:40 - Removed 0 empty sentences.
0: INFO - 04/19/20 17:16:42 - 0:00:41 - Removed 0 empty sentences.
0: 
0: INFO - 04/19/20 17:16:42 - 0:00:41 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
0: INFO - 04/19/20 17:16:42 - 0:00:41 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/19/20 17:16:42 - 0:00:42 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
0: INFO - 04/19/20 17:16:42 - 0:00:42 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
0: INFO - 04/19/20 17:16:45 - 0:00:45 - Removed 0 empty sentences.
0: 
0: 
0: INFO - 04/19/20 17:16:45 - 0:00:45 - ============ Parallel data with image regions (de-en)
0: INFO - 04/19/20 17:16:45 - 0:00:45 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
0: INFO - 04/19/20 17:16:49 - 0:00:48 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
0: INFO - 04/19/20 17:16:49 - 0:00:48 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
0: INFO - 04/19/20 17:16:52 - 0:00:52 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
2: INFO - 04/19/20 17:16:53 - 0:00:52 - Removed 2 too long sentences.
1: INFO - 04/19/20 17:16:55 - 0:00:54 - Removed 2 too long sentences.
3: INFO - 04/19/20 17:16:56 - 0:00:55 - Removed 2 too long sentences.
3: INFO - 04/19/20 17:16:56 - 0:00:56 - Removed 2 too long sentences.
2: 
2: INFO - 04/19/20 17:16:59 - 0:00:58 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
2: INFO - 04/19/20 17:17:00 - 0:00:59 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/19/20 17:17:00 - 0:00:59 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
2: INFO - 04/19/20 17:17:01 - 0:00:59 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: 
1: INFO - 04/19/20 17:17:02 - 0:01:01 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
3: 
3: INFO - 04/19/20 17:17:03 - 0:01:02 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
1: INFO - 04/19/20 17:17:03 - 0:01:02 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/19/20 17:17:03 - 0:01:02 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
3: 
3: INFO - 04/19/20 17:17:03 - 0:01:02 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/19/20 17:17:03 - 0:01:03 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
3: INFO - 04/19/20 17:17:03 - 0:01:03 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: INFO - 04/19/20 17:17:03 - 0:01:02 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
3: INFO - 04/19/20 17:17:04 - 0:01:03 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/19/20 17:17:04 - 0:01:03 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
3: INFO - 04/19/20 17:17:04 - 0:01:04 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
3: INFO - 04/19/20 17:17:04 - 0:01:04 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
2: INFO - 04/19/20 17:17:05 - 0:01:04 - Removed 0 empty sentences.
2: 
2: INFO - 04/19/20 17:17:05 - 0:01:04 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
2: INFO - 04/19/20 17:17:06 - 0:01:04 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/19/20 17:17:06 - 0:01:05 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
2: INFO - 04/19/20 17:17:06 - 0:01:05 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
3: INFO - 04/19/20 17:17:07 - 0:01:07 - Removed 0 empty sentences.
3: 
3: INFO - 04/19/20 17:17:07 - 0:01:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/19/20 17:17:07 - 0:01:07 - Removed 0 empty sentences.
1: 
1: INFO - 04/19/20 17:17:08 - 0:01:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/19/20 17:17:08 - 0:01:07 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/19/20 17:17:08 - 0:01:07 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/19/20 17:17:08 - 0:01:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/19/20 17:17:08 - 0:01:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
3: INFO - 04/19/20 17:17:08 - 0:01:08 - Removed 0 empty sentences.
3: 
3: INFO - 04/19/20 17:17:08 - 0:01:08 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/19/20 17:17:08 - 0:01:07 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
3: INFO - 04/19/20 17:17:08 - 0:01:08 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
3: INFO - 04/19/20 17:17:09 - 0:01:08 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/19/20 17:17:09 - 0:01:08 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
3: INFO - 04/19/20 17:17:09 - 0:01:09 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
2: INFO - 04/19/20 17:17:09 - 0:01:08 - Removed 0 empty sentences.
2: 
2: 
2: INFO - 04/19/20 17:17:10 - 0:01:09 - ============ Parallel data with image regions (de-en)
2: INFO - 04/19/20 17:17:10 - 0:01:09 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
1: INFO - 04/19/20 17:17:12 - 0:01:11 - Removed 0 empty sentences.
1: 
1: 
3: INFO - 04/19/20 17:17:12 - 0:01:11 - Removed 0 empty sentences.
3: 
3: 
1: INFO - 04/19/20 17:17:12 - 0:01:11 - ============ Parallel data with image regions (de-en)
1: INFO - 04/19/20 17:17:12 - 0:01:11 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: INFO - 04/19/20 17:17:12 - 0:01:11 - ============ Parallel data with image regions (de-en)
3: INFO - 04/19/20 17:17:12 - 0:01:11 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: INFO - 04/19/20 17:17:13 - 0:01:13 - Removed 0 empty sentences.
3: 
3: 
3: INFO - 04/19/20 17:17:13 - 0:01:13 - ============ Parallel data with image regions (de-en)
3: INFO - 04/19/20 17:17:13 - 0:01:13 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
2: INFO - 04/19/20 17:17:14 - 0:01:13 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
2: INFO - 04/19/20 17:17:14 - 0:01:13 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
1: INFO - 04/19/20 17:17:17 - 0:01:16 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
1: INFO - 04/19/20 17:17:17 - 0:01:16 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
3: INFO - 04/19/20 17:17:17 - 0:01:16 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/19/20 17:17:17 - 0:01:16 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
3: INFO - 04/19/20 17:17:18 - 0:01:18 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/19/20 17:17:18 - 0:01:18 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
2: INFO - 04/19/20 17:17:19 - 0:01:18 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/19/20 17:17:21 - 0:01:20 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
1: INFO - 04/19/20 17:17:21 - 0:01:20 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/19/20 17:17:22 - 0:01:22 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
0: INFO - 04/19/20 17:17:54 - 0:01:54 - Removed 0 empty sentences.
0: INFO - 04/19/20 17:18:17 - 0:02:17 - Removed 0 empty sentences.
0: INFO - 04/19/20 17:18:37 - 0:02:37 - Removed 2 too long sentences.
0: 
0: INFO - 04/19/20 17:18:42 - 0:02:41 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
0: INFO - 04/19/20 17:18:42 - 0:02:42 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/19/20 17:18:42 - 0:02:42 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
0: INFO - 04/19/20 17:18:42 - 0:02:42 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/19/20 17:18:44 - 0:02:43 - Removed 0 empty sentences.
2: INFO - 04/19/20 17:18:44 - 0:02:43 - Removed 0 empty sentences.
3: INFO - 04/19/20 17:18:47 - 0:02:46 - Removed 0 empty sentences.
3: INFO - 04/19/20 17:18:48 - 0:02:48 - Removed 0 empty sentences.
0: INFO - 04/19/20 17:18:49 - 0:02:48 - Removed 0 empty sentences.
0: 
0: INFO - 04/19/20 17:18:49 - 0:02:48 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
0: INFO - 04/19/20 17:18:49 - 0:02:49 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/19/20 17:18:49 - 0:02:49 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
0: INFO - 04/19/20 17:18:49 - 0:02:49 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
0: INFO - 04/19/20 17:18:52 - 0:02:51 - Removed 0 empty sentences.
0: 
0: 
0: INFO - 04/19/20 17:18:52 - 0:02:51 - ============ Data summary
0: INFO - 04/19/20 17:18:52 - 0:02:51 - Parallel data      - train -        de-en:   3308331
0: INFO - 04/19/20 17:18:52 - 0:02:51 - Parallel data      - valid -        de-en:      5000
0: INFO - 04/19/20 17:18:52 - 0:02:51 - Parallel data      -  test -        de-en:      5000
0: 
0: INFO - 04/19/20 17:19:01 - 0:03:00 - Model: TransformerModel(
0:                                        (projector): Projector(
0:                                          (linear): Linear(in_features=1536, out_features=512, bias=True)
0:                                        )
0:                                        (regional_encodings): RegionalEncodings(
0:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
0:                                        )
0:                                        (position_embeddings): Embedding(512, 512)
0:                                        (lang_embeddings): Embedding(3, 512)
0:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
0:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        (attentions): ModuleList(
0:                                          (0): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (1): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (2): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (3): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (4): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (5): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                        )
0:                                        (layer_norm1): ModuleList(
0:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        )
0:                                        (ffns): ModuleList(
0:                                          (0): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (1): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (2): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (3): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (4): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (5): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                        )
0:                                        (layer_norm2): ModuleList(
0:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        )
0:                                        (memories): ModuleDict()
0:                                        (pred_layer): PredLayer(
0:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
0:                                        )
0:                                        (img_pred_layer): ImgPredLayer(
0:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
0:                                        )
0:                                      )
0: INFO - 04/19/20 17:19:01 - 0:03:00 - Number of parameters (model): 42634904
1: INFO - 04/19/20 17:19:05 - 0:03:04 - Removed 0 empty sentences.
2: INFO - 04/19/20 17:19:07 - 0:03:06 - Removed 0 empty sentences.
3: INFO - 04/19/20 17:19:10 - 0:03:09 - Removed 0 empty sentences.
3: INFO - 04/19/20 17:19:11 - 0:03:11 - Removed 0 empty sentences.
1: INFO - 04/19/20 17:19:25 - 0:03:24 - Removed 2 too long sentences.
2: INFO - 04/19/20 17:19:28 - 0:03:27 - Removed 2 too long sentences.
3: INFO - 04/19/20 17:19:30 - 0:03:29 - Removed 2 too long sentences.
1: 
1: INFO - 04/19/20 17:19:32 - 0:03:31 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
3: INFO - 04/19/20 17:19:32 - 0:03:32 - Removed 2 too long sentences.
1: INFO - 04/19/20 17:19:33 - 0:03:32 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/19/20 17:19:33 - 0:03:32 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: INFO - 04/19/20 17:19:33 - 0:03:32 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
2: 
2: INFO - 04/19/20 17:19:34 - 0:03:33 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
2: INFO - 04/19/20 17:19:35 - 0:03:34 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/19/20 17:19:35 - 0:03:34 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
2: INFO - 04/19/20 17:19:36 - 0:03:34 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
3: 
3: INFO - 04/19/20 17:19:36 - 0:03:35 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
3: INFO - 04/19/20 17:19:37 - 0:03:36 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/19/20 17:19:37 - 0:03:36 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
3: INFO - 04/19/20 17:19:37 - 0:03:36 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
3: 
3: INFO - 04/19/20 17:19:38 - 0:03:38 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
3: INFO - 04/19/20 17:19:39 - 0:03:38 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/19/20 17:19:39 - 0:03:39 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
3: INFO - 04/19/20 17:19:39 - 0:03:39 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/19/20 17:19:46 - 0:03:45 - Removed 0 empty sentences.
1: 
1: INFO - 04/19/20 17:19:46 - 0:03:45 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/19/20 17:19:47 - 0:03:46 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/19/20 17:19:47 - 0:03:46 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/19/20 17:19:47 - 0:03:47 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
2: INFO - 04/19/20 17:19:49 - 0:03:48 - Removed 0 empty sentences.
2: 
2: INFO - 04/19/20 17:19:49 - 0:03:48 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
2: INFO - 04/19/20 17:19:49 - 0:03:48 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/19/20 17:19:49 - 0:03:48 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
2: INFO - 04/19/20 17:19:50 - 0:03:49 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
3: INFO - 04/19/20 17:19:50 - 0:03:49 - Removed 0 empty sentences.
3: 
3: INFO - 04/19/20 17:19:50 - 0:03:49 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/19/20 17:19:51 - 0:03:50 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/19/20 17:19:51 - 0:03:50 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
3: INFO - 04/19/20 17:19:51 - 0:03:51 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: INFO - 04/19/20 17:19:52 - 0:03:51 - Removed 0 empty sentences.
1: 
1: 
1: INFO - 04/19/20 17:19:52 - 0:03:51 - ============ Data summary
1: INFO - 04/19/20 17:19:52 - 0:03:51 - Parallel data      - train -        de-en:   3308331
1: INFO - 04/19/20 17:19:52 - 0:03:51 - Parallel data      - valid -        de-en:      5000
1: INFO - 04/19/20 17:19:52 - 0:03:51 - Parallel data      -  test -        de-en:      5000
1: 
3: INFO - 04/19/20 17:19:52 - 0:03:51 - Removed 0 empty sentences.
3: 
3: INFO - 04/19/20 17:19:52 - 0:03:51 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/19/20 17:19:52 - 0:03:52 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/19/20 17:19:52 - 0:03:52 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
3: INFO - 04/19/20 17:19:53 - 0:03:52 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
2: INFO - 04/19/20 17:19:54 - 0:03:53 - Removed 0 empty sentences.
2: 
2: 
2: INFO - 04/19/20 17:19:54 - 0:03:53 - ============ Data summary
2: INFO - 04/19/20 17:19:54 - 0:03:53 - Parallel data      - train -        de-en:   3308331
2: INFO - 04/19/20 17:19:54 - 0:03:53 - Parallel data      - valid -        de-en:      5000
2: INFO - 04/19/20 17:19:54 - 0:03:53 - Parallel data      -  test -        de-en:      5000
2: 
3: INFO - 04/19/20 17:19:55 - 0:03:54 - Removed 0 empty sentences.
3: 
3: 
3: INFO - 04/19/20 17:19:55 - 0:03:55 - ============ Data summary
3: INFO - 04/19/20 17:19:55 - 0:03:55 - Parallel data      - train -        de-en:   3308331
3: INFO - 04/19/20 17:19:55 - 0:03:55 - Parallel data      - valid -        de-en:      5000
3: INFO - 04/19/20 17:19:55 - 0:03:55 - Parallel data      -  test -        de-en:      5000
3: 
3: INFO - 04/19/20 17:19:57 - 0:03:56 - Removed 0 empty sentences.
3: 
3: 
3: INFO - 04/19/20 17:19:57 - 0:03:56 - ============ Data summary
3: INFO - 04/19/20 17:19:57 - 0:03:56 - Parallel data      - train -        de-en:   3308331
3: INFO - 04/19/20 17:19:57 - 0:03:56 - Parallel data      - valid -        de-en:      5000
3: INFO - 04/19/20 17:19:57 - 0:03:56 - Parallel data      -  test -        de-en:      5000
3: 
1: INFO - 04/19/20 17:20:05 - 0:04:04 - Model: TransformerModel(
1:                                        (projector): Projector(
1:                                          (linear): Linear(in_features=1536, out_features=512, bias=True)
1:                                        )
1:                                        (regional_encodings): RegionalEncodings(
1:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
1:                                        )
1:                                        (position_embeddings): Embedding(512, 512)
1:                                        (lang_embeddings): Embedding(3, 512)
1:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
1:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        (attentions): ModuleList(
1:                                          (0): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (1): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (2): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (3): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (4): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (5): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                        )
1:                                        (layer_norm1): ModuleList(
1:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        )
1:                                        (ffns): ModuleList(
1:                                          (0): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (1): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (2): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (3): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (4): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (5): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                        )
1:                                        (layer_norm2): ModuleList(
1:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        )
1:                                        (memories): ModuleDict()
1:                                        (pred_layer): PredLayer(
1:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
1:                                        )
1:                                        (img_pred_layer): ImgPredLayer(
1:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
1:                                        )
1:                                      )
1: INFO - 04/19/20 17:20:05 - 0:04:04 - Number of parameters (model): 42634904
2: INFO - 04/19/20 17:20:08 - 0:04:07 - Model: TransformerModel(
2:                                        (projector): Projector(
2:                                          (linear): Linear(in_features=1536, out_features=512, bias=True)
2:                                        )
2:                                        (regional_encodings): RegionalEncodings(
2:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
2:                                        )
2:                                        (position_embeddings): Embedding(512, 512)
2:                                        (lang_embeddings): Embedding(3, 512)
2:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
2:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        (attentions): ModuleList(
2:                                          (0): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (1): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (2): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (3): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (4): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (5): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                        )
2:                                        (layer_norm1): ModuleList(
2:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        )
2:                                        (ffns): ModuleList(
2:                                          (0): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (1): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (2): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (3): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (4): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (5): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                        )
2:                                        (layer_norm2): ModuleList(
2:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        )
2:                                        (memories): ModuleDict()
2:                                        (pred_layer): PredLayer(
2:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
2:                                        )
2:                                        (img_pred_layer): ImgPredLayer(
2:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
2:                                        )
2:                                      )
2: INFO - 04/19/20 17:20:08 - 0:04:07 - Number of parameters (model): 42634904
3: INFO - 04/19/20 17:20:09 - 0:04:09 - Model: TransformerModel(
3:                                        (projector): Projector(
3:                                          (linear): Linear(in_features=1536, out_features=512, bias=True)
3:                                        )
3:                                        (regional_encodings): RegionalEncodings(
3:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
3:                                        )
3:                                        (position_embeddings): Embedding(512, 512)
3:                                        (lang_embeddings): Embedding(3, 512)
3:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
3:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        (attentions): ModuleList(
3:                                          (0): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (1): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (2): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (3): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (4): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (5): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm1): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (ffns): ModuleList(
3:                                          (0): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (1): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (2): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (3): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (4): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (5): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm2): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (memories): ModuleDict()
3:                                        (pred_layer): PredLayer(
3:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
3:                                        )
3:                                        (img_pred_layer): ImgPredLayer(
3:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
3:                                        )
3:                                      )
3: INFO - 04/19/20 17:20:09 - 0:04:09 - Number of parameters (model): 42634904
3: INFO - 04/19/20 17:20:10 - 0:04:09 - Model: TransformerModel(
3:                                        (projector): Projector(
3:                                          (linear): Linear(in_features=1536, out_features=512, bias=True)
3:                                        )
3:                                        (regional_encodings): RegionalEncodings(
3:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
3:                                        )
3:                                        (position_embeddings): Embedding(512, 512)
3:                                        (lang_embeddings): Embedding(3, 512)
3:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
3:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        (attentions): ModuleList(
3:                                          (0): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (1): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (2): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (3): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (4): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (5): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm1): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (ffns): ModuleList(
3:                                          (0): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (1): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (2): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (3): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (4): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (5): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm2): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (memories): ModuleDict()
3:                                        (pred_layer): PredLayer(
3:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
3:                                        )
3:                                        (img_pred_layer): ImgPredLayer(
3:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
3:                                        )
3:                                      )
3: INFO - 04/19/20 17:20:10 - 0:04:09 - Number of parameters (model): 42634904
0: INFO - 04/19/20 17:20:18 - 0:04:18 - Found 0 memories.
0: INFO - 04/19/20 17:20:18 - 0:04:18 - Found 6 FFN.
0: INFO - 04/19/20 17:20:18 - 0:04:18 - Found 108 parameters in model.
0: INFO - 04/19/20 17:20:18 - 0:04:18 - Using nn.parallel.DistributedDataParallel ...
1: INFO - 04/19/20 17:21:30 - 0:05:29 - Found 0 memories.
1: INFO - 04/19/20 17:21:30 - 0:05:29 - Found 6 FFN.
1: INFO - 04/19/20 17:21:30 - 0:05:29 - Found 108 parameters in model.
1: INFO - 04/19/20 17:21:30 - 0:05:29 - Using nn.parallel.DistributedDataParallel ...
2: INFO - 04/19/20 17:21:33 - 0:05:32 - Found 0 memories.
2: INFO - 04/19/20 17:21:33 - 0:05:32 - Found 6 FFN.
2: INFO - 04/19/20 17:21:33 - 0:05:32 - Found 108 parameters in model.
2: INFO - 04/19/20 17:21:33 - 0:05:32 - Using nn.parallel.DistributedDataParallel ...
3: INFO - 04/19/20 17:21:34 - 0:05:33 - Found 0 memories.
3: INFO - 04/19/20 17:21:34 - 0:05:33 - Found 6 FFN.
3: INFO - 04/19/20 17:21:34 - 0:05:33 - Found 108 parameters in model.
3: INFO - 04/19/20 17:21:34 - 0:05:33 - Using nn.parallel.DistributedDataParallel ...
3: INFO - 04/19/20 17:21:34 - 0:05:34 - Found 0 memories.
3: INFO - 04/19/20 17:21:34 - 0:05:34 - Found 6 FFN.
3: INFO - 04/19/20 17:21:34 - 0:05:34 - Found 108 parameters in model.
3: INFO - 04/19/20 17:21:34 - 0:05:34 - Using nn.parallel.DistributedDataParallel ...
3: INFO - 04/19/20 17:21:35 - 0:05:34 - Using nn.parallel.DistributedDataParallel ...
2: INFO - 04/19/20 17:21:35 - 0:05:34 - Using nn.parallel.DistributedDataParallel ...
2: INFO - 04/19/20 17:21:35 - 0:05:34 - Optimizers: model
3: INFO - 04/19/20 17:21:35 - 0:05:35 - Optimizers: model
2: INFO - 04/19/20 17:21:35 - 0:05:34 - ============ Starting epoch 0 ... ============
2: INFO - 04/19/20 17:21:35 - 0:05:34 - Creating new training data iterator (pred,en,de) ...
2: Traceback (most recent call last):
2:   File "train.py", line 348, in <module>
2:     main(params)
2:   File "train.py", line 289, in main
2:     trainer.mlm_step(lang1, lang2, params.lambda_mlm, iter)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 840, in mlm_step
2:     tensor = model('fwd', x=x, lengths=lengths, positions=positions, langs=langs, causal=False)
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
2:     result = self.forward(*input, **kwargs)
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 464, in forward
2:     self.reducer.prepare_for_backward([])
2: RuntimeError: Expected to have finished reduction in the prior iteration before starting a new one. This error indicates that your module has parameters that were not used in producing loss. You can enable unused parameter detection by (1) passing the keyword argument `find_unused_parameters=True` to `torch.nn.parallel.DistributedDataParallel`; (2) making sure all `forward` function outputs participate in calculating loss. If you already have done the above two steps, then the distributed data parallel module wasn't able to locate the output tensors in the return value of your module's `forward` function. Please include the loss function and the structure of the return value of `forward` of your module when reporting this issue (e.g. list, dict, iterable). (prepare_for_backward at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:514)
2: frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x33 (0x7fb60b8c8193 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libc10.so)
2: frame #1: c10d::Reducer::prepare_for_backward(std::vector<at::Tensor, std::allocator<at::Tensor> > const&) + 0x731 (0x7fb64de98471 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
2: frame #2: <unknown function> + 0xa0e63a (0x7fb64de8463a in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
2: frame #3: <unknown function> + 0x2956c4 (0x7fb64d70b6c4 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
2: <omitting python frames>
2: frame #35: main + 0x119 (0x400a99 in /home/menekse/virtualenvs/torch_env/bin/python)
2: frame #36: __libc_start_main + 0xf5 (0x7fb65e85b3d5 in /lib64/libc.so.6)
2: frame #37: /home/menekse/virtualenvs/torch_env/bin/python() [0x400c20]
2: 
3: Traceback (most recent call last):
3:   File "train.py", line 348, in <module>
3:     main(params)
3:   File "train.py", line 251, in main
3:     trainer = SingleTrainer(model, data, params)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
3:     super().__init__(data, params)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 67, in __init__
3:     setattr(self, name, nn.parallel.DistributedDataParallel(getattr(self, name), device_ids=[params.local_rank], output_device=params.local_rank, broadcast_buffers=True))
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 303, in __init__
3:     self.broadcast_bucket_size)
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 485, in _distributed_broadcast_coalesced
3:     dist._broadcast_coalesced(self.process_group, tensors, buffer_size)
3: RuntimeError: NCCL error in: /pytorch/torch/lib/c10d/ProcessGroupNCCL.cpp:410, unhandled system error, NCCL version 2.4.8
0: Traceback (most recent call last):
0:   File "train.py", line 348, in <module>
0:     main(params)
0:   File "train.py", line 251, in main
0:     trainer = SingleTrainer(model, data, params)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
0:     super().__init__(data, params)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 67, in __init__
0:     setattr(self, name, nn.parallel.DistributedDataParallel(getattr(self, name), device_ids=[params.local_rank], output_device=params.local_rank, broadcast_buffers=True))
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 303, in __init__
0:     self.broadcast_bucket_size)
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 485, in _distributed_broadcast_coalesced
0:     dist._broadcast_coalesced(self.process_group, tensors, buffer_size)
0: RuntimeError: NCCL error in: /pytorch/torch/lib/c10d/ProcessGroupNCCL.cpp:410, unhandled system error, NCCL version 2.4.8
3: INFO - 04/19/20 17:22:08 - 0:06:08 - ============ Starting epoch 0 ... ============
3: INFO - 04/19/20 17:22:08 - 0:06:08 - Creating new training data iterator (pred,en,de) ...
3: Traceback (most recent call last):
3:   File "train.py", line 348, in <module>
3:     main(params)
3:   File "train.py", line 289, in main
3:     trainer.mlm_step(lang1, lang2, params.lambda_mlm, iter)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 840, in mlm_step
3:     tensor = model('fwd', x=x, lengths=lengths, positions=positions, langs=langs, causal=False)
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
3:     result = self.forward(*input, **kwargs)
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 464, in forward
3:     self.reducer.prepare_for_backward([])
3: RuntimeError: Expected to have finished reduction in the prior iteration before starting a new one. This error indicates that your module has parameters that were not used in producing loss. You can enable unused parameter detection by (1) passing the keyword argument `find_unused_parameters=True` to `torch.nn.parallel.DistributedDataParallel`; (2) making sure all `forward` function outputs participate in calculating loss. If you already have done the above two steps, then the distributed data parallel module wasn't able to locate the output tensors in the return value of your module's `forward` function. Please include the loss function and the structure of the return value of `forward` of your module when reporting this issue (e.g. list, dict, iterable). (prepare_for_backward at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:514)
3: frame #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x33 (0x7f2c747ed193 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libc10.so)
3: frame #1: c10d::Reducer::prepare_for_backward(std::vector<at::Tensor, std::allocator<at::Tensor> > const&) + 0x731 (0x7f2cb6dbd471 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
3: frame #2: <unknown function> + 0xa0e63a (0x7f2cb6da963a in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
3: frame #3: <unknown function> + 0x2956c4 (0x7f2cb66306c4 in /home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/lib/libtorch_python.so)
3: <omitting python frames>
3: frame #35: main + 0x119 (0x400a99 in /home/menekse/virtualenvs/torch_env/bin/python)
3: frame #36: __libc_start_main + 0xf5 (0x7f2cc77803d5 in /lib64/libc.so.6)
3: frame #37: /home/menekse/virtualenvs/torch_env/bin/python() [0x400c20]
3: 
3: Traceback (most recent call last):
3:   File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
3:     "__main__", mod_spec)
3:   File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
3:     exec(code, run_globals)
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 263, in <module>
3:     main()
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 259, in main
3:     cmd=cmd)
3: subprocess.CalledProcessError: Command '['/home/menekse/virtualenvs/torch_env/bin/python', '-u', 'train.py', '--local_rank=1', '--exp_name', 'xlm_en_de_tlm', '--dump_path', '/data/menekse/dumped', '--data_path', '/data/shared/ConceptualCaptions/XLM_data/50k', '--lgs', 'en-de', '--clm_steps', '', '--mlm_steps', 'en-de', '--emb_dim', '512', '--n_layers', '6', '--n_heads', '8', '--dropout', '0.1', '--attention_dropout', '0.1', '--gelu_activation', 'true', '--batch_size', '32', '--bptt', '256', '--optimizer', 'adam,lr=0.0001', '--epoch_size', '300000', '--max_epoch', '100000', '--validation_metrics', 'valid_en_de_mlm_ppl', '--stopping_criterion', '_valid_mlm_ppl,25', '--fp16', 'false', '--image_names', '/data/shared/ConceptualCaptions/XLM_data/50k']' returned non-zero exit status 1.
srun: error: hanabi: task 3: Exited with exit code 1
