/var/spool/slurm/d/job03083/slurm_script: line 15: {workdir}/3083.stdout: No such file or directory
/var/spool/slurm/d/job03083/slurm_script: line 16: {workdir}/3083.stdout: No such file or directory
/var/spool/slurm/d/job03083/slurm_script: line 17: {workdir}/3083.stdout: No such file or directory
/var/spool/slurm/d/job03083/slurm_script: line 18: {workdir}/3083.stdout: No such file or directory
/var/spool/slurm/d/job03083/slurm_script: line 19: {workdir}/3083.stdout: No such file or directory
/var/spool/slurm/d/job03083/slurm_script: line 20: {workdir}/3083.stdout: No such file or directory
3: FAISS library was not found.
3: FAISS not available. Switching to standard nearest neighbors search implementation.
0: FAISS library was not found.
0: FAISS not available. Switching to standard nearest neighbors search implementation.
2: FAISS library was not found.
2: FAISS not available. Switching to standard nearest neighbors search implementation.
3: FAISS library was not found.
3: FAISS not available. Switching to standard nearest neighbors search implementation.
1: FAISS library was not found.
1: FAISS not available. Switching to standard nearest neighbors search implementation.
3: FAISS library was not found.
3: FAISS not available. Switching to standard nearest neighbors search implementation.
2: FAISS library was not found.
2: FAISS not available. Switching to standard nearest neighbors search implementation.
0: FAISS library was not found.
0: FAISS not available. Switching to standard nearest neighbors search implementation.
0: FAISS library was not found.
0: FAISS not available. Switching to standard nearest neighbors search implementation.
2: FAISS library was not found.
2: FAISS not available. Switching to standard nearest neighbors search implementation.
1: FAISS library was not found.
1: FAISS not available. Switching to standard nearest neighbors search implementation.
1: FAISS library was not found.
1: FAISS not available. Switching to standard nearest neighbors search implementation.
1: INFO - 04/18/20 13:42:01 - 0:00:00 - ============ Initialized logger ============
1: INFO - 04/18/20 13:42:01 - 0:00:00 - accumulate_gradients: 1
1:                                      ae_steps: []
1:                                      amp: -1
1:                                      asm: False
1:                                      attention_dropout: 0.1
1:                                      batch_size: 32
1:                                      beam_size: 1
1:                                      bptt: 256
1:                                      bt_src_langs: []
1:                                      bt_steps: []
1:                                      clip_grad_norm: 5
1:                                      clm_steps: []
1:                                      command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3083"
1:                                      context_size: 0
1:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
1:                                      debug: False
1:                                      debug_slurm: False
1:                                      debug_train: False
1:                                      dropout: 0.1
1:                                      dump_path: ./dumped/xlm_en_de_tlm/3083
1:                                      early_stopping: False
1:                                      emb_dim: 512
1:                                      encoder_only: True
1:                                      epoch_size: 300000
1:                                      eval_bleu: False
1:                                      eval_only: False
1:                                      exp_id: 3083
1:                                      exp_name: xlm_en_de_tlm
1:                                      fp16: False
1:                                      gelu_activation: True
1:                                      global_rank: 2
1:                                      group_by_size: True
1:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
1:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
1:                                      is_master: False
1:                                      is_slurm_job: False
1:                                      lambda_ae: 1
1:                                      lambda_bt: 1
1:                                      lambda_clm: 1
1:                                      lambda_mlm: 1
1:                                      lambda_mt: 1
1:                                      lambda_pc: 1
1:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
1:                                      langs: ['en', 'de', 'img']
1:                                      length_penalty: 1
1:                                      lg_sampling_factor: -1
1:                                      lgs: en-de
1:                                      local_rank: 2
1:                                      master_port: -1
1:                                      max_batch_size: 0
1:                                      max_epoch: 100000
1:                                      max_len: 100
1:                                      max_vocab: -1
1:                                      min_count: 0
1:                                      mlm_steps: [('en', 'de')]
1:                                      mono_dataset: {}
1:                                      mt_steps: []
1:                                      multi_gpu: True
1:                                      multi_node: False
1:                                      n_gpu_per_node: 3
1:                                      n_heads: 8
1:                                      n_langs: 3
1:                                      n_layers: 6
1:                                      n_nodes: 1
1:                                      node_id: 0
1:                                      only_vlm: False
1:                                      optimizer: adam,lr=0.0001
1:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
1:                                      pc_steps: []
1:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
1:                                      reload_checkpoint: 
1:                                      reload_emb: 
1:                                      reload_model: 
1:                                      sample_alpha: 0
1:                                      save_periodic: 0
1:                                      share_inout_emb: True
1:                                      sinusoidal_embeddings: False
1:                                      split_data: False
1:                                      stopping_criterion: _valid_mlm_ppl,25
1:                                      tokens_per_batch: -1
1:                                      use_lang_emb: True
1:                                      use_memory: False
1:                                      validation_metrics: valid_en_de_mlm_ppl
1:                                      vlm_steps: [('en', 'de')]
1:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
1:                                      word_blank: 0
1:                                      word_dropout: 0
1:                                      word_keep: 0.1
1:                                      word_mask: 0.8
1:                                      word_mask_keep_rand: 0.8,0.1,0.1
1:                                      word_pred: 0.15
1:                                      word_rand: 0.1
1:                                      word_shuffle: 0
1:                                      world_size: 3
1: INFO - 04/18/20 13:42:01 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3083
1:                                      
1: INFO - 04/18/20 13:42:01 - 0:00:00 - Running command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
1: 
1: WARNING - 04/18/20 13:42:01 - 0:00:00 - Signal handler installed.
1: 
1: INFO - 04/18/20 13:42:01 - 0:00:00 - ============ Parallel data (de-en)
1: INFO - 04/18/20 13:42:01 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
1: INFO - 04/18/20 13:42:02 - 0:00:00 - ============ Initialized logger ============
1: INFO - 04/18/20 13:42:02 - 0:00:00 - accumulate_gradients: 1
1:                                      ae_steps: []
1:                                      amp: -1
1:                                      asm: False
1:                                      attention_dropout: 0.1
1:                                      batch_size: 32
1:                                      beam_size: 1
1:                                      bptt: 256
1:                                      bt_src_langs: []
1:                                      bt_steps: []
1:                                      clip_grad_norm: 5
1:                                      clm_steps: []
1:                                      command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3083"
1:                                      context_size: 0
1:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
1:                                      debug: False
1:                                      debug_slurm: False
1:                                      debug_train: False
1:                                      dropout: 0.1
1:                                      dump_path: ./dumped/xlm_en_de_tlm/3083
1:                                      early_stopping: False
1:                                      emb_dim: 512
1:                                      encoder_only: True
1:                                      epoch_size: 300000
1:                                      eval_bleu: False
1:                                      eval_only: False
1:                                      exp_id: 3083
1:                                      exp_name: xlm_en_de_tlm
1:                                      fp16: False
1:                                      gelu_activation: True
1:                                      global_rank: 1
1:                                      group_by_size: True
1:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
1:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
1:                                      is_master: False
1:                                      is_slurm_job: False
1:                                      lambda_ae: 1
1:                                      lambda_bt: 1
1:                                      lambda_clm: 1
1:                                      lambda_mlm: 1
1:                                      lambda_mt: 1
1:                                      lambda_pc: 1
1:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
1:                                      langs: ['en', 'de', 'img']
1:                                      length_penalty: 1
1:                                      lg_sampling_factor: -1
1:                                      lgs: en-de
1:                                      local_rank: 1
1:                                      master_port: -1
1:                                      max_batch_size: 0
1:                                      max_epoch: 100000
1:                                      max_len: 100
1:                                      max_vocab: -1
1:                                      min_count: 0
1:                                      mlm_steps: [('en', 'de')]
1:                                      mono_dataset: {}
1:                                      mt_steps: []
1:                                      multi_gpu: True
1:                                      multi_node: False
1:                                      n_gpu_per_node: 3
1:                                      n_heads: 8
1:                                      n_langs: 3
1:                                      n_layers: 6
1:                                      n_nodes: 1
1:                                      node_id: 0
1:                                      only_vlm: False
1:                                      optimizer: adam,lr=0.0001
1:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
1:                                      pc_steps: []
1:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
1:                                      reload_checkpoint: 
1:                                      reload_emb: 
1:                                      reload_model: 
1:                                      sample_alpha: 0
1:                                      save_periodic: 0
1:                                      share_inout_emb: True
1:                                      sinusoidal_embeddings: False
1:                                      split_data: False
1:                                      stopping_criterion: _valid_mlm_ppl,25
1:                                      tokens_per_batch: -1
1:                                      use_lang_emb: True
1:                                      use_memory: False
1:                                      validation_metrics: valid_en_de_mlm_ppl
1:                                      vlm_steps: [('en', 'de')]
1:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
1:                                      word_blank: 0
1:                                      word_dropout: 0
1:                                      word_keep: 0.1
1:                                      word_mask: 0.8
1:                                      word_mask_keep_rand: 0.8,0.1,0.1
1:                                      word_pred: 0.15
1:                                      word_rand: 0.1
1:                                      word_shuffle: 0
1:                                      world_size: 3
1: INFO - 04/18/20 13:42:02 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3083
1:                                      
1: INFO - 04/18/20 13:42:02 - 0:00:00 - Running command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
1: 
1: WARNING - 04/18/20 13:42:02 - 0:00:00 - Signal handler installed.
1: 
1: INFO - 04/18/20 13:42:02 - 0:00:00 - ============ Parallel data (de-en)
1: INFO - 04/18/20 13:42:02 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
1: INFO - 04/18/20 13:42:02 - 0:00:00 - ============ Initialized logger ============
1: INFO - 04/18/20 13:42:02 - 0:00:00 - accumulate_gradients: 1
1:                                      ae_steps: []
1:                                      amp: -1
1:                                      asm: False
1:                                      attention_dropout: 0.1
1:                                      batch_size: 32
1:                                      beam_size: 1
1:                                      bptt: 256
1:                                      bt_src_langs: []
1:                                      bt_steps: []
1:                                      clip_grad_norm: 5
1:                                      clm_steps: []
1:                                      command: python train.py --local_rank=0 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3083"
1:                                      context_size: 0
1:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
1:                                      debug: False
1:                                      debug_slurm: False
1:                                      debug_train: False
1:                                      dropout: 0.1
1:                                      dump_path: ./dumped/xlm_en_de_tlm/3083
1:                                      early_stopping: False
1:                                      emb_dim: 512
1:                                      encoder_only: True
1:                                      epoch_size: 300000
1:                                      eval_bleu: False
1:                                      eval_only: False
1:                                      exp_id: 3083
1:                                      exp_name: xlm_en_de_tlm
1:                                      fp16: False
1:                                      gelu_activation: True
1:                                      global_rank: 0
1:                                      group_by_size: True
1:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
1:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
1:                                      is_master: True
1:                                      is_slurm_job: False
1:                                      lambda_ae: 1
1:                                      lambda_bt: 1
1:                                      lambda_clm: 1
1:                                      lambda_mlm: 1
1:                                      lambda_mt: 1
1:                                      lambda_pc: 1
1:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
1:                                      langs: ['en', 'de', 'img']
1:                                      length_penalty: 1
1:                                      lg_sampling_factor: -1
1:                                      lgs: en-de
1:                                      local_rank: 0
1:                                      master_port: -1
1:                                      max_batch_size: 0
1:                                      max_epoch: 100000
1:                                      max_len: 100
1:                                      max_vocab: -1
1:                                      min_count: 0
1:                                      mlm_steps: [('en', 'de')]
1:                                      mono_dataset: {}
1:                                      mt_steps: []
1:                                      multi_gpu: True
1:                                      multi_node: False
1:                                      n_gpu_per_node: 3
1:                                      n_heads: 8
1:                                      n_langs: 3
1:                                      n_layers: 6
1:                                      n_nodes: 1
1:                                      node_id: 0
1:                                      only_vlm: False
1:                                      optimizer: adam,lr=0.0001
1:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
1:                                      pc_steps: []
1:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
1:                                      reload_checkpoint: 
1:                                      reload_emb: 
1:                                      reload_model: 
1:                                      sample_alpha: 0
1:                                      save_periodic: 0
1:                                      share_inout_emb: True
1:                                      sinusoidal_embeddings: False
1:                                      split_data: False
1:                                      stopping_criterion: _valid_mlm_ppl,25
1:                                      tokens_per_batch: -1
1:                                      use_lang_emb: True
1:                                      use_memory: False
1:                                      validation_metrics: valid_en_de_mlm_ppl
1:                                      vlm_steps: [('en', 'de')]
1:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
1:                                      word_blank: 0
1:                                      word_dropout: 0
1:                                      word_keep: 0.1
1:                                      word_mask: 0.8
1:                                      word_mask_keep_rand: 0.8,0.1,0.1
1:                                      word_pred: 0.15
1:                                      word_rand: 0.1
1:                                      word_shuffle: 0
1:                                      world_size: 3
1: INFO - 04/18/20 13:42:02 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3083
1:                                      
1: INFO - 04/18/20 13:42:02 - 0:00:00 - Running command: python train.py --local_rank=0 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
1: 
1: WARNING - 04/18/20 13:42:02 - 0:00:00 - Signal handler installed.
1: 
1: INFO - 04/18/20 13:42:02 - 0:00:00 - ============ Parallel data (de-en)
1: INFO - 04/18/20 13:42:02 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
0: Traceback (most recent call last):
0:   File "train.py", line 348, in <module>
0:     main(params)
0:   File "train.py", line 230, in main
0:     init_distributed_mode(params)
0:   File "/home/menekse/xlm/Animal/XLM-master/src/slurm.py", line 171, in init_distributed_mode
0:     backend='nccl',
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py", line 397, in init_process_group
0:     store, rank, world_size = next(rendezvous_iterator)
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/rendezvous.py", line 168, in _env_rendezvous_handler
0:     store = TCPStore(master_addr, master_port, world_size, start_daemon)
0: RuntimeError: Address already in use
3: INFO - 04/18/20 13:42:02 - 0:00:00 - ============ Initialized logger ============
3: INFO - 04/18/20 13:42:02 - 0:00:00 - accumulate_gradients: 1
3:                                      ae_steps: []
3:                                      amp: -1
3:                                      asm: False
3:                                      attention_dropout: 0.1
3:                                      batch_size: 32
3:                                      beam_size: 1
3:                                      bptt: 256
3:                                      bt_src_langs: []
3:                                      bt_steps: []
3:                                      clip_grad_norm: 5
3:                                      clm_steps: []
3:                                      command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3083"
3:                                      context_size: 0
3:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      debug: False
3:                                      debug_slurm: False
3:                                      debug_train: False
3:                                      dropout: 0.1
3:                                      dump_path: ./dumped/xlm_en_de_tlm/3083
3:                                      early_stopping: False
3:                                      emb_dim: 512
3:                                      encoder_only: True
3:                                      epoch_size: 300000
3:                                      eval_bleu: False
3:                                      eval_only: False
3:                                      exp_id: 3083
3:                                      exp_name: xlm_en_de_tlm
3:                                      fp16: False
3:                                      gelu_activation: True
3:                                      global_rank: 2
3:                                      group_by_size: True
3:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
3:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      is_master: False
3:                                      is_slurm_job: False
3:                                      lambda_ae: 1
3:                                      lambda_bt: 1
3:                                      lambda_clm: 1
3:                                      lambda_mlm: 1
3:                                      lambda_mt: 1
3:                                      lambda_pc: 1
3:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
3:                                      langs: ['en', 'de', 'img']
3:                                      length_penalty: 1
3:                                      lg_sampling_factor: -1
3:                                      lgs: en-de
3:                                      local_rank: 2
3:                                      master_port: -1
3:                                      max_batch_size: 0
3:                                      max_epoch: 100000
3:                                      max_len: 100
3:                                      max_vocab: -1
3:                                      min_count: 0
3:                                      mlm_steps: [('en', 'de')]
3:                                      mono_dataset: {}
3:                                      mt_steps: []
3:                                      multi_gpu: True
3:                                      multi_node: False
3:                                      n_gpu_per_node: 3
3:                                      n_heads: 8
3:                                      n_langs: 3
3:                                      n_layers: 6
3:                                      n_nodes: 1
3:                                      node_id: 0
3:                                      only_vlm: False
3:                                      optimizer: adam,lr=0.0001
3:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      pc_steps: []
3:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
3:                                      reload_checkpoint: 
3:                                      reload_emb: 
3:                                      reload_model: 
3:                                      sample_alpha: 0
3:                                      save_periodic: 0
3:                                      share_inout_emb: True
3:                                      sinusoidal_embeddings: False
3:                                      split_data: False
3:                                      stopping_criterion: _valid_mlm_ppl,25
3:                                      tokens_per_batch: -1
3:                                      use_lang_emb: True
3:                                      use_memory: False
3:                                      validation_metrics: valid_en_de_mlm_ppl
3:                                      vlm_steps: [('en', 'de')]
3:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      word_blank: 0
3:                                      word_dropout: 0
3:                                      word_keep: 0.1
3:                                      word_mask: 0.8
3:                                      word_mask_keep_rand: 0.8,0.1,0.1
3:                                      word_pred: 0.15
3:                                      word_rand: 0.1
3:                                      word_shuffle: 0
3:                                      world_size: 3
3: INFO - 04/18/20 13:42:02 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3083
3:                                      
3: INFO - 04/18/20 13:42:02 - 0:00:00 - ============ Initialized logger ============
3: INFO - 04/18/20 13:42:02 - 0:00:00 - Running command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
2: INFO - 04/18/20 13:42:02 - 0:00:00 - ============ Initialized logger ============
3: 
0: INFO - 04/18/20 13:42:02 - 0:00:00 - ============ Initialized logger ============
3: WARNING - 04/18/20 13:42:02 - 0:00:00 - Signal handler installed.
3: 
3: INFO - 04/18/20 13:42:02 - 0:00:00 - ============ Parallel data (de-en)
3: INFO - 04/18/20 13:42:02 - 0:00:00 - accumulate_gradients: 1
3:                                      ae_steps: []
3:                                      amp: -1
3:                                      asm: False
3:                                      attention_dropout: 0.1
3:                                      batch_size: 32
3:                                      beam_size: 1
3:                                      bptt: 256
3:                                      bt_src_langs: []
3:                                      bt_steps: []
3:                                      clip_grad_norm: 5
3:                                      clm_steps: []
3:                                      command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3083"
3:                                      context_size: 0
3:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      debug: False
3:                                      debug_slurm: False
3:                                      debug_train: False
3:                                      dropout: 0.1
3:                                      dump_path: ./dumped/xlm_en_de_tlm/3083
3:                                      early_stopping: False
3:                                      emb_dim: 512
3:                                      encoder_only: True
3:                                      epoch_size: 300000
3:                                      eval_bleu: False
3:                                      eval_only: False
3:                                      exp_id: 3083
3:                                      exp_name: xlm_en_de_tlm
3:                                      fp16: False
3:                                      gelu_activation: True
3:                                      global_rank: 1
3:                                      group_by_size: True
3:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
3:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
3:                                      is_master: False
3:                                      is_slurm_job: False
3:                                      lambda_ae: 1
3:                                      lambda_bt: 1
3:                                      lambda_clm: 1
3:                                      lambda_mlm: 1
3:                                      lambda_mt: 1
3:                                      lambda_pc: 1
3:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
3:                                      langs: ['en', 'de', 'img']
3:                                      length_penalty: 1
3:                                      lg_sampling_factor: -1
3:                                      lgs: en-de
3:                                      local_rank: 1
3:                                      master_port: -1
3:                                      max_batch_size: 0
3:                                      max_epoch: 100000
3:                                      max_len: 100
3:                                      max_vocab: -1
3:                                      min_count: 0
3:                                      mlm_steps: [('en', 'de')]
3:                                      mono_dataset: {}
3:                                      mt_steps: []
3:                                      multi_gpu: True
3:                                      multi_node: False
3:                                      n_gpu_per_node: 3
3:                                      n_heads: 8
3:                                      n_langs: 3
3:                                      n_layers: 6
3:                                      n_nodes: 1
2: INFO - 04/18/20 13:42:02 - 0:00:00 - accumulate_gradients: 1
2:                                      ae_steps: []
2:                                      amp: -1
2:                                      asm: False
2:                                      attention_dropout: 0.1
2:                                      batch_size: 32
2:                                      beam_size: 1
2:                                      bptt: 256
2:                                      bt_src_langs: []
2:                                      bt_steps: []
2:                                      clip_grad_norm: 5
2:                                      clm_steps: []
2:                                      command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3083"
2:                                      context_size: 0
2:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
2:                                      debug: False
2:                                      debug_slurm: False
2:                                      debug_train: False
2:                                      dropout: 0.1
2:                                      dump_path: ./dumped/xlm_en_de_tlm/3083
2:                                      early_stopping: False
2:                                      emb_dim: 512
2:                                      encoder_only: True
2:                                      epoch_size: 300000
2:                                      eval_bleu: False
2:                                      eval_only: False
2:                                      exp_id: 3083
2:                                      exp_name: xlm_en_de_tlm
2:                                      fp16: False
2:                                      gelu_activation: True
2:                                      global_rank: 1
2:                                      group_by_size: True
2:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
2:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
2:                                      is_master: False
2:                                      is_slurm_job: False
2:                                      lambda_ae: 1
2:                                      lambda_bt: 1
2:                                      lambda_clm: 1
2:                                      lambda_mlm: 1
2:                                      lambda_mt: 1
2:                                      lambda_pc: 1
2:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
2:                                      langs: ['en', 'de', 'img']
2:                                      length_penalty: 1
2:                                      lg_sampling_factor: -1
2:                                      lgs: en-de
2:                                      local_rank: 1
2:                                      master_port: -1
2:                                      max_batch_size: 0
2:                                      max_epoch: 100000
2:                                      max_len: 100
2:                                      max_vocab: -1
2:                                      min_count: 0
2:                                      mlm_steps: [('en', 'de')]
2:                                      mono_dataset: {}
2:                                      mt_steps: []
2:                                      multi_gpu: True
2:                                      multi_node: False
2:                                      n_gpu_per_node: 3
2:                                      n_heads: 8
2:                                      n_langs: 3
2:                                      n_layers: 6
2:                                      n_nodes: 1
3:                                      node_id: 0
3:                                      only_vlm: False
3:                                      optimizer: adam,lr=0.0001
3:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      pc_steps: []
3:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
3:                                      reload_checkpoint: 
3:                                      reload_emb: 
3:                                      reload_model: 
3:                                      sample_alpha: 0
3:                                      save_periodic: 0
3:                                      share_inout_emb: True
3:                                      sinusoidal_embeddings: False
3:                                      split_data: False
3:                                      stopping_criterion: _valid_mlm_ppl,25
3:                                      tokens_per_batch: -1
3:                                      use_lang_emb: True
3:                                      use_memory: False
3:                                      validation_metrics: valid_en_de_mlm_ppl
3:                                      vlm_steps: [('en', 'de')]
3:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
3:                                      word_blank: 0
3:                                      word_dropout: 0
3:                                      word_keep: 0.1
3:                                      word_mask: 0.8
3:                                      word_mask_keep_rand: 0.8,0.1,0.1
3:                                      word_pred: 0.15
3:                                      word_rand: 0.1
3:                                      word_shuffle: 0
3:                                      world_size: 3
3: INFO - 04/18/20 13:42:02 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3083
3:                                      
3: INFO - 04/18/20 13:42:02 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: INFO - 04/18/20 13:42:02 - 0:00:00 - Running command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
0: INFO - 04/18/20 13:42:02 - 0:00:00 - accumulate_gradients: 1
0:                                      ae_steps: []
0:                                      amp: -1
0:                                      asm: False
0:                                      attention_dropout: 0.1
0:                                      batch_size: 32
0:                                      beam_size: 1
0:                                      bptt: 256
0:                                      bt_src_langs: []
0:                                      bt_steps: []
0:                                      clip_grad_norm: 5
0:                                      clm_steps: []
0:                                      command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3083"
0:                                      context_size: 0
0:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
0:                                      debug: False
0:                                      debug_slurm: False
0:                                      debug_train: False
0:                                      dropout: 0.1
0:                                      dump_path: ./dumped/xlm_en_de_tlm/3083
0:                                      early_stopping: False
0:                                      emb_dim: 512
0:                                      encoder_only: True
0:                                      epoch_size: 300000
0:                                      eval_bleu: False
0:                                      eval_only: False
0:                                      exp_id: 3083
0:                                      exp_name: xlm_en_de_tlm
0:                                      fp16: False
0:                                      gelu_activation: True
0:                                      global_rank: 2
0:                                      group_by_size: True
0:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
0:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
0:                                      is_master: False
0:                                      is_slurm_job: False
0:                                      lambda_ae: 1
0:                                      lambda_bt: 1
0:                                      lambda_clm: 1
0:                                      lambda_mlm: 1
0:                                      lambda_mt: 1
0:                                      lambda_pc: 1
0:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
0:                                      langs: ['en', 'de', 'img']
0:                                      length_penalty: 1
0:                                      lg_sampling_factor: -1
0:                                      lgs: en-de
0:                                      local_rank: 2
0:                                      master_port: -1
0:                                      max_batch_size: 0
0:                                      max_epoch: 100000
0:                                      max_len: 100
0:                                      max_vocab: -1
0:                                      min_count: 0
0:                                      mlm_steps: [('en', 'de')]
0:                                      mono_dataset: {}
0:                                      mt_steps: []
0:                                      multi_gpu: True
0:                                      multi_node: False
0:                                      n_gpu_per_node: 3
0:                                      n_heads: 8
0:                                      n_langs: 3
0:                                      n_layers: 6
0:                                      n_nodes: 1
2:                                      node_id: 0
2:                                      only_vlm: False
2:                                      optimizer: adam,lr=0.0001
2:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
2:                                      pc_steps: []
2:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
2:                                      reload_checkpoint: 
2:                                      reload_emb: 
2:                                      reload_model: 
2:                                      sample_alpha: 0
2:                                      save_periodic: 0
2:                                      share_inout_emb: True
2:                                      sinusoidal_embeddings: False
2:                                      split_data: False
2:                                      stopping_criterion: _valid_mlm_ppl,25
2:                                      tokens_per_batch: -1
2:                                      use_lang_emb: True
2:                                      use_memory: False
2:                                      validation_metrics: valid_en_de_mlm_ppl
2:                                      vlm_steps: [('en', 'de')]
2:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
2:                                      word_blank: 0
2:                                      word_dropout: 0
2:                                      word_keep: 0.1
2:                                      word_mask: 0.8
2:                                      word_mask_keep_rand: 0.8,0.1,0.1
2:                                      word_pred: 0.15
2:                                      word_rand: 0.1
2:                                      word_shuffle: 0
2:                                      world_size: 3
2: INFO - 04/18/20 13:42:02 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3083
2:                                      
2: INFO - 04/18/20 13:42:02 - 0:00:00 - Running command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
2: 
3: 
0:                                      node_id: 0
0:                                      only_vlm: False
0:                                      optimizer: adam,lr=0.0001
0:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
0:                                      pc_steps: []
0:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
0:                                      reload_checkpoint: 
0:                                      reload_emb: 
0:                                      reload_model: 
0:                                      sample_alpha: 0
0:                                      save_periodic: 0
0:                                      share_inout_emb: True
0:                                      sinusoidal_embeddings: False
0:                                      split_data: False
0:                                      stopping_criterion: _valid_mlm_ppl,25
0:                                      tokens_per_batch: -1
0:                                      use_lang_emb: True
0:                                      use_memory: False
0:                                      validation_metrics: valid_en_de_mlm_ppl
0:                                      vlm_steps: [('en', 'de')]
0:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
0:                                      word_blank: 0
0:                                      word_dropout: 0
0:                                      word_keep: 0.1
0:                                      word_mask: 0.8
0:                                      word_mask_keep_rand: 0.8,0.1,0.1
0:                                      word_pred: 0.15
0:                                      word_rand: 0.1
0:                                      word_shuffle: 0
0:                                      world_size: 3
0: INFO - 04/18/20 13:42:02 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3083
0:                                      
0: INFO - 04/18/20 13:42:02 - 0:00:00 - Running command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
0: 
0: WARNING - 04/18/20 13:42:02 - 0:00:00 - Signal handler installed.
2: WARNING - 04/18/20 13:42:02 - 0:00:00 - Signal handler installed.
3: WARNING - 04/18/20 13:42:02 - 0:00:00 - Signal handler installed.
3: Traceback (most recent call last):
2: Traceback (most recent call last):
2:   File "train.py", line 348, in <module>
3:   File "train.py", line 348, in <module>
0: 
2: 
3: 
0: INFO - 04/18/20 13:42:02 - 0:00:00 - ============ Parallel data (de-en)
2: INFO - 04/18/20 13:42:02 - 0:00:00 - ============ Parallel data (de-en)
3: INFO - 04/18/20 13:42:02 - 0:00:00 - ============ Parallel data (de-en)
2: INFO - 04/18/20 13:42:02 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: INFO - 04/18/20 13:42:02 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
0: INFO - 04/18/20 13:42:02 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
0: INFO - 04/18/20 13:42:02 - 0:00:00 - ============ Initialized logger ============
3:     main(params)
3:   File "train.py", line 230, in main
2:     main(params)
2:   File "train.py", line 230, in main
0: INFO - 04/18/20 13:42:02 - 0:00:00 - accumulate_gradients: 1
0:                                      ae_steps: []
0:                                      amp: -1
0:                                      asm: False
0:                                      attention_dropout: 0.1
0:                                      batch_size: 32
0:                                      beam_size: 1
0:                                      bptt: 256
0:                                      bt_src_langs: []
0:                                      bt_steps: []
0:                                      clip_grad_norm: 5
0:                                      clm_steps: []
0:                                      command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3083"
0:                                      context_size: 0
0:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
0:                                      debug: False
0:                                      debug_slurm: False
0:                                      debug_train: False
0:                                      dropout: 0.1
0:                                      dump_path: ./dumped/xlm_en_de_tlm/3083
0:                                      early_stopping: False
0:                                      emb_dim: 512
0:                                      encoder_only: True
0:                                      epoch_size: 300000
0:                                      eval_bleu: False
0:                                      eval_only: False
0:                                      exp_id: 3083
0:                                      exp_name: xlm_en_de_tlm
0:                                      fp16: False
0:                                      gelu_activation: True
0:                                      global_rank: 1
0:                                      group_by_size: True
0:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
0:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
0:                                      is_master: False
0:                                      is_slurm_job: False
0:                                      lambda_ae: 1
0:                                      lambda_bt: 1
0:                                      lambda_clm: 1
0:                                      lambda_mlm: 1
0:                                      lambda_mt: 1
0:                                      lambda_pc: 1
0:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
0:                                      langs: ['en', 'de', 'img']
0:                                      length_penalty: 1
0:                                      lg_sampling_factor: -1
0:                                      lgs: en-de
0:                                      local_rank: 1
0:                                      master_port: -1
0:                                      max_batch_size: 0
0:                                      max_epoch: 100000
0:                                      max_len: 100
0:                                      max_vocab: -1
0:                                      min_count: 0
0:                                      mlm_steps: [('en', 'de')]
0:                                      mono_dataset: {}
0:                                      mt_steps: []
0:                                      multi_gpu: True
0:                                      multi_node: False
0:                                      n_gpu_per_node: 3
0:                                      n_heads: 8
0:                                      n_langs: 3
0:                                      n_layers: 6
0:                                      n_nodes: 1
0:                                      node_id: 0
0:                                      only_vlm: False
0:                                      optimizer: adam,lr=0.0001
0:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
0:                                      pc_steps: []
0:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
0:                                      reload_checkpoint: 
0:                                      reload_emb: 
0:                                      reload_model: 
0:                                      sample_alpha: 0
0:                                      save_periodic: 0
0:                                      share_inout_emb: True
0:                                      sinusoidal_embeddings: False
0:                                      split_data: False
0:                                      stopping_criterion: _valid_mlm_ppl,25
0:                                      tokens_per_batch: -1
0:                                      use_lang_emb: True
0:                                      use_memory: False
0:                                      validation_metrics: valid_en_de_mlm_ppl
0:                                      vlm_steps: [('en', 'de')]
0:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
0:                                      word_blank: 0
0:                                      word_dropout: 0
0:                                      word_keep: 0.1
0:                                      word_mask: 0.8
0:                                      word_mask_keep_rand: 0.8,0.1,0.1
0:                                      word_pred: 0.15
0:                                      word_rand: 0.1
0:                                      word_shuffle: 0
0:                                      world_size: 3
0: INFO - 04/18/20 13:42:02 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3083
0:                                      
0: INFO - 04/18/20 13:42:02 - 0:00:00 - Running command: python train.py --local_rank=1 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
2: INFO - 04/18/20 13:42:02 - 0:00:00 - ============ Initialized logger ============
3:     init_distributed_mode(params)
3:   File "/home/menekse/xlm/Animal/XLM-master/src/slurm.py", line 171, in init_distributed_mode
0: 
2:     init_distributed_mode(params)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/slurm.py", line 171, in init_distributed_mode
0: WARNING - 04/18/20 13:42:02 - 0:00:00 - Signal handler installed.
0: 
3:     backend='nccl',
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py", line 397, in init_process_group
0: INFO - 04/18/20 13:42:02 - 0:00:00 - ============ Parallel data (de-en)
2: INFO - 04/18/20 13:42:02 - 0:00:00 - accumulate_gradients: 1
2:                                      ae_steps: []
2:                                      amp: -1
2:                                      asm: False
2:                                      attention_dropout: 0.1
2:                                      batch_size: 32
2:                                      beam_size: 1
2:                                      bptt: 256
2:                                      bt_src_langs: []
2:                                      bt_steps: []
2:                                      clip_grad_norm: 5
2:                                      clm_steps: []
2:                                      command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k' --exp_id "3083"
2:                                      context_size: 0
2:                                      data_path: /data/shared/ConceptualCaptions/XLM_data/50k
2:                                      debug: False
2:                                      debug_slurm: False
2:                                      debug_train: False
2:                                      dropout: 0.1
2:                                      dump_path: ./dumped/xlm_en_de_tlm/3083
2:                                      early_stopping: False
2:                                      emb_dim: 512
2:                                      encoder_only: True
2:                                      epoch_size: 300000
2:                                      eval_bleu: False
2:                                      eval_only: False
2:                                      exp_id: 3083
2:                                      exp_name: xlm_en_de_tlm
2:                                      fp16: False
2:                                      gelu_activation: True
2:                                      global_rank: 2
2:                                      group_by_size: True
2:                                      id2lang: {0: 'de', 1: 'en', 2: 'img'}
2:                                      image_names: /data/shared/ConceptualCaptions/XLM_data/50k
2:                                      is_master: False
2:                                      is_slurm_job: False
2:                                      lambda_ae: 1
2:                                      lambda_bt: 1
2:                                      lambda_clm: 1
2:                                      lambda_mlm: 1
2:                                      lambda_mt: 1
2:                                      lambda_pc: 1
2:                                      lang2id: {'de': 0, 'en': 1, 'img': 2}
2:                                      langs: ['en', 'de', 'img']
2:                                      length_penalty: 1
2:                                      lg_sampling_factor: -1
2:                                      lgs: en-de
2:                                      local_rank: 2
2:                                      master_port: -1
2:                                      max_batch_size: 0
2:                                      max_epoch: 100000
2:                                      max_len: 100
2:                                      max_vocab: -1
2:                                      min_count: 0
2:                                      mlm_steps: [('en', 'de')]
2:                                      mono_dataset: {}
2:                                      mt_steps: []
2:                                      multi_gpu: True
2:                                      multi_node: False
2:                                      n_gpu_per_node: 3
2:                                      n_heads: 8
2:                                      n_langs: 3
2:                                      n_layers: 6
2:                                      n_nodes: 1
0: INFO - 04/18/20 13:42:02 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
2:                                      node_id: 0
2:                                      only_vlm: False
2:                                      optimizer: adam,lr=0.0001
2:                                      para_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
2:                                      pc_steps: []
2:                                      region_feats_path: /data/shared/ConceptualCaptions/fastrcnn_features_36/
2:                                      reload_checkpoint: 
2:                                      reload_emb: 
2:                                      reload_model: 
2:                                      sample_alpha: 0
2:                                      save_periodic: 0
2:                                      share_inout_emb: True
2:                                      sinusoidal_embeddings: False
2:                                      split_data: False
2:                                      stopping_criterion: _valid_mlm_ppl,25
2:                                      tokens_per_batch: -1
2:                                      use_lang_emb: True
2:                                      use_memory: False
2:                                      validation_metrics: valid_en_de_mlm_ppl
2:                                      vlm_steps: [('en', 'de')]
2:                                      vpara_dataset: {('de', 'en'): {'train': ('/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth'), 'valid': ('/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth'), 'test': ('/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth', '/data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth')}}
2:                                      word_blank: 0
2:                                      word_dropout: 0
2:                                      word_keep: 0.1
2:                                      word_mask: 0.8
2:                                      word_mask_keep_rand: 0.8,0.1,0.1
2:                                      word_pred: 0.15
2:                                      word_rand: 0.1
2:                                      word_shuffle: 0
2:                                      world_size: 3    backend='nccl',
2: 
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py", line 397, in init_process_group
2: INFO - 04/18/20 13:42:02 - 0:00:00 - The experiment will be stored in ./dumped/xlm_en_de_tlm/3083
2:                                      
2: INFO - 04/18/20 13:42:02 - 0:00:00 - Running command: python train.py --local_rank=2 --exp_name xlm_en_de_tlm --dump_path './dumped' --data_path '/data/shared/ConceptualCaptions/XLM_data/50k' --lgs 'en-de' --clm_steps '' --mlm_steps 'en-de' --emb_dim 512 --n_layers 6 --n_heads 8 --dropout '0.1' --attention_dropout '0.1' --gelu_activation true --batch_size 32 --bptt 256 --optimizer 'adam,lr=0.0001' --epoch_size 300000 --max_epoch 100000 --validation_metrics valid_en_de_mlm_ppl --stopping_criterion '_valid_mlm_ppl,25' --fp16 false --image_names '/data/shared/ConceptualCaptions/XLM_data/50k'
3:     store, rank, world_size = next(rendezvous_iterator)
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/rendezvous.py", line 168, in _env_rendezvous_handler
2: 
2:     store, rank, world_size = next(rendezvous_iterator)
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/rendezvous.py", line 168, in _env_rendezvous_handler
2: WARNING - 04/18/20 13:42:02 - 0:00:00 - Signal handler installed.
3:     store = TCPStore(master_addr, master_port, world_size, start_daemon)
3: RuntimeError: Address already in use
2: 
2:     store = TCPStore(master_addr, master_port, world_size, start_daemon)
2: RuntimeError: Address already in use
2: INFO - 04/18/20 13:42:02 - 0:00:00 - ============ Parallel data (de-en)
2: INFO - 04/18/20 13:42:02 - 0:00:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
1: INFO - 04/18/20 13:42:05 - 0:00:04 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:42:05 - 0:00:04 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
1: INFO - 04/18/20 13:42:06 - 0:00:04 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:42:06 - 0:00:04 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:42:06 - 0:00:04 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
1: INFO - 04/18/20 13:42:06 - 0:00:04 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
2: INFO - 04/18/20 13:42:09 - 0:00:06 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:42:09 - 0:00:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
0: INFO - 04/18/20 13:42:09 - 0:00:07 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:42:09 - 0:00:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
0: INFO - 04/18/20 13:42:09 - 0:00:07 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:42:09 - 0:00:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
2: INFO - 04/18/20 13:42:09 - 0:00:07 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:42:09 - 0:00:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
3: INFO - 04/18/20 13:42:09 - 0:00:07 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:42:09 - 0:00:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
3: INFO - 04/18/20 13:42:09 - 0:00:07 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:42:09 - 0:00:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
1: INFO - 04/18/20 13:42:10 - 0:00:09 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
0: Traceback (most recent call last):
0:   File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
0:     "__main__", mod_spec)
0:   File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
0:     exec(code, run_globals)
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 263, in <module>
0:     main()
0:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 259, in main
0:     cmd=cmd)
0: subprocess.CalledProcessError: Command '['/home/menekse/virtualenvs/torch_env/bin/python', '-u', 'train.py', '--local_rank=2', '--exp_name', 'xlm_en_de_tlm', '--dump_path', './dumped', '--data_path', '/data/shared/ConceptualCaptions/XLM_data/50k', '--lgs', 'en-de', '--clm_steps', '', '--mlm_steps', 'en-de', '--emb_dim', '512', '--n_layers', '6', '--n_heads', '8', '--dropout', '0.1', '--attention_dropout', '0.1', '--gelu_activation', 'true', '--batch_size', '32', '--bptt', '256', '--optimizer', 'adam,lr=0.0001', '--epoch_size', '300000', '--max_epoch', '100000', '--validation_metrics', 'valid_en_de_mlm_ppl', '--stopping_criterion', '_valid_mlm_ppl,25', '--fp16', 'false', '--image_names', '/data/shared/ConceptualCaptions/XLM_data/50k']' returned non-zero exit status 1.
1: INFO - 04/18/20 13:42:10 - 0:00:09 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:42:11 - 0:00:09 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
2: Traceback (most recent call last):
2:   File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
2:     "__main__", mod_spec)
2:   File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
2:     exec(code, run_globals)
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 263, in <module>
2:     main()
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 259, in main
2:     cmd=cmd)
2: subprocess.CalledProcessError: Command '['/home/menekse/virtualenvs/torch_env/bin/python', '-u', 'train.py', '--local_rank=2', '--exp_name', 'xlm_en_de_tlm', '--dump_path', './dumped', '--data_path', '/data/shared/ConceptualCaptions/XLM_data/50k', '--lgs', 'en-de', '--clm_steps', '', '--mlm_steps', 'en-de', '--emb_dim', '512', '--n_layers', '6', '--n_heads', '8', '--dropout', '0.1', '--attention_dropout', '0.1', '--gelu_activation', 'true', '--batch_size', '32', '--bptt', '256', '--optimizer', 'adam,lr=0.0001', '--epoch_size', '300000', '--max_epoch', '100000', '--validation_metrics', 'valid_en_de_mlm_ppl', '--stopping_criterion', '_valid_mlm_ppl,25', '--fp16', 'false', '--image_names', '/data/shared/ConceptualCaptions/XLM_data/50k']' returned non-zero exit status 1.
3: Traceback (most recent call last):
3:   File "/usr/lib64/python3.6/runpy.py", line 193, in _run_module_as_main
3:     "__main__", mod_spec)
3:   File "/usr/lib64/python3.6/runpy.py", line 85, in _run_code
3:     exec(code, run_globals)
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 263, in <module>
3:     main()
3:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/distributed/launch.py", line 259, in main
3:     cmd=cmd)
3: subprocess.CalledProcessError: Command '['/home/menekse/virtualenvs/torch_env/bin/python', '-u', 'train.py', '--local_rank=2', '--exp_name', 'xlm_en_de_tlm', '--dump_path', './dumped', '--data_path', '/data/shared/ConceptualCaptions/XLM_data/50k', '--lgs', 'en-de', '--clm_steps', '', '--mlm_steps', 'en-de', '--emb_dim', '512', '--n_layers', '6', '--n_heads', '8', '--dropout', '0.1', '--attention_dropout', '0.1', '--gelu_activation', 'true', '--batch_size', '32', '--bptt', '256', '--optimizer', 'adam,lr=0.0001', '--epoch_size', '300000', '--max_epoch', '100000', '--validation_metrics', 'valid_en_de_mlm_ppl', '--stopping_criterion', '_valid_mlm_ppl,25', '--fp16', 'false', '--image_names', '/data/shared/ConceptualCaptions/XLM_data/50k']' returned non-zero exit status 1.
0: INFO - 04/18/20 13:42:14 - 0:00:12 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
2: INFO - 04/18/20 13:42:14 - 0:00:12 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:42:14 - 0:00:12 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
2: INFO - 04/18/20 13:42:15 - 0:00:12 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:42:15 - 0:00:12 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
0: INFO - 04/18/20 13:42:15 - 0:00:13 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
srun: error: hanabi: task 0: Exited with exit code 1
srun: error: hanabi: task 2: Exited with exit code 1
srun: error: hanabi: task 3: Exited with exit code 1
1: INFO - 04/18/20 13:42:22 - 0:00:21 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:42:23 - 0:00:21 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:42:23 - 0:00:21 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:42:25 - 0:00:22 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:42:26 - 0:00:24 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:42:26 - 0:00:24 - Removed 0 empty sentences.
2: INFO - 04/18/20 13:42:26 - 0:00:24 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:42:27 - 0:00:24 - Removed 0 empty sentences.
2: INFO - 04/18/20 13:42:27 - 0:00:25 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:42:40 - 0:00:38 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:42:42 - 0:00:41 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:42:43 - 0:00:40 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:42:43 - 0:00:42 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:42:43 - 0:00:42 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:42:47 - 0:00:44 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:42:49 - 0:00:47 - Removed 0 empty sentences.
2: INFO - 04/18/20 13:42:51 - 0:00:48 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:42:51 - 0:00:48 - Removed 2 too long sentences.
2: INFO - 04/18/20 13:42:54 - 0:00:52 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:42:54 - 0:00:52 - Removed 2 too long sentences.
0: 
0: INFO - 04/18/20 13:42:56 - 0:00:53 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
0: INFO - 04/18/20 13:42:56 - 0:00:54 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:42:56 - 0:00:54 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
0: INFO - 04/18/20 13:42:56 - 0:00:54 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:42:57 - 0:00:55 - Removed 2 too long sentences.
1: INFO - 04/18/20 13:42:57 - 0:00:56 - Removed 2 too long sentences.
1: INFO - 04/18/20 13:42:58 - 0:00:56 - Removed 2 too long sentences.
0: 
0: INFO - 04/18/20 13:42:59 - 0:00:57 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
0: INFO - 04/18/20 13:43:00 - 0:00:57 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:43:00 - 0:00:57 - Removed 2 too long sentences.
0: INFO - 04/18/20 13:43:00 - 0:00:58 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
0: INFO - 04/18/20 13:43:00 - 0:00:58 - Removed 0 empty sentences.
0: 
0: INFO - 04/18/20 13:43:00 - 0:00:58 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
0: INFO - 04/18/20 13:43:00 - 0:00:58 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
0: INFO - 04/18/20 13:43:01 - 0:00:58 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:43:01 - 0:00:58 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
0: INFO - 04/18/20 13:43:01 - 0:00:59 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: 
1: INFO - 04/18/20 13:43:02 - 0:01:00 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
1: INFO - 04/18/20 13:43:02 - 0:01:00 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:43:02 - 0:01:01 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: 
1: INFO - 04/18/20 13:43:03 - 0:01:01 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
1: INFO - 04/18/20 13:43:03 - 0:01:01 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: 
1: INFO - 04/18/20 13:43:03 - 0:01:02 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
1: INFO - 04/18/20 13:43:03 - 0:01:01 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:43:03 - 0:01:01 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: INFO - 04/18/20 13:43:03 - 0:01:02 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:43:03 - 0:01:02 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: INFO - 04/18/20 13:43:04 - 0:01:02 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:43:04 - 0:01:03 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
0: INFO - 04/18/20 13:43:04 - 0:01:02 - Removed 0 empty sentences.
0: 
0: INFO - 04/18/20 13:43:04 - 0:01:02 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
0: INFO - 04/18/20 13:43:04 - 0:01:02 - Removed 0 empty sentences.
0: 
0: 
0: INFO - 04/18/20 13:43:05 - 0:01:02 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:43:05 - 0:01:02 - ============ Parallel data with image regions (de-en)
0: INFO - 04/18/20 13:43:05 - 0:01:02 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
0: INFO - 04/18/20 13:43:05 - 0:01:02 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
3: INFO - 04/18/20 13:43:05 - 0:01:03 - Removed 2 too long sentences.
3: 
3: INFO - 04/18/20 13:43:05 - 0:01:03 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
0: INFO - 04/18/20 13:43:05 - 0:01:03 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
2: INFO - 04/18/20 13:43:05 - 0:01:03 - Removed 2 too long sentences.
3: INFO - 04/18/20 13:43:06 - 0:01:03 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:43:06 - 0:01:03 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
3: INFO - 04/18/20 13:43:06 - 0:01:04 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:43:07 - 0:01:05 - Removed 0 empty sentences.
1: 
1: INFO - 04/18/20 13:43:07 - 0:01:05 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/18/20 13:43:07 - 0:01:05 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:43:07 - 0:01:05 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/18/20 13:43:07 - 0:01:05 - Removed 0 empty sentences.
1: 
1: INFO - 04/18/20 13:43:07 - 0:01:05 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/18/20 13:43:07 - 0:01:06 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: INFO - 04/18/20 13:43:07 - 0:01:06 - Removed 0 empty sentences.
1: 
1: INFO - 04/18/20 13:43:07 - 0:01:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/18/20 13:43:08 - 0:01:06 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:43:08 - 0:01:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/18/20 13:43:08 - 0:01:07 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:43:08 - 0:01:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/18/20 13:43:08 - 0:01:06 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: INFO - 04/18/20 13:43:08 - 0:01:07 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
0: INFO - 04/18/20 13:43:08 - 0:01:06 - Removed 0 empty sentences.
0: 
0: 
0: INFO - 04/18/20 13:43:09 - 0:01:06 - ============ Parallel data with image regions (de-en)
0: INFO - 04/18/20 13:43:09 - 0:01:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
0: INFO - 04/18/20 13:43:09 - 0:01:06 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:43:09 - 0:01:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
3: INFO - 04/18/20 13:43:10 - 0:01:07 - Removed 0 empty sentences.
3: 
3: INFO - 04/18/20 13:43:10 - 0:01:07 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/18/20 13:43:10 - 0:01:08 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:43:10 - 0:01:08 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
2: 
2: INFO - 04/18/20 13:43:10 - 0:01:08 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
3: INFO - 04/18/20 13:43:10 - 0:01:08 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
2: INFO - 04/18/20 13:43:11 - 0:01:08 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:43:11 - 0:01:08 - Removed 2 too long sentences.
2: INFO - 04/18/20 13:43:11 - 0:01:08 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: INFO - 04/18/20 13:43:11 - 0:01:09 - Removed 0 empty sentences.
1: 
1: 
2: INFO - 04/18/20 13:43:11 - 0:01:09 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:43:11 - 0:01:09 - ============ Parallel data with image regions (de-en)
1: INFO - 04/18/20 13:43:11 - 0:01:09 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: 
3: INFO - 04/18/20 13:43:11 - 0:01:09 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
1: INFO - 04/18/20 13:43:11 - 0:01:10 - Removed 0 empty sentences.
1: 
1: 
1: INFO - 04/18/20 13:43:12 - 0:01:10 - ============ Parallel data with image regions (de-en)
1: INFO - 04/18/20 13:43:12 - 0:01:10 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: INFO - 04/18/20 13:43:12 - 0:01:09 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:43:12 - 0:01:11 - Removed 0 empty sentences.
1: 
1: 
3: INFO - 04/18/20 13:43:12 - 0:01:09 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: INFO - 04/18/20 13:43:12 - 0:01:11 - ============ Parallel data with image regions (de-en)
1: INFO - 04/18/20 13:43:12 - 0:01:11 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: INFO - 04/18/20 13:43:12 - 0:01:10 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
0: INFO - 04/18/20 13:43:13 - 0:01:10 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:43:13 - 0:01:10 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
0: INFO - 04/18/20 13:43:13 - 0:01:11 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:43:14 - 0:01:11 - Removed 0 empty sentences.
3: 
3: 
3: INFO - 04/18/20 13:43:14 - 0:01:12 - ============ Parallel data with image regions (de-en)
3: INFO - 04/18/20 13:43:14 - 0:01:12 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: INFO - 04/18/20 13:43:16 - 0:01:13 - Removed 0 empty sentences.
3: 
3: INFO - 04/18/20 13:43:16 - 0:01:13 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
2: INFO - 04/18/20 13:43:16 - 0:01:13 - Removed 0 empty sentences.
2: 
2: INFO - 04/18/20 13:43:16 - 0:01:13 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/18/20 13:43:16 - 0:01:14 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:43:16 - 0:01:14 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
3: INFO - 04/18/20 13:43:16 - 0:01:14 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:43:16 - 0:01:14 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
2: INFO - 04/18/20 13:43:16 - 0:01:14 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:43:16 - 0:01:14 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:43:16 - 0:01:14 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
2: INFO - 04/18/20 13:43:16 - 0:01:14 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
3: INFO - 04/18/20 13:43:16 - 0:01:14 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: INFO - 04/18/20 13:43:16 - 0:01:15 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:43:16 - 0:01:15 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
2: 
2: INFO - 04/18/20 13:43:16 - 0:01:14 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
2: INFO - 04/18/20 13:43:17 - 0:01:14 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
2: INFO - 04/18/20 13:43:17 - 0:01:14 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:43:17 - 0:01:14 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
2: INFO - 04/18/20 13:43:17 - 0:01:15 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
2: INFO - 04/18/20 13:43:17 - 0:01:15 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:43:18 - 0:01:16 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:43:18 - 0:01:16 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
3: INFO - 04/18/20 13:43:18 - 0:01:16 - Removed 0 empty sentences.
3: 
3: 
3: INFO - 04/18/20 13:43:18 - 0:01:16 - ============ Parallel data with image regions (de-en)
3: INFO - 04/18/20 13:43:19 - 0:01:16 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
1: INFO - 04/18/20 13:43:21 - 0:01:19 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:43:21 - 0:01:19 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
2: INFO - 04/18/20 13:43:21 - 0:01:19 - Removed 0 empty sentences.
2: 
2: 
1: INFO - 04/18/20 13:43:21 - 0:01:20 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
2: INFO - 04/18/20 13:43:21 - 0:01:19 - ============ Parallel data with image regions (de-en)
2: INFO - 04/18/20 13:43:21 - 0:01:19 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
2: INFO - 04/18/20 13:43:21 - 0:01:19 - Removed 0 empty sentences.
2: 
2: INFO - 04/18/20 13:43:21 - 0:01:19 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/18/20 13:43:22 - 0:01:19 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
2: INFO - 04/18/20 13:43:22 - 0:01:19 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:43:22 - 0:01:19 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
2: INFO - 04/18/20 13:43:22 - 0:01:20 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
3: INFO - 04/18/20 13:43:22 - 0:01:20 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:43:22 - 0:01:20 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
2: INFO - 04/18/20 13:43:24 - 0:01:22 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:43:24 - 0:01:22 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
2: INFO - 04/18/20 13:43:25 - 0:01:23 - Removed 0 empty sentences.
2: 
2: 
2: INFO - 04/18/20 13:43:25 - 0:01:23 - ============ Parallel data with image regions (de-en)
2: INFO - 04/18/20 13:43:25 - 0:01:23 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.de.pth ...
3: INFO - 04/18/20 13:43:25 - 0:01:23 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
2: INFO - 04/18/20 13:43:28 - 0:01:26 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
2: INFO - 04/18/20 13:43:28 - 0:01:26 - 33531289 words (43583 unique) in 3308333 sentences. 0 unknown words (0 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:43:28 - 0:01:26 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/train.de-en.en.pth ...
2: INFO - 04/18/20 13:43:32 - 0:01:29 - 34574637 words (43583 unique) in 3308333 sentences. 1388007 unknown words (5654 unique) covering 4.01% of the data.
0: INFO - 04/18/20 13:44:09 - 0:02:06 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:44:16 - 0:02:14 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:44:28 - 0:02:26 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:44:29 - 0:02:26 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:44:32 - 0:02:30 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:44:34 - 0:02:33 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:44:35 - 0:02:33 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:44:36 - 0:02:34 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:44:39 - 0:02:37 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:44:42 - 0:02:40 - Removed 2 too long sentences.
2: INFO - 04/18/20 13:44:45 - 0:02:43 - Removed 0 empty sentences.
0: 
0: INFO - 04/18/20 13:44:47 - 0:02:45 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
0: INFO - 04/18/20 13:44:48 - 0:02:45 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:44:48 - 0:02:46 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
0: INFO - 04/18/20 13:44:48 - 0:02:46 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
0: INFO - 04/18/20 13:44:50 - 0:02:48 - Removed 2 too long sentences.
1: INFO - 04/18/20 13:44:51 - 0:02:49 - Removed 0 empty sentences.
3: INFO - 04/18/20 13:44:53 - 0:02:51 - Removed 0 empty sentences.
0: 
0: INFO - 04/18/20 13:44:55 - 0:02:53 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
0: INFO - 04/18/20 13:44:55 - 0:02:53 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:44:56 - 0:02:53 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
0: INFO - 04/18/20 13:44:56 - 0:02:54 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
2: INFO - 04/18/20 13:44:57 - 0:02:54 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:44:58 - 0:02:56 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:44:58 - 0:02:57 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:44:59 - 0:02:57 - Removed 0 empty sentences.
0: 
0: INFO - 04/18/20 13:44:59 - 0:02:57 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
0: INFO - 04/18/20 13:44:59 - 0:02:57 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:45:00 - 0:02:57 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
0: INFO - 04/18/20 13:45:00 - 0:02:58 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
3: INFO - 04/18/20 13:45:01 - 0:02:59 - Removed 0 empty sentences.
0: INFO - 04/18/20 13:45:04 - 0:03:01 - Removed 0 empty sentences.
0: 
0: 
0: INFO - 04/18/20 13:45:04 - 0:03:01 - ============ Data summary
0: INFO - 04/18/20 13:45:04 - 0:03:01 - Parallel data      - train -        de-en:   3308331
0: INFO - 04/18/20 13:45:04 - 0:03:01 - Parallel data      - valid -        de-en:      5000
0: INFO - 04/18/20 13:45:04 - 0:03:01 - Parallel data      -  test -        de-en:      5000
0: 
1: INFO - 04/18/20 13:45:06 - 0:03:04 - Removed 2 too long sentences.
3: INFO - 04/18/20 13:45:08 - 0:03:05 - Removed 2 too long sentences.
0: INFO - 04/18/20 13:45:08 - 0:03:05 - Removed 0 empty sentences.
0: 
0: INFO - 04/18/20 13:45:08 - 0:03:05 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
0: INFO - 04/18/20 13:45:08 - 0:03:06 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
0: INFO - 04/18/20 13:45:08 - 0:03:06 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
0: INFO - 04/18/20 13:45:09 - 0:03:06 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
2: INFO - 04/18/20 13:45:10 - 0:03:07 - Removed 0 empty sentences.
1: 
1: INFO - 04/18/20 13:45:11 - 0:03:09 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
1: INFO - 04/18/20 13:45:12 - 0:03:10 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:45:12 - 0:03:10 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: INFO - 04/18/20 13:45:12 - 0:03:11 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
0: INFO - 04/18/20 13:45:12 - 0:03:10 - Removed 0 empty sentences.
0: 
0: 
0: INFO - 04/18/20 13:45:13 - 0:03:10 - ============ Data summary
3: 
0: INFO - 04/18/20 13:45:13 - 0:03:10 - Parallel data      - train -        de-en:   3308331
0: INFO - 04/18/20 13:45:13 - 0:03:10 - Parallel data      - valid -        de-en:      5000
0: INFO - 04/18/20 13:45:13 - 0:03:10 - Parallel data      -  test -        de-en:      5000
0: 
3: INFO - 04/18/20 13:45:13 - 0:03:10 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
3: INFO - 04/18/20 13:45:13 - 0:03:11 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:45:13 - 0:03:11 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: INFO - 04/18/20 13:45:14 - 0:03:12 - Removed 2 too long sentences.
3: INFO - 04/18/20 13:45:14 - 0:03:11 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:45:14 - 0:03:12 - Removed 2 too long sentences.
3: INFO - 04/18/20 13:45:17 - 0:03:15 - Removed 2 too long sentences.
1: 
1: INFO - 04/18/20 13:45:19 - 0:03:18 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
2: INFO - 04/18/20 13:45:20 - 0:03:17 - Removed 0 empty sentences.
1: INFO - 04/18/20 13:45:20 - 0:03:19 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:45:20 - 0:03:19 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: 
1: INFO - 04/18/20 13:45:20 - 0:03:18 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
0: INFO - 04/18/20 13:45:20 - 0:03:18 - Model: TransformerModel(
0:                                        (projector): Projector(
0:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
0:                                        )
0:                                        (regional_encodings): RegionalEncodings(
0:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
0:                                        )
0:                                        (position_embeddings): Embedding(512, 512)
0:                                        (lang_embeddings): Embedding(3, 512)
0:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
0:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        (attentions): ModuleList(
0:                                          (0): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (1): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (2): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (3): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (4): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (5): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                        )
0:                                        (layer_norm1): ModuleList(
0:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        )
0:                                        (ffns): ModuleList(
0:                                          (0): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (1): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (2): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (3): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (4): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (5): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                        )
0:                                        (layer_norm2): ModuleList(
0:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        )
0:                                        (memories): ModuleDict()
0:                                        (pred_layer): PredLayer(
0:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
0:                                        )
0:                                        (img_pred_layer): ImgPredLayer(
0:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
0:                                        )
0:                                      )
0: INFO - 04/18/20 13:45:20 - 0:03:18 - Number of parameters (model): 92180120
1: INFO - 04/18/20 13:45:20 - 0:03:19 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:45:21 - 0:03:19 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:45:21 - 0:03:19 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
1: INFO - 04/18/20 13:45:21 - 0:03:19 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
3: 
3: INFO - 04/18/20 13:45:23 - 0:03:20 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
3: INFO - 04/18/20 13:45:23 - 0:03:21 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:45:23 - 0:03:21 - Removed 0 empty sentences.
3: 
3: INFO - 04/18/20 13:45:23 - 0:03:21 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/18/20 13:45:23 - 0:03:21 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
3: INFO - 04/18/20 13:45:24 - 0:03:21 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:45:24 - 0:03:21 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
3: INFO - 04/18/20 13:45:24 - 0:03:21 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
3: INFO - 04/18/20 13:45:24 - 0:03:22 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: INFO - 04/18/20 13:45:25 - 0:03:23 - Removed 0 empty sentences.
1: 
1: INFO - 04/18/20 13:45:25 - 0:03:23 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/18/20 13:45:25 - 0:03:24 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:45:26 - 0:03:24 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/18/20 13:45:26 - 0:03:24 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
2: INFO - 04/18/20 13:45:26 - 0:03:24 - Removed 2 too long sentences.
3: INFO - 04/18/20 13:45:27 - 0:03:25 - Removed 0 empty sentences.
3: 
3: 
3: INFO - 04/18/20 13:45:28 - 0:03:25 - ============ Data summary
3: INFO - 04/18/20 13:45:28 - 0:03:25 - Parallel data      - train -        de-en:   3308331
3: INFO - 04/18/20 13:45:28 - 0:03:25 - Parallel data      - valid -        de-en:      5000
3: INFO - 04/18/20 13:45:28 - 0:03:25 - Parallel data      -  test -        de-en:      5000
3: 
0: INFO - 04/18/20 13:45:29 - 0:03:27 - Model: TransformerModel(
0:                                        (projector): Projector(
0:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
0:                                        )
0:                                        (regional_encodings): RegionalEncodings(
0:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
0:                                        )
0:                                        (position_embeddings): Embedding(512, 512)
0:                                        (lang_embeddings): Embedding(3, 512)
0:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
0:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        (attentions): ModuleList(
0:                                          (0): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (1): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (2): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (3): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (4): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                          (5): MultiHeadAttention(
0:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
0:                                          )
0:                                        )
0:                                        (layer_norm1): ModuleList(
0:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        )
0:                                        (ffns): ModuleList(
0:                                          (0): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (1): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (2): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (3): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (4): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                          (5): TransformerFFN(
0:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
0:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
0:                                          )
0:                                        )
0:                                        (layer_norm2): ModuleList(
0:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
0:                                        )
0:                                        (memories): ModuleDict()
0:                                        (pred_layer): PredLayer(
0:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
0:                                        )
0:                                        (img_pred_layer): ImgPredLayer(
0:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
0:                                        )
0:                                      )
0: INFO - 04/18/20 13:45:29 - 0:03:27 - Number of parameters (model): 92180120
1: INFO - 04/18/20 13:45:30 - 0:03:29 - Removed 0 empty sentences.
1: 
1: 
1: INFO - 04/18/20 13:45:31 - 0:03:29 - ============ Data summary
1: INFO - 04/18/20 13:45:31 - 0:03:29 - Parallel data      - train -        de-en:   3308331
1: INFO - 04/18/20 13:45:31 - 0:03:29 - Parallel data      - valid -        de-en:      5000
1: INFO - 04/18/20 13:45:31 - 0:03:29 - Parallel data      -  test -        de-en:      5000
1: 
2: 
2: INFO - 04/18/20 13:45:31 - 0:03:29 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
2: INFO - 04/18/20 13:45:32 - 0:03:29 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:45:32 - 0:03:30 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
2: INFO - 04/18/20 13:45:32 - 0:03:30 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
1: INFO - 04/18/20 13:45:33 - 0:03:32 - Removed 0 empty sentences.
1: 
1: INFO - 04/18/20 13:45:33 - 0:03:32 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/18/20 13:45:33 - 0:03:32 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:45:33 - 0:03:32 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/18/20 13:45:33 - 0:03:31 - Removed 0 empty sentences.
1: 
1: INFO - 04/18/20 13:45:33 - 0:03:31 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
1: INFO - 04/18/20 13:45:34 - 0:03:32 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: INFO - 04/18/20 13:45:34 - 0:03:32 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
1: INFO - 04/18/20 13:45:34 - 0:03:32 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
1: INFO - 04/18/20 13:45:34 - 0:03:32 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
3: INFO - 04/18/20 13:45:34 - 0:03:32 - Removed 0 empty sentences.
3: 
3: INFO - 04/18/20 13:45:34 - 0:03:32 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/18/20 13:45:35 - 0:03:32 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:45:35 - 0:03:33 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
3: INFO - 04/18/20 13:45:35 - 0:03:33 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
2: INFO - 04/18/20 13:45:36 - 0:03:34 - Removed 2 too long sentences.
1: INFO - 04/18/20 13:45:37 - 0:03:36 - Removed 0 empty sentences.
1: 
1: 
1: INFO - 04/18/20 13:45:37 - 0:03:35 - Removed 0 empty sentences.
1: 
1: 
1: INFO - 04/18/20 13:45:37 - 0:03:36 - ============ Data summary
1: INFO - 04/18/20 13:45:37 - 0:03:36 - Parallel data      - train -        de-en:   3308331
1: INFO - 04/18/20 13:45:37 - 0:03:36 - Parallel data      - valid -        de-en:      5000
1: INFO - 04/18/20 13:45:37 - 0:03:36 - Parallel data      -  test -        de-en:      5000
1: 
1: INFO - 04/18/20 13:45:37 - 0:03:35 - ============ Data summary
1: INFO - 04/18/20 13:45:37 - 0:03:35 - Parallel data      - train -        de-en:   3308331
1: INFO - 04/18/20 13:45:37 - 0:03:35 - Parallel data      - valid -        de-en:      5000
1: INFO - 04/18/20 13:45:37 - 0:03:35 - Parallel data      -  test -        de-en:      5000
1: 
3: INFO - 04/18/20 13:45:39 - 0:03:37 - Removed 0 empty sentences.
3: 
3: 
3: INFO - 04/18/20 13:45:39 - 0:03:37 - ============ Data summary
3: INFO - 04/18/20 13:45:39 - 0:03:37 - Parallel data      - train -        de-en:   3308331
3: INFO - 04/18/20 13:45:39 - 0:03:37 - Parallel data      - valid -        de-en:      5000
3: INFO - 04/18/20 13:45:39 - 0:03:37 - Parallel data      -  test -        de-en:      5000
3: 
2: 
2: INFO - 04/18/20 13:45:41 - 0:03:39 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.de.pth ...
2: INFO - 04/18/20 13:45:42 - 0:03:39 - 50155 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
3: INFO - 04/18/20 13:45:42 - 0:03:39 - Model: TransformerModel(
3:                                        (projector): Projector(
3:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
3:                                        )
3:                                        (regional_encodings): RegionalEncodings(
3:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
3:                                        )
3:                                        (position_embeddings): Embedding(512, 512)
3:                                        (lang_embeddings): Embedding(3, 512)
3:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
3:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        (attentions): ModuleList(
3:                                          (0): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (1): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (2): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (3): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (4): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (5): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm1): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (ffns): ModuleList(
3:                                          (0): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (1): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (2): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (3): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (4): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (5): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm2): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (memories): ModuleDict()
3:                                        (pred_layer): PredLayer(
3:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
3:                                        )
3:                                        (img_pred_layer): ImgPredLayer(
3:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
3:                                        )
3:                                      )
3: INFO - 04/18/20 13:45:42 - 0:03:39 - Number of parameters (model): 92180120
2: INFO - 04/18/20 13:45:42 - 0:03:40 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/valid.de-en.en.pth ...
2: INFO - 04/18/20 13:45:42 - 0:03:40 - Removed 0 empty sentences.
2: 
2: INFO - 04/18/20 13:45:42 - 0:03:40 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
2: INFO - 04/18/20 13:45:42 - 0:03:40 - 51874 words (43583 unique) in 5000 sentences. 2079 unknown words (1276 unique) covering 4.01% of the data.
2: INFO - 04/18/20 13:45:43 - 0:03:40 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:45:43 - 0:03:40 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
2: INFO - 04/18/20 13:45:43 - 0:03:41 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
2: INFO - 04/18/20 13:45:46 - 0:03:44 - Removed 0 empty sentences.
2: 
2: 
2: INFO - 04/18/20 13:45:46 - 0:03:44 - ============ Data summary
2: INFO - 04/18/20 13:45:46 - 0:03:44 - Parallel data      - train -        de-en:   3308331
2: INFO - 04/18/20 13:45:46 - 0:03:44 - Parallel data      - valid -        de-en:      5000
2: INFO - 04/18/20 13:45:46 - 0:03:44 - Parallel data      -  test -        de-en:      5000
2: 
1: INFO - 04/18/20 13:45:48 - 0:03:46 - Model: TransformerModel(
1:                                        (projector): Projector(
1:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
1:                                        )
1:                                        (regional_encodings): RegionalEncodings(
1:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
1:                                        )
1:                                        (position_embeddings): Embedding(512, 512)
1:                                        (lang_embeddings): Embedding(3, 512)
1:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
1:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        (attentions): ModuleList(
1:                                          (0): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (1): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (2): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (3): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (4): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (5): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                        )
1:                                        (layer_norm1): ModuleList(
1:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        )
1:                                        (ffns): ModuleList(
1:                                          (0): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (1): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (2): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (3): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (4): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (5): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                        )
1:                                        (layer_norm2): ModuleList(
1:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        )
1:                                        (memories): ModuleDict()
1:                                        (pred_layer): PredLayer(
1:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
1:                                        )
1:                                        (img_pred_layer): ImgPredLayer(
1:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
1:                                        )
1:                                      )
1: INFO - 04/18/20 13:45:48 - 0:03:46 - Number of parameters (model): 92180120
2: INFO - 04/18/20 13:45:54 - 0:03:52 - Removed 0 empty sentences.
2: 
2: INFO - 04/18/20 13:45:54 - 0:03:52 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.de.pth ...
3: INFO - 04/18/20 13:45:54 - 0:03:52 - Model: TransformerModel(
3:                                        (projector): Projector(
3:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
3:                                        )
3:                                        (regional_encodings): RegionalEncodings(
3:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
3:                                        )
3:                                        (position_embeddings): Embedding(512, 512)
3:                                        (lang_embeddings): Embedding(3, 512)
3:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
3:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        (attentions): ModuleList(
3:                                          (0): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (1): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (2): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (3): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (4): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                          (5): MultiHeadAttention(
3:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm1): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (ffns): ModuleList(
3:                                          (0): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (1): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (2): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (3): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (4): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                          (5): TransformerFFN(
3:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
3:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
3:                                          )
3:                                        )
3:                                        (layer_norm2): ModuleList(
3:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
3:                                        )
3:                                        (memories): ModuleDict()
3:                                        (pred_layer): PredLayer(
3:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
3:                                        )
3:                                        (img_pred_layer): ImgPredLayer(
3:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
3:                                        )
3:                                      )
3: INFO - 04/18/20 13:45:54 - 0:03:52 - Number of parameters (model): 92180120
2: INFO - 04/18/20 13:45:54 - 0:03:52 - 50096 words (43583 unique) in 5000 sentences. 2 unknown words (2 unique) covering 0.00% of the data.
2: INFO - 04/18/20 13:45:54 - 0:03:52 - Loading data from /data/shared/ConceptualCaptions/XLM_data/50k/test.de-en.en.pth ...
2: INFO - 04/18/20 13:45:55 - 0:03:52 - 51841 words (43583 unique) in 5000 sentences. 2012 unknown words (1221 unique) covering 3.88% of the data.
1: INFO - 04/18/20 13:45:55 - 0:03:54 - Model: TransformerModel(
1:                                        (projector): Projector(
1:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
1:                                        )
1:                                        (regional_encodings): RegionalEncodings(
1:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
1:                                        )
1:                                        (position_embeddings): Embedding(512, 512)
1:                                        (lang_embeddings): Embedding(3, 512)
1:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
1:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        (attentions): ModuleList(
1:                                          (0): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (1): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (2): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (3): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (4): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (5): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                        )
1:                                        (layer_norm1): ModuleList(
1:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        )
1:                                        (ffns): ModuleList(
1:                                          (0): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (1): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (2): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (3): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (4): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (5): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                        )
1:                                        (layer_norm2): ModuleList(
1:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        )
1:                                        (memories): ModuleDict()
1:                                        (pred_layer): PredLayer(
1:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
1:                                        )
1:                                        (img_pred_layer): ImgPredLayer(
1:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
1:                                        )
1:                                      )
1: INFO - 04/18/20 13:45:55 - 0:03:54 - Number of parameters (model): 92180120
1: INFO - 04/18/20 13:45:56 - 0:03:54 - Model: TransformerModel(
1:                                        (projector): Projector(
1:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
1:                                        )
1:                                        (regional_encodings): RegionalEncodings(
1:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
1:                                        )
1:                                        (position_embeddings): Embedding(512, 512)
1:                                        (lang_embeddings): Embedding(3, 512)
1:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
1:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        (attentions): ModuleList(
1:                                          (0): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (1): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (2): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (3): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (4): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                          (5): MultiHeadAttention(
1:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
1:                                          )
1:                                        )
1:                                        (layer_norm1): ModuleList(
1:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        )
1:                                        (ffns): ModuleList(
1:                                          (0): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (1): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (2): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (3): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (4): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                          (5): TransformerFFN(
1:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
1:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
1:                                          )
1:                                        )
1:                                        (layer_norm2): ModuleList(
1:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
1:                                        )
1:                                        (memories): ModuleDict()
1:                                        (pred_layer): PredLayer(
1:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
1:                                        )
1:                                        (img_pred_layer): ImgPredLayer(
1:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
1:                                        )
1:                                      )
1: INFO - 04/18/20 13:45:56 - 0:03:54 - Number of parameters (model): 92180120
2: INFO - 04/18/20 13:45:58 - 0:03:56 - Removed 0 empty sentences.
2: 
2: 
2: INFO - 04/18/20 13:45:58 - 0:03:56 - ============ Data summary
2: INFO - 04/18/20 13:45:58 - 0:03:56 - Parallel data      - train -        de-en:   3308331
2: INFO - 04/18/20 13:45:58 - 0:03:56 - Parallel data      - valid -        de-en:      5000
2: INFO - 04/18/20 13:45:58 - 0:03:56 - Parallel data      -  test -        de-en:      5000
2: 
2: INFO - 04/18/20 13:46:06 - 0:04:04 - Model: TransformerModel(
2:                                        (projector): Projector(
2:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
2:                                        )
2:                                        (regional_encodings): RegionalEncodings(
2:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
2:                                        )
2:                                        (position_embeddings): Embedding(512, 512)
2:                                        (lang_embeddings): Embedding(3, 512)
2:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
2:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        (attentions): ModuleList(
2:                                          (0): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (1): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (2): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (3): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (4): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (5): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                        )
2:                                        (layer_norm1): ModuleList(
2:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        )
2:                                        (ffns): ModuleList(
2:                                          (0): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (1): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (2): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (3): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (4): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (5): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                        )
2:                                        (layer_norm2): ModuleList(
2:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        )
2:                                        (memories): ModuleDict()
2:                                        (pred_layer): PredLayer(
2:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
2:                                        )
2:                                        (img_pred_layer): ImgPredLayer(
2:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
2:                                        )
2:                                      )
2: INFO - 04/18/20 13:46:06 - 0:04:04 - Number of parameters (model): 92180120
2: INFO - 04/18/20 13:46:19 - 0:04:16 - Model: TransformerModel(
2:                                        (projector): Projector(
2:                                          (linear): Linear(in_features=98304, out_features=512, bias=True)
2:                                        )
2:                                        (regional_encodings): RegionalEncodings(
2:                                          (linear): Linear(in_features=4, out_features=512, bias=True)
2:                                        )
2:                                        (position_embeddings): Embedding(512, 512)
2:                                        (lang_embeddings): Embedding(3, 512)
2:                                        (embeddings): Embedding(43583, 512, padding_idx=2)
2:                                        (layer_norm_emb): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        (attentions): ModuleList(
2:                                          (0): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (1): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (2): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (3): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (4): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                          (5): MultiHeadAttention(
2:                                            (q_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (k_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (v_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                            (out_lin): Linear(in_features=512, out_features=512, bias=True)
2:                                          )
2:                                        )
2:                                        (layer_norm1): ModuleList(
2:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        )
2:                                        (ffns): ModuleList(
2:                                          (0): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (1): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (2): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (3): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (4): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                          (5): TransformerFFN(
2:                                            (lin1): Linear(in_features=512, out_features=2048, bias=True)
2:                                            (lin2): Linear(in_features=2048, out_features=512, bias=True)
2:                                          )
2:                                        )
2:                                        (layer_norm2): ModuleList(
2:                                          (0): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (1): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (2): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (3): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (4): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                          (5): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
2:                                        )
2:                                        (memories): ModuleDict()
2:                                        (pred_layer): PredLayer(
2:                                          (proj): Linear(in_features=512, out_features=43583, bias=True)
2:                                        )
2:                                        (img_pred_layer): ImgPredLayer(
2:                                          (proj): Linear(in_features=512, out_features=601, bias=True)
2:                                        )
2:                                      )
2: INFO - 04/18/20 13:46:19 - 0:04:16 - Number of parameters (model): 92180120
0: INFO - 04/18/20 13:46:46 - 0:04:43 - Found 0 memories.
0: INFO - 04/18/20 13:46:46 - 0:04:43 - Found 6 FFN.
0: INFO - 04/18/20 13:46:46 - 0:04:43 - Found 108 parameters in model.
0: INFO - 04/18/20 13:46:46 - 0:04:43 - Using nn.parallel.DistributedDataParallel ...
0: INFO - 04/18/20 13:46:51 - 0:04:49 - Found 0 memories.
0: INFO - 04/18/20 13:46:51 - 0:04:49 - Found 6 FFN.
0: INFO - 04/18/20 13:46:51 - 0:04:49 - Found 108 parameters in model.
0: INFO - 04/18/20 13:46:51 - 0:04:49 - Using nn.parallel.DistributedDataParallel ...
3: INFO - 04/18/20 13:47:00 - 0:04:58 - Found 0 memories.
3: INFO - 04/18/20 13:47:00 - 0:04:58 - Found 6 FFN.
3: INFO - 04/18/20 13:47:00 - 0:04:58 - Found 108 parameters in model.
3: INFO - 04/18/20 13:47:00 - 0:04:58 - Using nn.parallel.DistributedDataParallel ...
3: INFO - 04/18/20 13:47:09 - 0:05:07 - Found 0 memories.
3: INFO - 04/18/20 13:47:09 - 0:05:07 - Found 6 FFN.
3: INFO - 04/18/20 13:47:09 - 0:05:07 - Found 108 parameters in model.
3: INFO - 04/18/20 13:47:09 - 0:05:07 - Using nn.parallel.DistributedDataParallel ...
1: INFO - 04/18/20 13:47:18 - 0:05:16 - Found 0 memories.
1: INFO - 04/18/20 13:47:18 - 0:05:16 - Found 6 FFN.
1: INFO - 04/18/20 13:47:18 - 0:05:16 - Found 108 parameters in model.
1: INFO - 04/18/20 13:47:18 - 0:05:16 - Using nn.parallel.DistributedDataParallel ...
1: INFO - 04/18/20 13:47:21 - 0:05:20 - Found 0 memories.
1: INFO - 04/18/20 13:47:21 - 0:05:20 - Found 6 FFN.
1: INFO - 04/18/20 13:47:21 - 0:05:20 - Found 108 parameters in model.
1: INFO - 04/18/20 13:47:21 - 0:05:20 - Using nn.parallel.DistributedDataParallel ...
1: INFO - 04/18/20 13:47:23 - 0:05:21 - Found 0 memories.
1: INFO - 04/18/20 13:47:23 - 0:05:21 - Found 6 FFN.
1: INFO - 04/18/20 13:47:23 - 0:05:21 - Found 108 parameters in model.
1: INFO - 04/18/20 13:47:23 - 0:05:21 - Using nn.parallel.DistributedDataParallel ...
2: INFO - 04/18/20 13:47:30 - 0:05:28 - Found 0 memories.
2: INFO - 04/18/20 13:47:30 - 0:05:28 - Found 6 FFN.
2: INFO - 04/18/20 13:47:30 - 0:05:28 - Found 108 parameters in model.
2: INFO - 04/18/20 13:47:30 - 0:05:28 - Using nn.parallel.DistributedDataParallel ...
2: INFO - 04/18/20 13:47:37 - 0:05:35 - Found 0 memories.
2: INFO - 04/18/20 13:47:37 - 0:05:35 - Found 6 FFN.
2: INFO - 04/18/20 13:47:37 - 0:05:35 - Found 108 parameters in model.
2: INFO - 04/18/20 13:47:37 - 0:05:35 - Using nn.parallel.DistributedDataParallel ...
2: Traceback (most recent call last):
2:   File "train.py", line 348, in <module>
2:     main(params)
2:   File "train.py", line 251, in main
2:     trainer = SingleTrainer(model, data, params)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 988, in __init__
2:     super().__init__(data, params)
2:   File "/home/menekse/xlm/Animal/XLM-master/src/trainer.py", line 67, in __init__
2:     setattr(self, name, nn.parallel.DistributedDataParallel(getattr(self, name), device_ids=[params.local_rank], output_device=params.local_rank, broadcast_buffers=True))
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 303, in __init__
2:     self.broadcast_bucket_size)
2:   File "/home/menekse/virtualenvs/torch_env/lib/python3.6/site-packages/torch/nn/parallel/distributed.py", line 485, in _distributed_broadcast_coalesced
2:     dist._broadcast_coalesced(self.process_group, tensors, buffer_size)
2: RuntimeError: NCCL error in: /pytorch/torch/lib/c10d/ProcessGroupNCCL.cpp:410, unhandled system error, NCCL version 2.4.8
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** JOB 3083 ON hanabi CANCELLED AT 2020-04-18T19:06:31 ***
0: slurmstepd: error: *** STEP 3083.0 ON hanabi CANCELLED AT 2020-04-18T19:06:31 ***
